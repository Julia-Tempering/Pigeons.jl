var documenterSearchIndex = {"docs":
[{"location":"mpi/#Distributed-sampling-over-MPI-using-Pigeons","page":"Distributed usage (MPI)","title":"Distributed sampling over MPI using Pigeons","text":"","category":"section"},{"location":"mpi/#mpi-local","page":"Distributed usage (MPI)","title":"Running MPI locally","text":"To run MPI locally on one machine, using 4 MPI processes, use:\n\nusing Pigeons\nresult = pigeons(\n    target = toy_mvn_target(100), \n    checkpoint = true, \n    on = ChildProcess(\n            n_local_mpi_processes = 4))\n\nNote that if n_local_mpi_processes exceeds the number of cores, performance  will steeply degrade (in contrast to threads, for which performance degrades  much more gracefully when the number of threads exceeds the number of cores). \n\nUsing on = ChildProcess(...) is also useful to change the  number of threads without having to restart the Julia session.  For example, to start 4 child processes, each with two threads concurrently sharing work  across the chains, use:\n\nresult = pigeons(\n    target = toy_mvn_target(100), \n    multithreaded = true, \n    checkpoint = true, \n    on = ChildProcess(\n            n_local_mpi_processes = 4,\n            n_threads = 2))\n\nAlternatively, if instead of using the 2 threads to parallelize across chain, we want to use them to parallelize e.g. a custom likelihood evalutation over datapoints, set multithreaded = false to  indicate to pigeons it is not responsible for the multithreading (multithreaded = false is the default behaviour):\n\nresult = pigeons(\n    target = toy_mvn_target(100), \n    multithreaded = false, # can be skipped, the default  \n    checkpoint = true, \n    on = ChildProcess(\n            n_local_mpi_processes = 4,\n            n_threads = 2))\n\nTo analyze the output, see the documentation page on post-processing for MPI runs. Briefly, one option is to load the state of the sampler  back to your interactive chain via: \n\npt = Pigeons.load(result) # possible thanks to 'pigeons(..., checkpoint = true)' used above","category":"section"},{"location":"mpi/#Running-MPI-on-a-cluster","page":"Distributed usage (MPI)","title":"Running MPI on a cluster","text":"note: The magic of distributed Parallel Tempering\nIf the dimensionality of the state space is large, you may worry that  the time to transmit states over the network would dominate the running time.  Remarkably, the size of the messages transmitted in the inner loop of our  algorithm does not depend on the state space. In a nutshell, the  machines only need to transmit the value of log density ratios (a single float).  See Algorithm 5 in Syed et al., 2021 for details.\n\nMPI is typically available via a cluster scheduling system. At the time of  writing, PBS and  SLURM are supported,  and an experimental implementation of LSF is included.  Create an issue if you would like another submission system included. \n\nThe main three steps to run MPI over several machines are given below.  For more information, please read the detailed instructions.\n\nIn the cluster login node, follow the local installation instructions. \nStart Julia in the login node, and perform a one-time setup. Read the documentation at setup_mpi() for more information. \nStill in the Julia REPL running in the login node, use the following syntax:\n\nmpi_run = pigeons(\n    target = toy_mvn_target(1000000), \n    n_chains = 1000,\n    checkpoint = true,\n    on = MPIProcesses(\n        n_mpi_processes = 1000,\n        n_threads = 1))\n\nThis will start a distributed PT algorithm with 1000 chains on 1000 MPIProcesses processes, each using one thread, targeting a one million  dimensional target distribution. On the UBC Sockeye cluster, the last  round of this run (i.e. the last 1024 iterations) takes 10 seconds to complete, versus more than  2 hours if run serially, i.e. a >700x speed-up.  This is reasonably close to the theoretical 1000x speedup, i.e. we see that the communication costs are negligible. \n\nYou can \"watch\" the progress of your job (queue status and  standard output once it is available), using:\n\nwatch(mpi_run)\n\nand cancel/kill a job using \n\nkill_job(mpi_run)\n\nTo analyze the output, see the documentation page on post-processing for MPI runs. In a nutshell, one option is to load the state of the sampler  back to your interactive chain via: \n\npt = Pigeons.load(mpi_run) # possible thanks to 'pigeons(..., checkpoint = true)' used above","category":"section"},{"location":"mpi/#Code-dependencies","page":"Distributed usage (MPI)","title":"Code dependencies","text":"So far we have used examples where the target, explorers, etc  are built-in inside the Pigeons module.  However in typical use cases, some user-provided code needs to be provided to  ChildProcess  and MPIProcesses so that the other participating Julia  processes have access to it.  This is done with the argument dependencies (of type Vector;  present in  both ChildProcess  and MPIProcesses).  Two types of elements can be used in the vector of dependencies, and they can be mixed:\n\nelements of type Module: for each of those, an using statement will be generated in the script used by the child process;\nelements of type String: a path to a Julia file defining functions and types, for each of those an include call is generated. \n\nHere is an example where we run a custom Ising model in a child process:\n\nusing Pigeons\n\n# making the path absolute can be necessary in some contexts:\nising_path = pkgdir(Pigeons) * \"/examples/ising.jl\"\nlazy_path = pkgdir(Pigeons) * \"/examples/lazy-ising.jl\"\n\npigeons(\n    # see examples/lazy-ising.jl why we need Lazy (Documenter.jl-specific issue)\n    target = Pigeons.LazyTarget(Val(:IsingLogPotential)), \n    checkpoint = true,  \n    on = ChildProcess(\n            n_local_mpi_processes = 2,\n            dependencies = [\n                Pigeons, # <- Pigeons itself can be skipped, added automatically\n                ising_path, # <- these are needed for this example to work\n                lazy_path   # <--+\n            ]\n\n        )\n    )\n\nNote the use of LazyTarget(..).  When starting a child process, the arguments of pigeons(...) are used to create  an Inputs struct, which is serialized.  In certain corner cases this serialization may not be possible, for example if the  target depends on external processes, or here due to the fact that Documenter.jl  defines temporary environments (see examples/lazy-ising.jl for details). In these corner cases, you can use a LazyTarget to delay the creation of the  target so that it is performed in the child processes instead of the calling process.\n\nnote: Note\nIn order for the child processes to be able to load the same module versions as  the current process, the current process calls Base.active_project() and  pass that information to the child processes. The child processes will activate  that environment before proceeding to sampling.We therefore assume that the environment given by Base.active_project() is  in working order.","category":"section"},{"location":"mpi/#Details-on-setting-up-Pigeons-with-multi-node-MPI","page":"Distributed usage (MPI)","title":"Details on setting up Pigeons with multi-node MPI","text":"We provide more details here to get Pigeons to work on HPC clusters with MPI,  specifically to  allow Pigeons processes across several machines to communicate with each  other. ","category":"section"},{"location":"mpi/#Understanding-your-HPC-cluster","page":"Distributed usage (MPI)","title":"Understanding your HPC cluster","text":"Read the documentation of your HPC cluster or contact the administrator to  find answers to the following questions:\n\nWhat are the locations in the file system that are shared between nodes?    Which ones are read/write vs read only? \nLogin nodes and compute nodes will often behave differently.    In particular they might have different read/write access in the various volumes. \nAre there HPC modules that need to be loaded to run MPI jobs?\nOptional: Is there a Julia install provided (e.g., vi HPC modules)? \nOptional: is there an example showing how to use MPI.jl? ","category":"section"},{"location":"mpi/#Installing-Julia-on-HPC","page":"Distributed usage (MPI)","title":"Installing Julia on HPC","text":"Check first if an HPC module is available with a recent version of Julia.  If not, it is easy to install  one yourself (no root access needed). We explain how to in this section.\n\nAs of 2024, we have encountered issues with juliaup   on HPC and recommend instead a simple approach:\n\nCreate a bin directory in a volume that is readable on all nodes.    E.g., it could be ~/bin. Go to that directory with cd. \nFollow these instructions,    including the step on how to add Julia to your PATH variable in ~/.bashrc. ","category":"section"},{"location":"mpi/#The-Julia-depot","page":"Distributed usage (MPI)","title":"The Julia depot","text":"Julia's package manager (Pkg.jl) stores a large number of files in a  directory called the Julia depot. Julia will look for the envirnonment variable  JULIA_DEPOT to find that directory. \n\nThe standard approach is to have one such Julia depot per user in a shared (network) drive with read and write access from all nodes.  However, having many files in a shared drive can make the Pkg operations and  pre-compilation extremely slow. If you see this issue, two possible options:\n\nIf your HPC architecture has a burst buffer, this will be a good place to    locate the Julia depot. You may need to request allocation, but it is well worth    doing so as it creates a huge performance boost on Pkg and precompile operations.\nIf no burst buffer is available, and you are experiencing very slow Pkg operations,    a workaround is described in this page.","category":"section"},{"location":"mpi/#Load-MPI-modules","page":"Distributed usage (MPI)","title":"Load MPI modules","text":"During the Pigeons MPI setup process (step below), the MPI library will need  to be loaded in order for Pigeons to find how to bind to it (more precisely, Pigeons will  call MPIPreferences.jl for the binding). \n\nTo see if you need to load extra HPC modules to make MPI available, try which mpiexec: if  that command finds mpiexec,  you are probably good to go and can go to next step, otherwise, read  the cluster documentation or talk to the cluster administrator.\n\nThe HPC modules that need to be loaded are system-dependent, e.g., on certain systems this may look like:\n\nmodule load gcc\nmodule load openmpi\n\nKeep note of the list of HPC modules needed, if any, you will need that information later in the process.","category":"section"},{"location":"mpi/#Setting-up-a-Julia-project","page":"Distributed usage (MPI)","title":"Setting up a Julia project","text":"Your Julia project should be in a volume with read/write access from all nodes. For testing purpose, your Julia project can start as an empty directory, then  cd into that empty directory and start julia.\n\nActivate the project and install Pigeons in it by using:\n\n] activate . \nadd Pigeons","category":"section"},{"location":"mpi/#Setting-up-Pigeons-MPI","page":"Distributed usage (MPI)","title":"Setting up Pigeons MPI","text":"We now need to tell Pigeons how to bind to the HPC's MPI library.  This needs to be done only once per project. ","category":"section"},{"location":"mpi/#Presets","page":"Distributed usage (MPI)","title":"Presets","text":"Look first at the list of clusters that have \"presets\" available, by  typing Pigeons.setup_mpi_ and then tab. These presets are the most straightforward to use. If there is a preset available for your system, just run that command and you  are done! \n\nFor example, on most Digital Research Alliance of Canada HPC clusters (formerly Compute Canada), you can simply use:\n\nPigeons.setup_mpi_compute_canada()","category":"section"},{"location":"mpi/#Calling-[setup_mpi()](@ref)","page":"Distributed usage (MPI)","title":"Calling setup_mpi()","text":"If a preset is not available, manual configuration can be done using  Pigeons.setup_mpi(). To get more information on the  arguments to pass in to Pigeons.setup_mpi(), see MPISettings, but we walk over the main steps here. ","category":"section"},{"location":"mpi/#Submission-system","page":"Distributed usage (MPI)","title":"Submission system","text":"The argument submission_system should specify the queue  submission system. Most popular choices are :pbs and  :slurm. Pigeons will use this information to generate  the queue submission scripts.\n\nOptionally, you can use also add_to_submission to add  extra information in the queue submission script.  See presets.jl for examples of  what these extra pieces of information look like in different clusters (to specify allocation codes, etc). \n\nWhen you submit MPI jobs, you can see the generated script  in results/latest/.submission_script.sh.  Here is an example of what a generated script  looks like if we add  add_to_submission = [\"source ~/bin/zip_depot/bin/load_depot\"],  as needed if you are using the zip_depot utility: \n\n#!/bin/bash\n#SBATCH -t 00:05:00\n#SBATCH --ntasks=2\n#SBATCH --cpus-per-task=1\n#SBATCH --mem-per-cpu=8gb \n\n#SBATCH --job-name=2025-04-09-18-04-55-fltVoqC0\n#SBATCH -o /home/bouchar3/Pigeons.jl/results/all/2025-04-09-18-04-55-fltVoqC0/info/stdout.txt\n#SBATCH -e /home/bouchar3/Pigeons.jl/results/all/2025-04-09-18-04-55-fltVoqC0/info/stderr.txt\nsource ~/bin/zip_depot/bin/load_depot # <-- this is where 'add_to_submission' entries are added\n\ncd $SLURM_SUBMIT_DIR\nmodule load julia/1.11.3\nMPI_OUTPUT_PATH=\"/home/bouchar3/Pigeons.jl/results/all/2025-04-09-18-04-55-fltVoqC0\"\n\nmpiexec --output-filename \"$MPI_OUTPUT_PATH/mpi_out\" --merge-stderr-to-stdout   /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Core/julia/1.11.3/bin/julia -C native -J/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Core/julia/1.11.3/lib/julia/sys.so -g1 --startup-file=no --banner=no --project=/home/bouchar3/Pigeons.jl --threads=1 --compiled-modules=existing /home/bouchar3/Pigeons.jl/results/all/2025-04-09-18-04-55-fltVoqC0/.launch_script.jl","category":"section"},{"location":"mpi/#Environment-modules","page":"Distributed usage (MPI)","title":"Environment modules","text":"The HPC modules you are currently using for the setup phase will need  to be added to the generated submission script, so Pigeons needs to know about them. Add them to the environment_modules argument of  setup_mpi(). \n\nFor example, if earlier you used\n\nmodule load gcc\nmodule load openmpi\n\nthen you do this:  setup_mpi(..., environment_modules = [\"gcc\", \"openmpi\"], ...).","category":"section"},{"location":"mpi/#Library-name","page":"Distributed usage (MPI)","title":"Library name","text":"In most cases, the MPI system library is found automatically, so try  first leaving library_name to its default value of nothing.  If not, see the documentation in MPISettings under  library_name for tricks to find it. Alternatively, you can also get information on  what paths are modified when you load an HPC module using:\n\nmodule show openmpi","category":"section"},{"location":"mpi/#Customizing-the-mpiexec-command","page":"Distributed usage (MPI)","title":"Customizing the mpiexec command","text":"In many HPC clusters, the command mpiexec is used to submit jobs to MPI.  If that is the case for your cluster, skip this step since   this is the default value in Pigeons' generated submission scripts.  In other clusters, a different command is used.  We describe here how to perform this customization if it is necessary. \n\nThe main mechanism is the argument mpiexec specified when calling setup_mpi(),  for example, on some cluster you may need:\n\nPigeons.setup_mpi(\n    mpiexec = \"srun -n \\$SLURM_NTASKS --mpi=pmi2\",\n    ...\n)\n\nMinor note: in order to be able to use the convenience function  watch(), used to show standard output of MPI jobs, you need  to ensure MPI will create output files at the right location.  For mpiexec, this is achieved with the default arguments of mpiexec:  see the source  code of MPISettings for more information. \n\nIf you need to change mpiexec's arguments (or the equivalent customized command) for a single job,  additional arguments  can be provided in the argument mpiexec_args in MPIProcesses. ","category":"section"},{"location":"mpi/#Testing-your-MPI-setup","page":"Distributed usage (MPI)","title":"Testing your MPI setup","text":"Use the following to start MPI over two MPI processes for  quick testing:\n\nusing Pigeons \nresult = pigeons(\n            target = toy_mvn_target(10), \n            on = MPIProcesses(walltime = \"00:05:00\"), \n            checkpoint = true)\n\nThen use: \n\nwatch(result)\n\nTo see the output. You can also look at the following  files to help you troubleshoot potential issues, all found  in results/all/latest (or results/all/[time]/):\n\n.submission_script.sh: the file submitted to the queue,\n.launch_script.jl: the script started on each node,\ninfo/submission_output.txt: the output of submitting the job to the queue,\ninfo/stderr.txt and info/stdout.txt: the slurm/pbs output,\nmpi_out: the mpiexec output, organized by node (note that internally, Pigeons suppresses most output on all nodes except the one at rank 0).  ","category":"section"},{"location":"mpi/#Creating-a-PR-with-your-cluster's-setup","page":"Distributed usage (MPI)","title":"Creating a PR with your cluster's setup","text":"Once you have determined what options to pass in to  setup_mpi, please consider creating a Pull Request (PR)  adding one function in the file  presets.jl. Thank you!","category":"section"},{"location":"input-explorers/#input-explorers","page":"Custom MCMC","title":"Custom explorers","text":"Pigeons have several built-in explorer kernels such as  AutoMALA and a SliceSampler.  However when the state space is neither the reals nor the integers,  or for performance reasons, it may be necessary to create custom  exploration MCMC kernels. ","category":"section"},{"location":"input-explorers/#Creating-a-new-explorer","page":"Custom MCMC","title":"Creating a new explorer","text":"We show how to create a new explorer,  for pedagogy, a simple independence Metropolis algorithm, applied to  our familiar unidentifiable toy example,  based on Julia black-box implementation. \n\nstruct MyIndependenceSampler \n    which_parameter_index::Int\nend\nfunction Pigeons.step!(explorer::MyIndependenceSampler, replica, shared)\n    state = replica.state \n    rng = replica.rng \n    i = explorer.which_parameter_index\n    # Note: the log_potential is an InterpolatedLogPotential between the target and reference\n    log_potential = Pigeons.find_log_potential(replica, shared.tempering, shared)\n    log_pr_before = log_potential(state)\n    # propose\n    state_before = state[i]\n    state[i] = rand(rng) \n    log_pr_after = log_potential(state)\n    # accept-reject step \n    accept_ratio = exp(log_pr_after - log_pr_before) \n    if accept_ratio < 1 && rand(rng) > accept_ratio \n        # reject: revert the move we just proposed\n        state[i] = state_before\n    end # (nothing to do if accept, we work in-place)\nend","category":"section"},{"location":"input-explorers/#Combinations-of-explorers","page":"Custom MCMC","title":"Combinations of explorers","text":"To alternate between two explorers, use Compose: for example continuing on  our example, we want to alternate between sampling the two parameters of our model:\n\npt = pigeons(\n        target = MyLogPotential(100, 50), \n        reference = MyLogPotential(0, 0),\n        explorer = Compose(MyIndependenceSampler(1), MyIndependenceSampler(2))\n    )\nnothing # hide\n\nSimilarly, use Mix to create a mixture of explorers. ","category":"section"},{"location":"input-explorers/#Adaptation","page":"Custom MCMC","title":"Adaptation","text":"We assume the following model for MCMC explorer adaptation: \n\nduring each PT round, statistics are collected distributively, \nat the end of each round, the statistics are reduced and shared, and the explorers are given an opportunity to update based on these statistics. \n\nTo control (1), use explorer_recorder_builders.  For example, AutoMALA requests online statistics to be computed on  uncontrainted parameters to perform pre-conditioning.  By default, explorer_recorder_builders returns an empty list. \n\nTo control (2), use adapt_explorer which is fed the  reduced statistics. By default, adapt_explorer is a no-op. ","category":"section"},{"location":"output-off-memory/#output-off-memory","page":"Off-memory","title":"Off-memory processing","text":"When the dimensionality of a model is large and/or the  number of MCMC samples is large, the samples may not  fit in memory.  In some situations, it may be possible to compute the  output in finite memory, as described in  the online statistics documentation page.  However not all situations admit sufficient statistics and  in this case it is necessary to store samples to disk.  We show here how to do so when pigeons is run on a single  machine, but the interface is similar over MPI and  described in the  MPI sample processing documentation page. ","category":"section"},{"location":"output-off-memory/#Prepare-the-PT-run-with-the-disk-recorder","page":"Off-memory","title":"Prepare the PT run with the disk recorder","text":"Two options need to be enabled.  First, checkpoint = true,  which saves a snapshot at the end of each round in  the directory results/all/[unique directory] and  symlinked to results/latest.  Second, the disk recorder:\n\nusing Pigeons\n\n# example target: a 1000 dimensional target\nhigh_d_target = Pigeons.toy_mvn_target(1000)\n\npt = pigeons(target = high_d_target, \n                checkpoint = true,\n                record = [disk])","category":"section"},{"location":"output-off-memory/#Accessing-the-disk-samples","page":"Off-memory","title":"Accessing the disk samples","text":"Use the function process_sample() which  processes the samples one by one and passes it to  a user-provided function.  Here we will extract the first dimension of  each 1000-dimensional vector:\n\n# load the samples from disk one by one, keeping only the first dimension\nfirst_dim_of_each = Vector{Float64}()\nprocess_sample(pt) do chain, scan, sample # ordered as if we had an inner loop over scans\n    # each sample here is a Vector{Float64} of length 1000 \n    # in general, it will is produced by extract_sample()\n    push!(first_dim_of_each, sample[1])\nend\n\nusing Plots\nplotlyjs()\nmyplot = Plots.plot(first_dim_of_each)\nPlots.savefig(myplot, \"first_dim_of_each.html\"); \nnothing # hide\n\n<iframe src=\"../first_dim_of_each.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"output-off-memory/#Internal-organization-of-the-samples","page":"Off-memory","title":"Internal organization of the samples","text":"This section can be skipped. \n\nThe samples are produced in compressed zip  folders, one for each replica having visited  the target:\n\nreaddir(\"$(pt.exec_folder)/round=10/samples\")\n\nIn the above example we see that only replicas  6 and 7 visited the target. Each zip file  contains serialized .jl files.  This output organization is used to support  concurrent and distributed processing. \n\nInternally, two passes are made, a first one to  index the samples which are shuffled across many files. Then they are visited in the correct  order and passed to the processing function.","category":"section"},{"location":"unidentifiable-example/#unidentifiable-example","page":"Why parallel tempering (PT)?","title":"Why Parallel Tempering (PT)? An example.","text":"Consider a Bayesian model where the likelihood is a binomial distribution with probability parameter p.  Let us consider an over-parameterized model where we  write p = p_1 p_2. Assume that each p_i has a uniform prior on the interval 0 1. This is a toy example of an unidentifiable parameterization. In practice many popular  Bayesian models are unidentifiable. \n\nWhen there are many observations, the posterior of  unidentifiable models concentrate on a sub-manifold,  making sampling difficult, as shown in the following pair plots:\n\n<iframe src=\"../pair_plot.svg\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"unidentifiable-example/#Unidentifiable-example-without-PT","page":"Why parallel tempering (PT)?","title":"Unidentifiable example without PT","text":"Let us look at trace plots obtained from performing  single-chain MCMC on this problem.  The key part of the code below is the argument  n_chains = 1: we have designed our PT implementation  so that setting the number of chains to one reduces to a  standard MCMC algorithm. \n\nusing DynamicPPL\nusing Pigeons\nusing MCMCChains\nusing StatsPlots\nplotlyjs()\n\n# The model described above implemented in Turing\n# note we are using a large observation size here\nan_unidentifiable_model = Pigeons.toy_turing_unid_target(100000, 50000)\n\npt = pigeons(\n        target = an_unidentifiable_model, \n        n_chains = 1, # <- corresponds to single chain MCMC\n        record = [traces])\n\n# collect the statistics and convert to MCMCChains' Chains\nsamples = Chains(pt)\n# create the trace plots\nmy_plot = StatsPlots.plot(samples)\nStatsPlots.savefig(my_plot, \"no_pt_posterior_densities_and_traces.html\"); \nnothing # hide\n\n<iframe src=\"../no_pt_posterior_densities_and_traces.html\" style=\"height:500px;width:100%;\"></iframe>\n\nIt is quite obvious that mixing is poor, as confirmed by effective sample size (ESS) estimates:\n\nsamples","category":"section"},{"location":"unidentifiable-example/#Unidentifiable-example-with-PT","page":"Why parallel tempering (PT)?","title":"Unidentifiable example with PT","text":"Let us enable parallel tempering now, by setting  n_chains to a value greater than one:\n\npt = pigeons(\n        target = an_unidentifiable_model, \n        n_chains = 10, \n        record = [traces, round_trip])\n\n# collect the statistics and convert to MCMCChains' Chains\nsamples = Chains(pt)\n# create the trace plots\nmy_plot = StatsPlots.plot(samples)\nStatsPlots.savefig(my_plot, \"with_pt_posterior_densities_and_traces.html\"); \nnothing # hide\n\n<iframe src=\"../with_pt_posterior_densities_and_traces.html\" style=\"height:500px;width:100%;\"></iframe>\n\nThere is a marked difference.  Thanks to round trips through the reference distribution,  where we can sample iid, we are able to jump at different  parts of the state space. \n\nThis is also confirmed by the PT ESS estimates:\n\nsamples","category":"section"},{"location":"output-online/#output-online","page":"Online stats","title":"Online (constant memory) statistics","text":"When the dimensionality of a model is large and/or the  number of MCMC samples is large, the samples may not  fit in memory.  The most flexible way to deal with this situation is  to write samples to disk and process them one at the time,  as described in the off-memory processing documentation.  However, certain statistics can be computed using fixed  dimensional sufficient statistics yielding more  efficient algorithms. We describe this alternative here. ","category":"section"},{"location":"output-online/#Built-in-online-statistics:-mean-and-variance","page":"Online stats","title":"Built-in online statistics: mean and variance","text":"Simply include the online() recorder to get  access to constant memory computation of the mean and variance.  \n\nusing DynamicPPL\nusing Pigeons\n\n# example target: Binomial likelihood with parameter p = p1 * p2\nan_unidentifiable_model = Pigeons.toy_turing_unid_target(100, 50)\n\npt = pigeons(\n        target = an_unidentifiable_model, \n        record = [online]\n    )\n\nusing Statistics \nmean(pt)\n\nTo be more precise, the online statistics are computed on the  result of calling extract_sample().  Use sample_names() to obtain the description of each  coordinate:\n\nsample_names(pt)","category":"section"},{"location":"output-online/#Including-other-online-statistics","page":"Online stats","title":"Including other online statistics","text":"The computation of online statistics makes use of  OnlineStats.jl. \n\nThe functions mean and var are implemented via the  types Mean and Variance from the  OnlineStats library.  Many other constant-memory statistic accumulators are available in the OnlineStats library.  To add additional constant-memory statistic accumulators,  register them via register_online_type().  Here is an example to add computation of extrema:\n\nusing OnlineStats\n\n# register a type <: OnlineStat to be included\nPigeons.register_online_type(Extrema)\n\npt = pigeons(\n        target = an_unidentifiable_model, \n        record = [online]\n    )\n\nPigeons.get_statistic(pt, :singleton_variable, Extrema)","category":"section"},{"location":"input-julia/#input-julia","page":"Black-box function","title":"Julia code as input to pigeons","text":"In typical Bayesian statistics applications, it is  easiest to specify the model in a modelling language,  such as Turing, but sometimes to get more flexibility or  speed it is useful to implement the density evaluation  manually as a \"black-box\" Julia function. \n\nHere we show how this is done using our familiar unidentifiable toy example.\n\nWe first create a custom type, MyLogPotential to control dispatch on the interface target.\n\nusing Pigeons \nusing Random\nusing Distributions\n\nstruct MyLogPotential \n    n_trials::Int\n    n_successes::Int\nend\n\nNext, we make MyLogPotential a  function-like object, so that we can write expressions of the form my_log_potential([0.5, 0.5]) and  hence MyLogPotential satisfies the log_potential interface:\n\nfunction (log_potential::MyLogPotential)(x) \n    p1, p2 = x\n    if !(0 < p1 < 1) || !(0 < p2 < 1)\n        return -Inf64 \n    end\n    p = p1 * p2\n    return logpdf(Binomial(log_potential.n_trials, p), log_potential.n_successes)\nend\n\n# e.g.:\nmy_log_potential = MyLogPotential(100, 50)\nmy_log_potential([0.5, 0.5])\n\nNext, we need to specify how to create fresh state objects: \n\nPigeons.initialization(::MyLogPotential, ::AbstractRNG, ::Int) = [0.5, 0.5]\n\nWe can now run the sampler:\n\npt = pigeons(\n        target = MyLogPotential(100, 50), \n        reference = MyLogPotential(0, 0)\n    )\nnothing # hide\n\nNotice that we have specified a reference distribution, in this case the same model but with  no observations (hence the prior). Indeed, in contrast to targets specified using  Turing.jl, it is not possible to construct a  reference automatically from Julia \"black-box\" targets. \n\nThe default_explorer() is the SliceSampler. ","category":"section"},{"location":"input-julia/#Sampling-from-the-reference-distribution","page":"Black-box function","title":"Sampling from the reference distribution","text":"Ability to sample from the reference distribution can be beneficial, e.g. to jump modes  in multi-modal distribution.  For black-box Julia function targets, this is done as follows:\n\n\nfunction Pigeons.sample_iid!(::MyLogPotential, replica, shared)\n    state = replica.state \n    rng = replica.rng \n    rand!(rng, state)\nend\n\npt = pigeons(\n        target = MyLogPotential(100, 50), \n        reference = MyLogPotential(0, 0)\n    )\nnothing # hide\n\nNotice that sample_iid!() should provide samples exactly distributed  according to the reference, otherwise several theoretical guarantees of  Parallel Tempering are invalidated. ","category":"section"},{"location":"input-julia/#Changing-the-explorer","page":"Black-box function","title":"Changing the explorer","text":"Here is an example using AutoMALA—a gradient-based sampler—instead of the default  SliceSampler. We'll use the Enzyme backend, a state-of-the-art AD system that supports targets written in plain Julia. Enzyme is considerably faster than the default ForwardDiff, whose main advantage is compatibility  with a broader range of targets. Many other AD backends are supported by the LogDensityProblemsAD.jl interface  (Enzyme, ForwardDiff, Zygote, ReverseDiff, etc).\n\nTo proceed, we only need to add methods to make our custom type MyLogPotential conform to the  LogDensityProblems interface:\n\nusing ADTypes\nusing Enzyme\nusing LogDensityProblems\n\nLogDensityProblems.dimension(lp::MyLogPotential) = 2\nLogDensityProblems.logdensity(lp::MyLogPotential, x) = lp(x)\n\npt = pigeons(\n        target = MyLogPotential(100, 50), \n        reference = MyLogPotential(0, 0), \n        explorer = AutoMALA(default_autodiff_backend = AutoEnzyme())\n    )\nnothing # hide\n\nPigeons have several built-in explorer kernels such as  AutoMALA and a SliceSampler.  However when the state space is neither the reals nor the integers,  or for performance reasons, it may be necessary to create custom  exploration MCMC kernels. This is described on the custom explorers page.","category":"section"},{"location":"input-julia/#Custom-gradients","page":"Black-box function","title":"Custom gradients","text":"In some situations it may be helpful to compute gradients explicitly  (performance, unsupported primitives, etc).  One method to do so is to use autodiff-specific machinery,  see for example the Enzyme documentation.  In addition, Pigeons also has an AD framework-agnostic method to provide  explicit gradients, supporting replica-specific, in-place  buffers (this functionality was developed to support efficient interfacing with Stan).  Using this is demonstrated below:\n\nusing Pigeons\nusing Random\nusing LogDensityProblems\nusing LogDensityProblemsAD\nusing ADTypes\n\nstruct CustomGradientLogPotential\n    precision::Float64\n    dim::Int\nend\nfunction (log_potential::CustomGradientLogPotential)(x)\n    -0.5 * log_potential.precision * sum(abs2, x)\nend\n\nPigeons.initialization(lp::CustomGradientLogPotential, ::AbstractRNG, ::Int) = zeros(lp.dim)\n\nLogDensityProblems.dimension(lp::CustomGradientLogPotential) = lp.dim\nLogDensityProblems.logdensity(lp::CustomGradientLogPotential, x) = lp(x)\n\nLogDensityProblemsAD.ADgradient(\n    ::AbstractADType, \n    log_potential::CustomGradientLogPotential, \n    replica::Pigeons.Replica\n    ) = Pigeons.BufferedAD(log_potential, replica.recorders.buffers)\n\nconst check_custom_grad_called = Ref(false)\n\nfunction LogDensityProblems.logdensity_and_gradient(log_potential::Pigeons.BufferedAD{CustomGradientLogPotential}, x)\n    logdens = log_potential.enclosed(x)\n    global check_custom_grad_called[] = true\n    log_potential.buffer .= -log_potential.enclosed.precision .* x\n    return logdens, log_potential.buffer\nend\n\npigeons(\n    target = CustomGradientLogPotential(2.1, 4), \n    reference = CustomGradientLogPotential(1.1, 4), \n    n_chains = 1,\n    n_rounds = 5,\n    explorer = AutoMALA())\n\n@assert check_custom_grad_called[]\n\nnothing # hide","category":"section"},{"location":"input-julia/#Manipulating-the-output","page":"Black-box function","title":"Manipulating the output","text":"Some  common post-processing are shown below, see the section on output processing for more information. \n\nusing MCMCChains\nusing StatsPlots\nplotlyjs()\n\npt = pigeons(\n        target = MyLogPotential(100, 50), \n        reference = MyLogPotential(0, 0), \n        explorer = AutoMALA(default_autodiff_backend = AutoEnzyme()),\n        record = [traces])\nsamples = Chains(pt)\nmy_plot = StatsPlots.plot(samples)\nStatsPlots.savefig(my_plot, \"julia_posterior_densities_and_traces.html\"); \n\nsamples\n\n<iframe src=\"../julia_posterior_densities_and_traces.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"about-us/#about","page":"About Us","title":"The Pigeons Team - About Us","text":"Planning for the Pigeons project started taking place in the summer of 2022.  Since then, we have grown as a team and have added various features to the software.  We still have great ambitions and a swath of features to add; if you would like  to become a part of our team feel free to reach out!","category":"section"},{"location":"about-us/#Team-Members-(chronological-order)","page":"About Us","title":"Team Members (chronological order)","text":"note: Note\nWe are recruiting graduate students! Click here for more information.\n\n<div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n    <img src=\"https://raw.githubusercontent.com/Julia-Tempering/Pigeons.jl/27ee86b8e0827ba9e7eead6374960ba8673e1006/docs/img/alex.png\" alt=\"Alexandre Bouchard-Côté\" style=\"width: 100px; height: 100px; border-radius: 50%; margin-right: 20px;\">\n    <div>\n        <b>Alexandre Bouchard-Côté</b>\n        </br>\n        University of British Columbia \n    </div>\n</div>\n\n<div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n    <img src=\"https://raw.githubusercontent.com/Julia-Tempering/Pigeons.jl/27ee86b8e0827ba9e7eead6374960ba8673e1006/docs/img/nikola.jpg\" alt=\"Nikola Surjanovic\" style=\"width: 100px; height: 100px; border-radius: 50%; margin-right: 20px;\">\n    <div>\n        <b>Nikola Surjanovic</b>\n        </br>\n        University of British Columbia \n    </div>\n</div>\n\n<div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n    <img src=\"https://raw.githubusercontent.com/Julia-Tempering/Pigeons.jl/27ee86b8e0827ba9e7eead6374960ba8673e1006/docs/img/paul.jpg\" alt=\"Paul Tiede\" style=\"width: 100px; height: 100px; border-radius: 50%; margin-right: 20px;\">\n    <div>\n        <b>Paul Tiede</b>\n        </br>\n        Harvard University, Event Horizon Telescope\n    </div>\n</div>\n\n<div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n    <img src=\"https://raw.githubusercontent.com/Julia-Tempering/Pigeons.jl/27ee86b8e0827ba9e7eead6374960ba8673e1006/docs/img/saif.jpg\" alt=\"Saifuddin Syed\" style=\"width: 100px; height: 100px; border-radius: 50%; margin-right: 20px;\">\n    <div>\n        <b>Saifuddin Syed</b>\n        </br>\n        University of Oxford \n    </div>\n</div>\n\n<div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n    <img src=\"https://raw.githubusercontent.com/Julia-Tempering/Pigeons.jl/27ee86b8e0827ba9e7eead6374960ba8673e1006/docs/img/trevor.jpg\" alt=\"Trevor Campbell\" style=\"width: 100px; height: 100px; border-radius: 50%; margin-right: 20px;\">\n    <div>\n        <b>Trevor Campbell</b>\n        </br>\n        University of British Columbia \n    </div>\n</div>\n\n<div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n    <img src=\"https://raw.githubusercontent.com/Julia-Tempering/Pigeons.jl/27ee86b8e0827ba9e7eead6374960ba8673e1006/docs/img/miguel.jpg\" alt=\"Miguel Biron-Lattes\" style=\"width: 100px; height: 100px; border-radius: 50%; margin-right: 20px;\">\n    <div>\n        <b>Miguel Biron-Lattes</b>\n        </br>\n        University of British Columbia \n    </div>\n</div>\n\n<div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n    <img src=\"https://raw.githubusercontent.com/Julia-Tempering/Pigeons.jl/27ee86b8e0827ba9e7eead6374960ba8673e1006/docs/img/william.png\" alt=\"William Thompson\" style=\"width: 100px; height: 100px; border-radius: 50%; margin-right: 20px;\">\n    <div>\n        <b>William Thompson</b>\n        </br>\n        Herzberg Astronomy and Astrophysics Research Centre\n    </div>\n</div>\n\n<div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n    <img src=\"https://raw.githubusercontent.com/Julia-Tempering/Pigeons.jl/27ee86b8e0827ba9e7eead6374960ba8673e1006/docs/img/yujia.jpg\" alt=\"Yujia Ma\" style=\"width: 100px; height: 100px; border-radius: 50%; margin-right: 20px;\">\n    <div>\n        <b>Yujia Ma</b>\n        </br>\n        University of British Columbia \n    </div>\n</div>\n\n<div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n    <img src=\"https://raw.githubusercontent.com/Julia-Tempering/Pigeons.jl/27ee86b8e0827ba9e7eead6374960ba8673e1006/docs/img/lucas.jpg\" alt=\"Lucas Wong\" style=\"width: 100px; height: 100px; border-radius: 50%; margin-right: 20px;\">\n    <div>\n        <b>Lucas Wong</b>\n        </br>\n        University of British Columbia \n    </div>\n</div>\n\n<div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n    <img src=\"https://raw.githubusercontent.com/Julia-Tempering/Pigeons.jl/27ee86b8e0827ba9e7eead6374960ba8673e1006/docs/img/son.jpg\" alt=\"Son Luu\" style=\"width: 100px; height: 100px; border-radius: 50%; margin-right: 20px;\">\n    <div>\n        <b>Son Luu</b>\n        </br>\n        University of British Columbia \n    </div>\n</div>\n\n<div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n    <img src=\"https://github.com/Julia-Tempering/doc-assets/blob/master/team/seren.jpg?raw=true\"\n    alt=\"Seren Lee\" style=\"width: 100px; height: 100px; border-radius: 50%; margin-right: 20px;\">\n    <div>\n        <b>Seren Lee</b>\n        </br>\n        University of British Columbia \n    </div>\n</div>","category":"section"},{"location":"correctness/#Correctness-checks-for-distributed/parallel-algorithms","page":"Correctness checks","title":"Correctness checks for distributed/parallel algorithms","text":"It is notoriously difficult to implement correct parallel/distributed algorithms.  One strategy we use to address this is to guarantee that the code will output  precisely the same output no matter how many threads/machines are used.  We describe how this is done under the hood in the page Distributed PT. \n\nIn practice, how is this useful? Let us say you developed a new target and you would like to make sure that it works correctly in a multi-threaded environment. To do so, add a flag to indicate to \"check\" one of the PT rounds as follows, and  enable checkpointing\n\nusing Pigeons\npigeons(target = toy_mvn_target(100), checked_round = 3, checkpoint = true)\nnothing # hide\n\nThe above line does the following: the PT algorithm will pause at the end of round 3, spawn  a separate process with only one thread in it, run 3 rounds of PT with the same  Inputs object in it, and verify that the checkpoints of the single-threaded run  is identical to   the one that ran in the main process. If not, an error will be raised with some  information on where the discrepancy comes from.  Try to pick the checked round to be small enough that it does not dominate the running time  (since it runs in single-threaded, single-process mode), but big enough to achieve  the same code coverage as the full algorithm. Setting it to zero (or omitting the argument),  disables this functionality.\n\nDid the code above actually use many threads? This depends on the value of Threads.nthreads(). Julia currently does not allow you to change this value at  runtime, so for convenience we provide the following way to run the job in a  child process with a set number of Julia threads:\n\npt_result = pigeons(target = toy_mvn_target(100), multithreaded = true, checked_round = 3, checkpoint = true, on = ChildProcess(n_threads = 4))\n\nNotice that we also add the flag multithreaded = true, to instruct Pigeons to use  the multiple threads available to parallelize exploration across chains (in other use cases,  parallelization might get used internally e.g. to parallelize likelihood evaluation).\n\nHere the check passed successfully as expected. But what  if you had a third-party target distribution that is not multi-threaded friendly?  For example some code sometimes write in global variables or  other non-thread safe constructs. In such situation, you can still use your thread-naive  target over MPI processes.  For example, if the thread-unsafety comes from the use of global variables, then each  process will have its own copy of the global variables. \n\nnote: Failed equality check\nIf you are using a custom struct that is either mutable or containing  mutables, it is possible that the check will fail even if your implementation is sound. This is caused by == dispatching === on your type, which is too strict for the purpose of comparing two deserialized checkpoints. See recursive_equal for instructions on how to prevent this behavior.","category":"section"},{"location":"correctness/#Correctness-checks-of-MCMC-kernels","page":"Correctness checks","title":"Correctness checks of MCMC kernels","text":"Pigeons offers a tool, the Exact Invariance Test (EIT), to help validating  correctness of MCMC kernels. It formulates an hypothesis test where the  null hypothesis is that the provided explorer kernel is  invariant with respect to the target distribution. For details, see  Bouchard-Côté, 2022, Section 10.5 or this tutorial. \n\nUsing EIT is as simple as defining a Bayesian model with a proper prior  using the Turing syntax, and then calling invariance_test(): \n\nusing Pigeons\nusing Distributions\nusing DynamicPPL \nusing HypothesisTests \n\n# note: observation should not be an argument of the Turing model\nDynamicPPL.@model function some_generative_model(n_trials)\n    p1 ~ Uniform()\n    p2 ~ Uniform()\n    n_successes ~ Binomial(n_trials, p1*p2)\n    return n_successes\nend\n\nmodel = some_generative_model(100)\ntarget = TuringLogPotential(model)\nexplorer = SliceSampler()\ntest_result = Pigeons.invariance_test(\n                target, \n                explorer;\n                condition_on=(:n_successes,))\n\n@assert test_result.passed\nnothing # hide\n\nEIT checks for invariance but not irreducibility.  Being able to check invariance irrespective of irreducibility is beneficial: for example if a Gibbs sampler has two moves, one can then test each in isolation  each of the two moves. Moreover,   in case of failure, we can determine which of the two moves would be problematic. ","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Descriptions of informal interfaces.\n\n","category":"section"},{"location":"interfaces/#explorer","page":"Interfaces","title":"explorer","text":"","category":"section"},{"location":"interfaces/#Description","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract","page":"Interfaces","title":"Contract","text":"Pigeons.step!()\nPigeons.adapt_explorer()\nPigeons.explorer_recorder_builders()\n\n","category":"section"},{"location":"interfaces/#log_potential","page":"Interfaces","title":"log_potential","text":"","category":"section"},{"location":"interfaces/#Description-2","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"Pigeons.create_reference_log_potential()\n\n","category":"section"},{"location":"interfaces/#log_potentials","page":"Interfaces","title":"log_potentials","text":"","category":"section"},{"location":"interfaces/#Description-3","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-2","page":"Interfaces","title":"Contract","text":"Pigeons.log_unnormalized_ratio()\nPigeons.n_chains()\n\n","category":"section"},{"location":"interfaces/#pair_swapper","page":"Interfaces","title":"pair_swapper","text":"","category":"section"},{"location":"interfaces/#Description-4","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-3","page":"Interfaces","title":"Contract","text":"Pigeons.swap_stat()\nPigeons.record_swap_stats!()\nPigeons.swap_decision()","category":"section"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-2","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"Pigeons.TestSwapper()\n\n","category":"section"},{"location":"interfaces/#path","page":"Interfaces","title":"path","text":"","category":"section"},{"location":"interfaces/#Description-5","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-4","page":"Interfaces","title":"Contract","text":"Pigeons.interpolate()","category":"section"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-3","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"Pigeons.InterpolatingPath()\nPigeons.ScaledPrecisionNormalPath()\n\n","category":"section"},{"location":"interfaces/#recorder","page":"Interfaces","title":"recorder","text":"","category":"section"},{"location":"interfaces/#Description-6","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-5","page":"Interfaces","title":"Contract","text":"Pigeons.record!()","category":"section"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-4","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"Pigeons.timing_extrema()\nPigeons.round_trip()\nPigeons.energy_ac1()\nPigeons.log_sum_ratio()\nPigeons._transformed_online()\nPigeons.traces()\nPigeons.allocation_extrema()\nPigeons.reversibility_rate()\nPigeons.explorer_acceptance_pr()\nPigeons.swap_acceptance_pr()\nPigeons.explorer_n_steps()\nPigeons.disk()\nPigeons.index_process()\nPigeons.online()\n\n","category":"section"},{"location":"interfaces/#recorder_builder","page":"Interfaces","title":"recorder_builder","text":"","category":"section"},{"location":"interfaces/#Description-7","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#recorders","page":"Interfaces","title":"recorders","text":"","category":"section"},{"location":"interfaces/#Description-8","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-6","page":"Interfaces","title":"Contract","text":"Pigeons.record_if_requested!()","category":"section"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-5","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"Pigeons.create_recorders()\n\n","category":"section"},{"location":"interfaces/#replicas","page":"Interfaces","title":"replicas","text":"","category":"section"},{"location":"interfaces/#Description-9","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-7","page":"Interfaces","title":"Contract","text":"Pigeons.swap!()\nPigeons.locals()\nPigeons.load()\nPigeons.communicator()\nPigeons.entangler()","category":"section"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-6","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"Pigeons.create_entangled_replicas()\nPigeons.create_replicas()\nPigeons.create_vector_replicas()\n\n","category":"section"},{"location":"interfaces/#state","page":"Interfaces","title":"state","text":"","category":"section"},{"location":"interfaces/#Description-10","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-8","page":"Interfaces","title":"Contract","text":"Pigeons.continuous_variables()\nPigeons.discrete_variables()\nPigeons.variable()\nPigeons.update_state!()\nPigeons.extract_sample()\nPigeons.sample_names()\n\n","category":"section"},{"location":"interfaces/#swap_graph","page":"Interfaces","title":"swap_graph","text":"","category":"section"},{"location":"interfaces/#Description-11","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-9","page":"Interfaces","title":"Contract","text":"Pigeons.partner_chain()\nPigeons.is_reference()\nPigeons.is_target()\n\n","category":"section"},{"location":"interfaces/#swap_graphs","page":"Interfaces","title":"swap_graphs","text":"","category":"section"},{"location":"interfaces/#Description-12","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-10","page":"Interfaces","title":"Contract","text":"Pigeons.create_swap_graph()","category":"section"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-7","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"Pigeons.deo()\nPigeons.variational_deo()\n\n","category":"section"},{"location":"interfaces/#target","page":"Interfaces","title":"target","text":"","category":"section"},{"location":"interfaces/#Description-13","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-11","page":"Interfaces","title":"Contract","text":"Pigeons.initialization()\nPigeons.default_explorer()\nPigeons.default_reference()\nPigeons.sample_iid!()\nPigeons.create_path()","category":"section"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-8","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"Pigeons.toy_mvn_target()\n\n","category":"section"},{"location":"interfaces/#tempering","page":"Interfaces","title":"tempering","text":"","category":"section"},{"location":"interfaces/#Description-14","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-12","page":"Interfaces","title":"Contract","text":"Pigeons.adapt_tempering()\nPigeons.tempering_recorder_builders()\nPigeons.create_pair_swapper()\nPigeons.find_log_potential()","category":"section"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-9","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"Pigeons.create_tempering()\n\n","category":"section"},{"location":"interfaces/#variational","page":"Interfaces","title":"variational","text":"","category":"section"},{"location":"interfaces/#Description-15","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/#Contract-13","page":"Interfaces","title":"Contract","text":"Pigeons.activate_variational()\nPigeons.update_reference!()\nPigeons.variational_recorder_builders()","category":"section"},{"location":"interfaces/#Pigeons.explorer","page":"Interfaces","title":"Pigeons.explorer","text":"Orchestrate the explore!() phase  of Parallel Tempering. This is the part of the algorithm  where each replica performs MCMC moves targeting its annealed  distribution. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.log_potential","page":"Interfaces","title":"Pigeons.log_potential","text":"A log_potential encodes a probability distribution, where only the  un-normalized probability density function is known. \n\nTo make MyType conform to this informal interface, implement \n\n(log_potential::MyType)(x)\n\nwhich should return the log of the un-normalized density.\n\nFor example, we provide this behaviour for any distribution  in Distributions.jl. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.log_potentials","page":"Interfaces","title":"Pigeons.log_potentials","text":"An encoding of a discrete set of probability distributions, where only the un-normalized  probability density functions are known.  Each distribution is allowed to have a different normalization constant. \n\nFor example, we provide this behaviour for any Vector containing log_potential's. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.pair_swapper","page":"Interfaces","title":"Pigeons.pair_swapper","text":"Informs swap!() of how to perform a swap between a given pair of chains.\n\nThis is done in two steps:\n\nUse swap_stat() to extract sufficient statistics needed to make a swap decision. \nGiven these statistics for the two chains, swap_decision() then perform the swap.\n\nThe rationale for breaking this down into two steps is that in a distributed swap context, swap!() will take care of transmitting the sufficient statistics over the network if necessary.\n\nThe function record_swap_stats!() is used to record information about swapping,  in particular mean swap acceptance probabilities.\n\nA default implementation of all of pair_swapper's methods is provided,  where the pair_swapper is assumed to follow the log_potentials interface.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.path","page":"Interfaces","title":"Pigeons.path","text":"A continuum of log_potential's interpolating between two end-points. More precisely, a mapping from [0, 1] to the space of probability distributions.\n\nThe main use of this interface is to pass it to discretize().\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.recorder","page":"Interfaces","title":"Pigeons.recorder","text":"Accumulate a specific type of statistic, for example  by keeping constant size sufficient statistics  (via OnlineStat, which conforms this interface),  storing samples to a file, etc. \n\nIn addition to the contract below, a recorder should support \n\nBase.merge()\nBase.empty!()\n\nSee also recorders.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.recorder_builder","page":"Interfaces","title":"Pigeons.recorder_builder","text":"A function such that calling it returns a fresh  recorder.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.recorders","page":"Interfaces","title":"Pigeons.recorders","text":"A NamedTuple containing several recorder's.  Each recorder is responsible for a type of statistic to be  accumulated (e.g. one for swap accept prs, one for round trip  info; some are in-memory, some are on file). \n\nDuring PT execution, each recorders object keep track of only the  statistics for one replica (for thread safety and/or  distribution purpose). After a PT round, reduce_recorders!() is used to do  a reduction before  accessing statistic values. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.replicas","page":"Interfaces","title":"Pigeons.replicas","text":"Stores the process' replicas.  Since we provide MPI implementations, do not assume that this will contain all the replicas, as  others can be located in other processes/machines\n\nImplementations provided\n\nEntangledReplicas: an MPI-based implementation\nVector{Replica}: single-process case (above can handle that case, but the array based implementation is non-allocating)\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.state","page":"Interfaces","title":"Pigeons.state","text":"The state held in each Parallel Tempering Replica.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.swap_graph","page":"Interfaces","title":"Pigeons.swap_graph","text":"Informs swap!() about which chain will interact with which.\n\nThese are instantiated by swap_graphs. \n\nCanonical example is the standard Odd and Even swap. Extension point for e.g. \n\nparallel parallel tempering,\nvariational methods with more than 2 legs,\nPT algorithms dealing with more than one target simultaneously for the purpose of model selection. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.swap_graphs","page":"Interfaces","title":"Pigeons.swap_graphs","text":"Creates one swap_graph for each communication  iteration.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.target","page":"Interfaces","title":"Pigeons.target","text":"The probability distribution of interest. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.tempering","page":"Interfaces","title":"Pigeons.tempering","text":"Orchestrate the communicate!() phase  of Parallel Tempering. \n\nIn addition to the methods in the contract below,  we also assume the presence of the following fields:\n\nlog_potentials\nswap_graphs\ncommunication_barriers\npath\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Pigeons.variational","page":"Interfaces","title":"Pigeons.variational","text":"A variational family of reference distributions.  Implementations should also satisfy the log_potential  contract and sample_iid!(). \n\n\n\n\n\n","category":"constant"},{"location":"parallel/#Parallelization","page":"Parallelization","title":"Parallelization","text":"","category":"section"},{"location":"parallel/#Parallel-exploration","page":"Parallelization","title":"Parallel exploration","text":"When multithreaded = true is activated, several threads will be used  concurrently to perform sampling.  The number of threads will be the minimum of the number of chains  and Threads.nthreads():\n\nusing Pigeons\npigeons(\n    target = toy_mvn_target(100), \n    n_chains = 2,\n    multithreaded = true)\n\nSince changing Threads.nthreads() requires restarting the Julia  session, a convenient way to call pigeons with a different number  of threads is to use on = ChildProcess(...) as described  in running MPI locally.","category":"section"},{"location":"gsoc/#gsoc","page":"Pigeons Projects - Google Summer of Code","title":"Pigeons Projects - Google Summer of Code","text":"","category":"section"},{"location":"gsoc/#Solving-Optimization-Problems-with-Pigeons","page":"Pigeons Projects - Google Summer of Code","title":"Solving Optimization Problems with Pigeons","text":"Annealing-based methods have shown promising performance both within the context  of sampling (e.g., parallel tempering MCMC) and optimization (e.g., simulated annealing).  Currently, Pigeons only supports annealing methods for sampling and the recent theory  developed for non-reversible parallel tempering methods applies to these sampling algorithms. The goal of this project would be to develop and implement new algorithms  for solving optimization problems within the Pigeons framework. Work on this project would include: \n\nExtending the Pigeons interface to allow users to solve general optimization problems.\nPerforming simulations to understand the advantages and limitations of annealing-based methods for optimization. Conducting a literature review to collect examples of optimization problems where annealing-based methods would be useful.\nUnderstanding the theoretical underpinnings of annealing for optimization and using past insights to develop and implement new algorithms within the Pigeons package. \n\nRecommended Skills: Familiarity with Julia and/or Python.  A basic knowledge of optimization algorithms and a moderate level of mathematical maturity. \n\nExpected Results: A new interface in Pigeons to allow users to solve general optimization problems,  as well as an implementation of new annealing-based optimization algorithms. \n\nMentors: Alexandre Bouchard-Côté,  Trevor Campbell, and  Nikola Surjanovic.\n\nExpected Project Size: 175 hours or 350 hours. \n\nDifficulty: Medium to Hard, depending on the chosen tasks.","category":"section"},{"location":"gsoc/#Library-of-Difficult-Sampling-Problems","page":"Pigeons Projects - Google Summer of Code","title":"Library of Difficult Sampling Problems","text":"The fields of Bayesian statistical inference and statistical physics abound with  difficult sampling problems. In the field of machine learning, it is common to compare  methods across several standard data sets.  In contrast, such collections of standard data sets and models do not exist or  are limited in scope in the field of statistics. (For example, the current, most commonly used library of difficult sampling problems,  posteriordb, does not emphasize  difficult distributions such as non-log-concave targets.) Work on this project would include:\n\nSearching for difficult sampling problems in the literature and implementing some examples in Julia.\nNumerical experiments to compare the performance of Pigeons with other state-of-the-art sampling algorithms.\n\nRecommended Skills: Familiarity with Julia, Markdown, and some basics of website development.  A basic knowledge of statistical concepts. A desire to learn about the parallel tempering algorithm.\n\nExpected Results: A collection of difficult sampling problems and implementations in Julia. \n\nMentors: Alexandre Bouchard-Côté,  Trevor Campbell, and  Nikola Surjanovic.\n\nExpected Project Size: 175 hours or 350 hours. \n\nDifficulty: Easy to Medium, depending on the chosen tasks.","category":"section"},{"location":"gsoc/#Automated-Families-for-Variational-Inference-and-MCMC","page":"Pigeons Projects - Google Summer of Code","title":"Automated Families for Variational Inference and MCMC","text":"The core algorithm behind Pigeons, parallel tempering, has recently had major developments.  In particular, recent work combines variational inference methods with  parallel tempering to improve the performance of both.  At the moment, Pigeons only implements basic variational families (e.g., mean-field Gaussians).  Work on this project would include:\n\nIncorporating new and existing variational families within Pigeons. \nAutomated selection of variational families depending on the given computational problem. \nExperimental comparison of the performance of various variational families on \n\ngiven computational tasks.\n\nRecommended Skills: Familiarity with Julia.  A basic knowledge of Bayesian statistical concepts. A desire to learn about parallel tempering and variational inference. \n\nExpected Results: An implementation of a rich collection of variational families within Pigeons,  and an automated variational family selection procedure. \n\nMentors: Alexandre Bouchard-Côté,  Trevor Campbell, and  Nikola Surjanovic.\n\nExpected Project Size: 175 hours or 350 hours. \n\nDifficulty: Medium to Hard, depending on the chosen tasks.","category":"section"},{"location":"gsoc/#Python-and-R-Interface-for-Pigeons","page":"Pigeons Projects - Google Summer of Code","title":"Python and R Interface for Pigeons","text":"Pigeons allows users to scale their Bayesian computation on up to thousands of  machines. At the moment, the only available API is through the Julia programming  language. To reach a wider audience, we would like to extend this to Python and R. Work on this project would include: \n\nDevelopment of a new Pigeons interface in Python and/or R.\nTesting of the new interface to ensure identical output to Julia.  \nEngaging with researchers interested in using a Python/R interface and implementing additional suggested features. \n\nRecommended Skills: Familiarity with Python and/or R. A basic knowledge of  statistical concepts and a desire to learn the basics of Julia and Bayesian inference.\n\nExpected Results: An interface for Pigeons in either Python or R (or both). \n\nMentors: Alexandre Bouchard-Côté,  Trevor Campbell, and  Nikola Surjanovic.\n\nExpected Project Size: 175 hours or 350 hours. \n\nDifficulty: Medium.","category":"section"},{"location":"gsoc/#guidance","page":"Pigeons Projects - Google Summer of Code","title":"Contributor Guidance","text":"Potential contributors are encouraged to provide a short CV or resume.\n\nAfter selecting one of the projects listed on this page, in your application please also include: \n\nA list of goals for each week of your participation in the program. \nHow our team can best support you during your Google Summer of Code experience.  \n\nParticipants are also allowed to propose their own modifications to projects listed on this page.  If you plan to moderately deviate from the project proposals listed here, please also  describe your plan in the application and contact the listed mentors or organization  administrators beforehand.","category":"section"},{"location":"openings/#openings","page":"Openings","title":"PhD and MSc Positions","text":"Interested in spending a MSc or PhD developing new, impactful inference methodologies? We have several fully funded openings for PhD and MSc students in Statistics, thanks  to a CANSSI Collaborative Research Teams grant. ","category":"section"},{"location":"openings/#Key-benefits-for-trainees","page":"Openings","title":"Key benefits for trainees","text":"Collaborate with scientists and engineers working on important and challenging problems. \nMobility and co-supervision possible across top Canadian universities. Generous travel funding to attend international meetings. \nGenerous stipend and benefits. ","category":"section"},{"location":"openings/#Partner-institutions-and-points-of-contact","page":"Openings","title":"Partner institutions and points of contact","text":"Alexandre Bouchard-Côté (UBC)\nTrevor Campbell (UBC)\nPhilippe Gagnon (UdeM)\nLiangliang Wang (SFU)","category":"section"},{"location":"openings/#How-to-apply","page":"Openings","title":"How to apply","text":"Submit a PhD, PhD Track, or MSc application to at least one of the partner institutions: UBC Statistics, UdeM Mathematics and Statistics, SFU Statistics (application to more than one permitted and encouraged). \nGet in touch by email with the point of contact person(s) you are applying to.\nUse email subject Pigeons CRT Graduate Application\nInclude as attachment:\nCV \nUp-to-date transcripts\nOne representative publication if available\nGithub identifier and link to a Github repository you have contributed, if available.","category":"section"},{"location":"output-inferencereport/#output-inferencereport","page":"Automated reports","title":"Automated reports","text":"InferenceReport is a Julia package to automatically generate a web page or PDF report from   Pigeons' output, containing common plots and diagnostics. \n\nWe provide a brief summary on how to use InfereReport here, see  the full InferenceReport documentation for details. ","category":"section"},{"location":"output-inferencereport/#Install-InferenceReport","page":"Automated reports","title":"Install InferenceReport","text":"using Pkg; Pkg.add(\"InferenceReport\")","category":"section"},{"location":"output-inferencereport/#Basic-usage","page":"Automated reports","title":"Basic usage","text":"using InferenceReport\nusing Pigeons \n\npt = pigeons(\n        target = toy_mvn_target(2), \n        n_rounds = 4,\n        record = [traces; round_trip; record_default()])\n\nreport(pt) \nnothing # hide\n\nThis will generate an HTML report with various useful diagnostic  plots and open it in your default browser. \n\nExamples available here.","category":"section"},{"location":"output-numerical/#output-numerical","page":"Numerical","title":"Numerical outputs and diagnostics","text":"Use sample_array() to convert target chain  samples into a format that can then be consumed by the  third party package  MCMCChains.jl.  We outline some useful features here, read   the MCMCChains.jl documentation for more information.","category":"section"},{"location":"output-numerical/#Quick-summary-of-ESS,-moments,-etc","page":"Numerical","title":"Quick summary of ESS, moments, etc","text":"Make sure to have the third party packages DynamicPPL and MCMCChains installed via \n\nusing Pkg; Pkg.add(\"DynamicPPL\", \"MCMCChains\")\n\nAlso make sure to record the trace, with record = [traces]:\n\nusing DynamicPPL\nusing Pigeons\nusing MCMCChains\n\n# example target: Binomial likelihood with parameter p = p1 * p2\nan_unidentifiable_model = Pigeons.toy_turing_unid_target(100, 50)\n\npt = pigeons(\n        target = an_unidentifiable_model, \n        record = [traces; round_trip; record_default()]\n    )\n\n# collect the statistics and convert to MCMCChains' Chains\n# to have axes labels matching variable names in Turing and Stan\nsamples = Chains(pt)\n\nsamples","category":"section"},{"location":"output-numerical/#Accessing-individual-diagnostics-and-summaries","page":"Numerical","title":"Accessing individual diagnostics and summaries","text":"Computing a mean  (but see online statistics for  a constant memory alternative):\n\nusing Statistics \nm = mean(samples)\n\nto access an individual entry in this example and the following ones:\n\nm[:p1, :mean]\n\nHighest posterior density interval:\n\nhpd(samples, alpha = 0.05)\n\nFor ESS estimates:\n\ness(samples)","category":"section"},{"location":"checkpoints/#checkpoints-page","page":"Checkpoints","title":"Checkpoints","text":"Pigeons can write a \"checkpoint\" periodically  to ensure that not more than half of the work is lost in  the event of e.g. a server failure. This is enabled as follows:\n\nusing Pigeons\npt = pigeons(target = toy_mvn_target(100), checkpoint = true)\n\nSee write_checkpoint() for details of how this  is accomplished in a way compatible to both the single-machine  and MPI contexts.  Each checkpoint is located in  results/all/[unique folder]/round=[x]/checkpoint,  with the latest run in results/latest/[unique folder]/round=[x]/checkpoint. \n\nCheckpoints are also useful when an MPI-distributed PT has been  ran, and the user wants to load the full set of  results in one interactive session. \n\nTo load a checkpoint, create a PT struct by passing in the path  string to the checkpoint folder, for example to re-load the latest checkpoint  from the latest run and perform more sampling:\n\npt = PT(\"results/latest\")\n\n# do two more rounds of sampling\npt = increment_n_rounds!(pt, 2)\npt = pigeons(pt)\nnothing # hide\n\nThis is useful when you realize you will need more CPUs or machines to  help. Continuing on the above example, we will now do one more round, but  this time using 2 local MPI processes:\n\npt = increment_n_rounds!(pt, 1)\nresult = pigeons(pt.exec_folder, ChildProcess(n_local_mpi_processes = 2))\nnothing # hide\n\nWe conclude with an example showing that it is not necessary to load  the PT object into the interactive node in order to increase the number of rounds:\n\nnew_exec_folder = increment_n_rounds!(result.exec_folder, 1)\nresult = pigeons(new_exec_folder, ChildProcess(n_local_mpi_processes = 2))\nnothing # hide","category":"section"},{"location":"checkpoints/#Large-immutable-data","page":"Checkpoints","title":"Large immutable data","text":"If part of a target is a large immutable object, it is  wasteful to have all the machines write it at each round.  To avoid this, encapsulate the  large immutable object  into an Immutable struct. \n\nFor an example where this is used, see here.","category":"section"},{"location":"developers/#Creating-a-release-from-a-PR","page":"For developers","title":"Creating a release from a PR","text":"Create a new branch locally.\nMake changes, and make sure all tests pass locally.\nWhen done, push the branch to the repo and create a PR. Make sure all tests pass on CI.\nYour PR will be reviewed by the team.\nAfter the review, but before merging, make sure to bump the version in Project.toml. Follow this convention.\nMerge the PR (and possibly delete the branch where you did your work).\nNavigate to the merge commit (hint: this should be on the main branch!) and make the comment @JuliaRegistrator register. See here for an example.\nIf all goes well, the bots will take it from here. After the Julia registry merges our release PR, TagBot will create a tag for the release automatically.","category":"section"},{"location":"developers/#Creating-a-release-without-a-PR","page":"For developers","title":"Creating a release without a PR","text":"Do step 7 above with the latest commit on main (example).","category":"section"},{"location":"developers/#Running-tests","page":"For developers","title":"Running tests","text":"See test/README.md.","category":"section"},{"location":"developers/#Generating-documentation","page":"For developers","title":"Generating documentation","text":"See docs/README.md.","category":"section"},{"location":"developers/#Adding-a-submission-system-(beyond-SLURM,-PBS,-etc,-or-variant-thereof)","page":"For developers","title":"Adding a submission system (beyond SLURM, PBS, etc, or variant thereof)","text":"Add an entry in the \"rosetta stone\" of submission systems (see SubmissionSyntax):\n\nusing Pigeons\n\nPigeons._rosetta\n\nThen, specify how resource strings are constructed by  creating a new dispatch of resource_string(). \n\nOnce you have tested it, please submit a Pull Request!","category":"section"},{"location":"input-nonjulian/#input-nonjulian","page":"Non-julian MCMC","title":"Targeting a non-Julian model","text":"Suppose you have some code implementing vanilla MCMC, written in an arbitrary \"foreign\" language such as C++, Python, R, Java, etc. You would like to turn this vanilla MCMC code into a Parallel Tempering algorithm able to harness large numbers of cores, including distributing this algorithm over MPI. However, you do not wish to learn anything about MPI/multi-threading/Parallel Tempering.\n\nSurprisingly, it is very simple to bridge such code with Pigeons. The only requirement on the \"foreign\" language is that it supports reading the standard in and writing to the standard out, hence virtually any languages can be interfaced in this fashion. Based on this minimalist \"standard stream bridge\" with worker processes running foreign code (one such process per replica; not necessarily running on the same machine), Pigeons will coordinate the execution of an adaptive non-reversible parallel tempering algorithm.\n\nThis behaviour is implemented in StreamTarget, see its documentation for details.  In a nutshell, there will be one child process for each PT chain. These processes will not necessarily be on  the same machine: indeed distributed sampling is the key use case of this bridge.  Pigeons will do some  lightweight coordination with these child processes to orchestrate non-reversible parallel tempering.  Interprocess communication only involves pigeons telling each child process  to perform exploration at a pigeons-provided annealing parameter. \n\nStreamTarget implements log_potential and explorer  by invoking worker processes via standard stream communication. The standard stream is less efficient than alternatives such as  protobuff, but it has the advantage of being supported by nearly all  programming languages in existence.  Also in many practical cases, since the worker  process is invoked only three times per chain per iteration, it is unlikely to be the bottleneck (overhead is in the order of 0.1ms per interprocess call).  ","category":"section"},{"location":"input-nonjulian/#Usage-example","page":"Non-julian MCMC","title":"Usage example","text":"To demonstrate this capability, we show  here how it enables running Blang models in  pigeons.  Blang is a Bayesian modelling language designed  for sampling combinatorial spaces such as  phylogenetic trees. \n\nWe first setup Blang as follows (assuming Java 11 is accessible in the PATH variable):\n\nusing Pigeons\n\nredirect_stdout(devnull) do\n    Pigeons.setup_blang(\"blangDemos\") \nend\n\nNext, we run a   Blang implementation of  our usual unidentifiable toy example:\n\nusing Pigeons\n\nblang_unidentifiable_example(n_trials, n_successes) = \n    Pigeons.BlangTarget(\n        `$(Pigeons.blang_executable(\"blangDemos\", \"demos.UnidentifiableProduct\")) --model.nTrials $n_trials --model.nFails $n_successes`\n    )\npt = pigeons(target = blang_unidentifiable_example(100, 50))\nnothing # hide\n\nAs shown above, create a StreamTarget amounts to specifying which command will  be used to create a child process. \n\nTo terminate the child processes associated with a stream target, use:\n\nPigeons.kill_child_processes(pt)","category":"section"},{"location":"output-traces/#output-traces","page":"Traces","title":"Saving traces","text":"The traces refer to the list of samples X_1 X_2 dots X_n from which we can approximate expectations of the form  Ef(X), where X sim pi via  a Monte Carlo average of the form sum_i f(X_i)  n. \n\nTo indicate that the traces should be saved, use\n\nusing DynamicPPL\nusing Pigeons\n\ntarget = Pigeons.toy_turing_unid_target(100, 50)\n\npt = pigeons(;  target, \n                n_rounds = 3,\n                # make sure to record the trace:\n                record = [traces; round_trip; record_default()])\n\nNote that there are more memory efficient alternatives  to saving the full traces: see  online (constant-memory) statistics and off-memory processing.","category":"section"},{"location":"output-traces/#Accessing-traces","page":"Traces","title":"Accessing traces","text":"Use get_sample to access the list of samples:\n\nget_sample(pt)\n\nIn the special case where each state is a vector, use  sample_names to obtain description of the  vector components:\n\nsample_names(pt)\n\nStill in the special case where each state is a vector,  it is often convenient to organize the result into a single  array, this is done using sample_array:\n\nsample_array(pt)","category":"section"},{"location":"output-traces/#Customizing-what-is-saved-in-the-traces","page":"Traces","title":"Customizing what is saved in the traces","text":"You may want to save only some statistics of interest, or a subset of the dimensions to  take up less memory. \n\nWe show here an example saving only the  value of the first coordinate:\n\nstruct OnlyFirstExtractor end \n\nPigeons.extract_sample(state, log_potential, extractor::OnlyFirstExtractor) = \n    Pigeons.extract_sample(state, log_potential)[1:1]\n\n\npt = pigeons(;  target, \n                n_rounds = 3,\n                # custom method to extract samples:\n                extractor = OnlyFirstExtractor(),\n                # make sure to record the trace:\n                record = [traces; round_trip; record_default()])\n\nsample_array(pt)\n\nOptionally, it is a good idea to also adjust the behaviour  of sample_names accordingly. For example, variables_names gets called  when creating MCMCChains object so that e.g. plots are labelled correctly.\n\nPigeons.sample_names(state, log_potential, extractor::OnlyFirstExtractor) = \n    Pigeons.sample_names(state, log_potential)[1:1]\n\nTo keep only the value of the log potential, you can use the following built-in LogPotentialExtractor:\n\npt = pigeons(;  target, \n                n_rounds = 3,\n                # custom method to extract samples:\n                extractor = Pigeons.LogPotentialExtractor(),\n                # make sure to record the trace:\n                record = [traces; round_trip; record_default()])\n\nsample_array(pt)","category":"section"},{"location":"pt/","page":"More on PT","title":"More on PT","text":"We provide in this page an overview of Non-Reversible Parallel Tempering (PT),  Syed et al., 2021,  linking it with some key parts of the code base. \n\nnote: Note\nRead this page if you are interested in extending Pigeons or  understanding how it works under the hood.  Reading this page is not required to use Pigeons, for that instead refer to the  user guide. ","category":"section"},{"location":"pt/#PT-augmented-state-space,-replicas","page":"More on PT","title":"PT augmented state space, replicas","text":"Let X_n denote a Markov chain on state space mathscrX with stationary distribution pi.  PT is a Markov chain defined on the augmented state space mathscrX^N, hence  a state has the form boldsymbolX = (X^(1) X^(2) dots X^(N)).  Each component of boldsymbolX is stored in a struct called a Replica. \n\nThe storage of the vector of replicas boldsymbolX, is done via the informal  interface replicas. In the context of PT running on one computer,  replicas is implemented with a Vector{Replica}. In the context  of running PT distributed across several communicating machines, replicas  is implemented via EntangledReplicas, which stores the parts of  boldsymbolX that are local to that machine as well as data structures  required to communicate with the other machines. \n\nInternally, PT operates on a discrete set of distributions,  pi_1 pi_2 dots pi_N, where N can be obtained using n_chains().  We use the terminology chain to refer to an index i of pi_i. Typically, pi_N coincides with the distribution of interest pi (called the \"target\"), while  pi_1 is a tractable approximation that will help PT efficiently explore the  state space (called the \"reference\").  More broadly, we assume a subset of the chains (determined by is_target()) coincide with the target, and that a subset of the chains (determined by  is_reference()) support  efficient exploration such as i.i.d. sampling or a rapid mixing kernel. \n\nPT is designed so that its stationary distribution is boldsymbolpi = pi_1 times pi_2 times dots pi_N.  As a result, subsetting each sample to its component corresponding to pi_N = pi,  and applying an integrable function f to each, will lead under weak assumptions  to Monte Carlo averages that converge to the expectation of interest Ef(X) for  X sim pi.","category":"section"},{"location":"pt/#Outline-of-local-exploration-and-communication","page":"More on PT","title":"Outline of local exploration and communication","text":"PT alternates between two phases, each boldsymbolpi-invariant: the local  exploration phase and the communication phase. Informally, the first phase attempts to achieve  mixing for the univariate statistics pi_i(X^(i)), while the second phase attempts to  translate well-mixing of these univariate statistics into global mixing of X^(i) by  leveraging the reference distribution(s).","category":"section"},{"location":"pt/#Local-exploration","page":"More on PT","title":"Local exploration","text":"In the local exploration phase, each Replica's state is modified using a pi_i-invariant kernel,  where i is given by Replica.chain. Often, Replica.chain corresponds to  an annealing parameter beta_i but this need not be the case (see  e.g. Baragatti et al., 2011). The kernel can either modify Replica.state in-place, or modify the  Replica's state field. The key interface controlling local exploration, explorer, is  described in more detail below. ","category":"section"},{"location":"pt/#Communication","page":"More on PT","title":"Communication","text":"In the communication phase, PT proposes swaps between pairs of replicas.  These swaps allow each replica's state to periodically visit reference chains. During these reference visits, the state can move around the space quickly.  In principle, there are two equivalent ways to do a swap: the Replicas could exchange  their state fields; or alternatively, they could exchange their chain fields. Since we provide distributed implementations, we use the latter as it ensures that  the amount of data that needs to be exchanged between two machines during a swap  can be made very small (two floats).  It is remarkable that this cost does not vary with the dimensionality of the state space,  in constrast to the naive implementation which would transmit states over the network. See Distributed PT for more information on our distributed implementation.\n\nBoth in distributed and single process mode,  swaps are performed using the function swap!(). \n\nThe key interface controlling communication, tempering, is  described in more detail below. ","category":"section"},{"location":"pt/#A-tour-of-the-PT-meta-algorithm","page":"More on PT","title":"A tour of the PT meta-algorithm","text":"A generalized version of Algorithm 1 (\"one round of PT\") in Syed et al., 2021  is implemented in Pigeons in run_one_round!(),  while the complete algorithm (\"several adaptive rounds\"),  Algorithm 4 of Syed et al., 2021,  has a generalized implementation in pigeons(). \n\nIn the following we discuss different facets of these (meta-)algorithms.","category":"section"},{"location":"pt/#Storage-in-PT-algorithms","page":"More on PT","title":"Storage in PT algorithms","text":"The information stored in the execution of pigeons()  is grouped in the struct PT.  The key fields are one pointing to a replicas and  one to a Shared.  Briefly, replicas will store information distinct in each  MPI process, and read-write during each  round, while Shared is identical in all MPI processes, read only during a round, and updated only between  rounds. \n\nTo orchestrate the creation of PT structs, Inputs is used. Inputs fully determines the execution of a  PT algorithm (target distribution, random seed, etc). ","category":"section"},{"location":"pt/#collecting-statistics","page":"More on PT","title":"Collecting statistics: recorder and recorders","text":"Two steps are needed to collect statistics from the execution of a PT algorithm: \n\nSpecifying which statistics to collect using one or several recorder_builder    (e.g. by    default, only some statistics that can be computed in constant memory  are included,    those that have growing memory consumption, e.g. tracking the full    index process as done here, need to be explicitly specified in advance).\nThen at the end of run_one_round!(), reduce_recorders!()   is called to compile the statistics collected  by the different replicas.\n\nAn object responsible for accumulating all different types of statistics for  one replica is called a  recorders. An object accumulating one  type of statistic for one replica is a recorder.  Each replica has a single recorders to ensure thread safety (e.g., see  the use of a parallel local exploration phase using @thread in explore!()) and to enable distributed  computing. ","category":"section"},{"location":"pt/#Using-a-built-in-[recorder](@ref)","page":"More on PT","title":"Using a built-in recorder","text":"To see the list of built-in implementations of recorder, see the section \"Examples of functions..\" at recorder. \n\nTo specify you want to use one recorder, specify it in the Vector  argument recorder_builders in Inputs. For example, to signal you want  to save the full index process, use:\n\nusing Pigeons\n\npt = pigeons(target = toy_mvn_target(1), record = [index_process]);\nnothing # hide\n\nYou can then access the index process via \n\npt.reduced_recorders.index_process","category":"section"},{"location":"pt/#Creating-your-own-[recorder](@ref)","page":"More on PT","title":"Creating your own recorder","text":"The following pieces are needed\n\nPick or create a struct MyStruct that will hold the information. \nImplement all the methods in the section \"Contract\" of recorder making sure to type the recorder argument as recorder::MyStruct. Some examples are in the same source file as recorder and/or in the same folder as recorder.jl.   \nCreate a recorder_builder which is simply a function such \n\nthat when called with zero argument, creates your desired type, i.e.  MyStruct. The name of this function will define the name of your recorder.","category":"section"},{"location":"pt/#Local-[explorer](@ref)","page":"More on PT","title":"Local explorer","text":"Typical target distributions are expected to take care of building  their own explorers, so most users are not expected to have to  write their own. But for non-standard target it is useful to be  able to do so. \n\nBuilding a new explorer is done as follows: first, suppose you are planning to use a non-standard target of type MyTargetType\n\nPick or create a struct MyExplorerStruct that may contain adaptation   information such as step sizes for HMC or proposal bandwidth.   Note that explorers will need to explore not only the target   distribution pi but also the intermediate ones pi_i.\nImplement all the methods in the section \"Contract\" of explorer making sure to type the explorer argument as explorer::MyExplorerStruct. Some examples are in the same folder as the source file of explorer.  \nDefine a method default_explorer(target::MyTargetType) which   should return a fresh MyExplorerStruct instance. \n\nOne explorer struct will be shared by all threads, so it should be  read-only during execution of run_one_round!().  It can be adapted between rounds. ","category":"section"},{"location":"pt/#Tempering","page":"More on PT","title":"Tempering","text":"Customizing communicate!() follows the same general steps as custom explorers, i.e.:\n\nPick or create a struct MyTemperingStruct that may contain adaptation   information such as schedule optimization. \nImplement all the methods in the section \"Contract\" of tempering making sure to type the tempering argument as tempering::MyTemperingStruct. For example, see NonReversiblePT. \nInitial construction of the tempering is done via  create_tempering().","category":"section"},{"location":"output-custom-types/#output-custom-types","page":"Custom types","title":"Output for custom types","text":"Much of the discussion on sample post-processing  so far has focussed on cases where state's  are real or integer  vectors. \n\nWe discuss here how to post-process samples when the states  are not real or integer vectors (\"custom types\").","category":"section"},{"location":"output-custom-types/#Example-of-custom-state","page":"Custom types","title":"Example of custom state","text":"As a concrete example, we consider an implementation of  an Ising model where a state contains a matrix of  binary variables as well as some other caches.  The full example can be found here,  the only snippet needed from this file needed to understand the following is:\n\nmutable struct IsingState \n    matrix::BitMatrix \n    [some cache variable, etc...]\nend","category":"section"},{"location":"output-custom-types/#Flattening-into-a-vector","page":"Custom types","title":"Flattening into a vector","text":"The sample_array function is convenient but it assumes that the variables are real or integer  vectors (the latter coerced into the former). \n\nSometimes, custom types can be \"flattened\" into a real vector.  For example, a 2D Ising grid can be reshaped into a vector using  vec().\n\nTo perform flattening, add a dispatch to Pigeons' extract_sample.  Here is how this would be done for the same Ising example as above:\n\ninclude(\"../../examples/ising.jl\")\n\nPigeons.extract_sample(state::IsingState, log_potential) = copy(vec(state.matrix))\n\npt = pigeons(target = IsingLogPotential(1.0, 2), record = [traces])\n\nusing MCMCChains\nusing StatsPlots\n\nsamples = Chains(sample_array(pt))\nmy_plot = StatsPlots.plot(samples)\nStatsPlots.savefig(my_plot, \"posterior_densities_and_traces_ising.html\"); \nnothing # hide\n\nThis plots the 4 components of a two-by-two Ising model:\n\n<iframe src=\"../posterior_densities_and_traces_ising.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"output-custom-types/#Trace-processing-without-flattening","page":"Custom types","title":"Trace processing without flattening","text":"It is also possible to process in-memory traces without flattening.  To do so, the function extract_sample should still be extended to  perform a copy of the relevant parts of the state.  Then to access the trace, use get_sample:\n\ninclude(\"../../examples/ising.jl\")\n\nPigeons.extract_sample(state::IsingState, log_potential) = copy(state.matrix)\n\npt = pigeons(target = IsingLogPotential(1.0, 2), record = [traces])\n\nvector = get_sample(pt)\n\n# a vector of 2^10 samples, each extracted into a BitMatrix:\nlength(vector), eltype(vector) ","category":"section"},{"location":"pluto/#Instructions-for-remote-Pluto-execution","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"Simplest method: connect to server via VSCode. Then \n\njulia\n;\ncd examples\n[ctrl-c]\n]activate .\nusing Pluto\nPluto.run()\n\nAnd this will open a browser window. \n\nLonger route without VSCode:\n\nOn the server:\n\njulia\nusing Pluto\nPluto.run(port = 1234)\n\nOn the client:\n\nssh sockeye -N -L 1234:localhost:1234\n\nOpen a browser in the client and go to http://localhost:1234/.  Look at the server terminal to get the \"secret\" part  of the URL. ","category":"section"},{"location":"pluto/#Various-tricks","page":"Instructions for remote Pluto execution","title":"Various tricks","text":"","category":"section"},{"location":"pluto/#Killing-zombies","page":"Instructions for remote Pluto execution","title":"Killing zombies","text":"On the client:\n\nlsof -i :1234","category":"section"},{"location":"pluto/#Force-reload-a-cell","page":"Instructions for remote Pluto execution","title":"Force reload a cell","text":"Ctrl-a followed by Shift-Enter","category":"section"},{"location":"pluto/#Misc","page":"Instructions for remote Pluto execution","title":"Misc","text":"","category":"section"},{"location":"pluto/#TableOfContents()","page":"Instructions for remote Pluto execution","title":"TableOfContents()","text":"","category":"section"},{"location":"pluto/#Wider:","page":"Instructions for remote Pluto execution","title":"Wider:","text":"html\"\"\"<style>\nmain {\n    max-width: 1000px;\n}\n\"\"\"","category":"section"},{"location":"pluto/#Sharing-github-hosted-html","page":"Instructions for remote Pluto execution","title":"Sharing github hosted html","text":"https://raw.githack.com/","category":"section"},{"location":"input-turing/#input-turing","page":"Turing.jl model","title":"Turing.jl model as input to pigeons","text":"To target the posterior distribution specified by  a Turing.jl model first load Turing or DynamicPPL and use TuringLogPotential:\n\nusing DynamicPPL, Pigeons, Distributions\n\nDynamicPPL.@model function my_turing_model(n_trials, n_successes)\n    p1 ~ Uniform(0, 1)\n    p2 ~ Uniform(0, 1)\n    n_successes ~ Binomial(n_trials, p1*p2)\n    return n_successes\nend\n\nmy_turing_target = TuringLogPotential(my_turing_model(100, 50))\npt = pigeons(target = my_turing_target);\nnothing # hide\n\nAt the moment, only Turing models with fixed dimensionality are supported. Both real and integer-valued random variables are supported.  For a TuringLogPotential, the default_explorer() is the SliceSampler and the default_reference() is the  prior distribution encoded in the Turing model. ","category":"section"},{"location":"input-turing/#Gradient-based-sampling-with-[AutoMALA](@ref)","page":"Turing.jl model","title":"Gradient-based sampling with AutoMALA","text":"For Turing models with fully continuous state-spaces—as is the case for my_turing_model defined above—AutoMALA can be an effective alternative to SliceSampler—especially for high-dimensional problems. Because Turing targets conform to the LogDensityProblemsAD.jl  interface, Automatic Differentiation (AD) backends can be used to obtain the gradients needed by AutoMALA.\n\nThe default AD backend for AutoMALA is ForwardDiff. However, Turing supports other backends that may exhibit improved performance.  One such is Mooncake, which  we can use in Pigeons via\n\nusing ADTypes, Mooncake\npt = pigeons(\n    target = my_turing_target,\n    explorer = AutoMALA(default_autodiff_backend = AutoMooncake(nothing))\n);\nnothing # hide\n\nAlternatively, in the special case when the Turing model does not involve branching  decisions (if, while, etc...) depending on latent variables,  ReverseDiff with compiled tape may provide accelerated performance. Since my_turing_target satisfies this criterion, we can use AutoMALA with the ReverseDiff AD backend via\n\nusing ADTypes, ReverseDiff\npt = pigeons(\n    target = my_turing_target,\n    explorer = AutoMALA(default_autodiff_backend = AutoReverseDiff(compile=true))\n);\nnothing # hide","category":"section"},{"location":"input-turing/#Using-DynamicPPL.@addlogprob!","page":"Turing.jl model","title":"Using DynamicPPL.@addlogprob!","text":"The macro DynamicPPL.@addlogprob! is sometimes used when additional flexibility is needed while incrementing the log probability. To do so with Pigeons.jl, you will need to enclose the call to DynamicPPL.@addlogprob! within an if statement as shown below. Failing to do so will lead to invalid results.\n\nDynamicPPL.@model function my_turing_model(my_data)\n    # code here\n    if DynamicPPL.leafcontext(__context__) !== DynamicPPL.PriorContext() \n        DynamicPPL.@addlogprob! logpdf(MyDist(parms), my_data)\n    end\nend","category":"section"},{"location":"input-turing/#Manipulating-the-output","page":"Turing.jl model","title":"Manipulating the output","text":"Internally, Turing target's states (of type DynamicPPL.TypedVarInfo) are stored in an unconstrained  parameterization provided by Turing  (for example, bounded support variables are mapped to the full real line).  However, sample post-processing functions such as sample_array() and process_sample()  convert back to the original (\"constrained\") parameterization via extract_sample(). \n\nAs a result parameterization issues can be essentially ignored when post-processing, for example some  common post-processing are shown below, see the section on output processing for more information. \n\nusing MCMCChains\nusing StatsPlots\nplotlyjs()\n\npt = pigeons(target = my_turing_target, record = [traces])\nsamples = Chains(pt)\nmy_plot = StatsPlots.plot(samples)\nStatsPlots.savefig(my_plot, \"turing_posterior_densities_and_traces.html\"); \n\nsamples\n\n<iframe src=\"../turing_posterior_densities_and_traces.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"input-turing/#Custom-initialization","page":"Turing.jl model","title":"Custom initialization","text":"It is sometimes useful to provide a custom initialization, for example to start in a feasible region.  This can be done as follows:\n\nusing DynamicPPL, Pigeons, Distributions, Random\n\nDynamicPPL.@model function toy_beta_binom_model(n_trials, n_successes)\n    p ~ Uniform(0, 1)\n    n_successes ~ Binomial(n_trials, p)\n    return n_successes\nend\n\nfunction toy_beta_binom_target(n_trials = 10, n_successes = 2)\n    return Pigeons.TuringLogPotential(toy_beta_binom_model(n_trials, n_successes))\nend\n\nconst ToyBetaBinomType = typeof(toy_beta_binom_target())\n\nfunction Pigeons.initialization(target::ToyBetaBinomType, rng::AbstractRNG, ::Int64) \n    result = DynamicPPL.VarInfo(rng, target.model, DynamicPPL.SampleFromPrior(), DynamicPPL.PriorContext())\n    result = DynamicPPL.link(result, target.model)\n\n    # custom init goes here: for example here setting the variable p to 0.5\n    Pigeons.update_state!(result, :p, 1, 0.5)\n\n    return result\nend\n\npt = pigeons(target = toy_beta_binom_target(), n_rounds = 0)\n@assert Pigeons.variable(pt.replicas[1].state, :p) == [0.5]","category":"section"},{"location":"output-pt/#output-pt","page":"PT diagnostics","title":"Parallel Tempering-specific diagnostics","text":"We describe how to produce some key  non-reversible parallel tempering diagnostics  described in Syed et al., 2021. ","category":"section"},{"location":"output-pt/#Global-communication-barrier","page":"PT diagnostics","title":"Global communication barrier","text":"The global communication barrier can be used  to set the number of chains.  The theoretical framework of Syed et al., 2021   yields that under simplifying assumptions, it is optimal to set the number of chains  (the argument n_chains in Inputs or  pigeons()) to roughly 2Λ.\n\nThe global communication barrier is shown  at each round and can also be accessed via  global_barrier().\n\nusing DynamicPPL\nusing Pigeons\n\npt = pigeons(target = Pigeons.toy_turing_unid_target(100, 50))\nPigeons.global_barrier(pt)\n\nWhen both a fixed and variational are used, they are printed separately,  labelled Λ and Λ_var for the fixed and variational global barriers  respectively:\n\nusing DynamicPPL\nusing Pigeons\n\npt = pigeons(target = Pigeons.toy_turing_unid_target(100, 50), \n                variational = GaussianReference(),\n                n_chains_variational = 10)\nnothing # hide","category":"section"},{"location":"output-pt/#Round-trips-and-tempered-restarts","page":"PT diagnostics","title":"Round trips and tempered restarts","text":"A tempered restart happens when a sample from the reference  percolates to the target.  When the reference supports iid sampling, tempered restarts  can enable large jumps in the state space. \n\nA round-trip happens when we have a full cycle from  reference to target and back to reference. \n\nTo count tempered restarts and round trips,  add the round_trip() recorder:\n\npt = pigeons(target = Pigeons.toy_turing_unid_target(100, 50), \n           record = [round_trip; record_default()])\nnothing # hide\n\nThe values can also be accessed as follows:\n\nPigeons.n_tempered_restarts(pt), Pigeons.n_round_trips(pt)","category":"section"},{"location":"output-pt/#Local-communication-barrier","page":"PT diagnostics","title":"Local communication barrier","text":"When the global communication barrier is large,  many chains may be required to obtain tempered restarts. \n\nThe local communication barrier can be used to  visualize the cause of a high global communication barrier.  For example, if there is a sharp peak close to a  reference constructed from the prior, it may be  useful to switch to a variational approximation.\n\nThe local barrier can be plotted as follows:\n\nusing Plots \nplotlyjs()\nmyplot = plot(pt.shared.tempering.communication_barriers.localbarrier);\nsavefig(myplot, \"local_barrier_plot.html\"); \nnothing # hide\n\n<iframe src=\"../local_barrier_plot.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"output-pt/#Index-process","page":"PT diagnostics","title":"Index process","text":"The index process tracks the permutation of chains as machine exchange  annealing parameters. Each row is a chain and each connected line corresponds to a replica. To enable this we use the index_process recorder:\n\npt = pigeons(\n        target = toy_mvn_target(1), \n        record = [index_process], \n        n_rounds = 5)\nmyplot = plot(pt.reduced_recorders.index_process)\nsavefig(myplot, \"index_process_plot.html\"); \nnothing # hide\n\n<iframe src=\"../index_process_plot.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"reference/#Types-and-functions","page":"Reference","title":"Types and functions","text":"","category":"section"},{"location":"reference/#Pigeons.registered_online_types","page":"Reference","title":"Pigeons.registered_online_types","text":"OnlineStat types to be computed when the [online()]  recorder is enabled. \n\n\n\n\n\n","category":"constant"},{"location":"reference/#Pigeons.AAPS","page":"Reference","title":"Pigeons.AAPS","text":"The Apogee to Apogee Path Sampler (AAPS) by Sherlock et al. (2022). \n\nAAPS is a simple alternative to the No U-Turn Sampler (NUTS). It serves a similar purpose as NUTS: the method should be robust to its choice  of tuning parameters when compared to standard HMC. For a given starting position and momentum (x, v), AAPS explores both forward and  backward trajectories. The trajectories are divided into segments, with  segments being separated by apogees (local maxima) in the energy landscape  of -log pi(x). The tuning parameter K defines the number of segments to explore. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Augmentation","page":"Reference","title":"Pigeons.Augmentation","text":"A state augmentation used by explorers. Internally, it hijacks the recorders  machinery to store (usually volatile) data in a Replica. This helps with writing allocation-light code by pre-allocating objects inside the Augmentation, while avoiding race-conditions between replicas. For an application, see buffers.\n\ncontents: The payload. Can be nothing for efficiency purposes.\n\nserialize: When it is volatile, i.e. can be reconstructed on the fly and is only stored for efficiency purpose, it is not worth serializing it\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.AutoMALA","page":"Reference","title":"Pigeons.AutoMALA","text":"The Metropolis-Adjusted Langevin Algorithm with automatic step size selection.\n\nBriefly, at each iteration, the step size is exponentially shrunk or grown until the acceptance rate is in a reasonable range. A reversibility check ensures that the move is reversible with respect to the target. The process is started at step_size, which at the end of each round is set to the average exponent used across all chains.\n\nThe number of steps per exploration is set to base_n_refresh * ceil(Int, dim^exponent_n_refresh).\n\nAt each round, an empirical diagonal marginal standard deviation matrix is estimated. At each step, a random interpolation between the identity and the estimated standard deviation is used to condition the problem.\n\nIn normal circumstance, there should not be a need for tuning, however the following optional keyword parameters are available:\n\nbase_n_refresh: The base number of steps (equivalently, momentum refreshments) between swaps. This base number gets multiplied by ceil(Int, dim^(exponent_n_refresh)).\n\nexponent_n_refresh: Used to scale the increase in number of refreshment with dimensionality.\n\ndefault_autodiff_backend: The default backend to use for autodiff. See https://github.com/tpapp/LogDensityProblemsAD.jl#backends\nCertain targets may ignore it, e.g. if a manual differential is offered or when calling an external program such as Stan.\n\nstep_size: Starting point for the automatic step size algorithm. Gets updated automatically between each round.\n\npreconditioner: A strategy for building a preconditioner.\n\nestimated_target_std_deviations: This gets updated after first iteration; initially nothing in which case an identity mass matrix is used.\n\nReference: Biron-Lattes, M., Surjanovic, N., Syed, S., Campbell, T., & Bouchard-Côté, A.. (2024).  autoMALA: Locally adaptive Metropolis-adjusted Langevin algorithm.  Proceedings of The 27th International Conference on Artificial Intelligence and Statistics,  in Proceedings of Machine Learning Research 238:4600-4608.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.BlangTarget","page":"Reference","title":"Pigeons.BlangTarget","text":"A StreamTarget delegating exploration to  Blang worker processes.\n\nusing Pigeons\n\nPigeons.setup_blang(\"blangDemos\", \"UBC-Stat-ML\") # pre-compile the blang models in the github repo UBC-Stat-ML/blangDemos\npigeons(target = Pigeons.blang_ising());\n\nType Pigeons.blang followed by tab to find other examples. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.BufferedAD","page":"Reference","title":"Pigeons.BufferedAD","text":"Holds a buffer for in-place auto-differentiation.  For example, used by stan log potentials. \n\nFields: \n\nenclosed:  A struct satisfying the LogDensityProblems informal interface.\nbuffer:  The buffer used for in-place gradient computation.\nlogd_buffer:  A buffer for logdensity eval.\nerr_buffer:  A buffer to hold error flags.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ChildProcess","page":"Reference","title":"Pigeons.ChildProcess","text":"Flag to run to a new julia  process. Useful e.g. to dynamically control  the number of threads to use or to use MPI on a  single machine. \n\nFields: \n\nn_threads: The number of threads to provide in the child julia process, the same as the current process by default.\n\ndependencies: Julia modules (if of type Module) or paths to include (if of type String) needed by the child process.\n\nn_local_mpi_processes: If greater than one, run the code locally over MPI using that many MPI processes. In most cases, this is useful only for debugging purpose, as multi-threading should typically perform better. This could also potentially be useful if using a third-party target distribution which somehow does not support multi-threading.\n\nwait: If wait is false, the process runs asynchronously. When wait is false, the process' I/O streams are directed to devnull.\n\nmpiexec_args: Extra arguments passed to mpiexec.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Compose","page":"Reference","title":"Pigeons.Compose","text":"A deterministic composition of two explorers.  E.g. Compose(SliceSampler(), AutoMALA())\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.DiagonalPreconditioner","page":"Reference","title":"Pigeons.DiagonalPreconditioner","text":"Constructs a diagonal preconditioner using the estimated precisions of the samples  from the previous round.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.DistributionLogPotential","page":"Reference","title":"Pigeons.DistributionLogPotential","text":"Provides a reference type for Pigeons based on an encapsulated Distribution type.\n\ndist: The encapsulated distribution.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.EntangledReplicas","page":"Reference","title":"Pigeons.EntangledReplicas","text":"An implementation of replicas for distributed PT.  Contains:\n\nlocals: The subset of replicas hosted in this process\n\nchain_to_replica_global_indices: A specialized distributed array that maps chain indices to replica indices (global indices). This corresponds to the mapping boldsymbolj in line 2 of Algorithm 5 in Syed et al, 2021.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Entangler","page":"Reference","title":"Pigeons.Entangler","text":"Assume all the MPI processes linked by this communicator  will all call the key operations listed below the same number of times  in their lifetime, at logically related occasions (e.g. a set  number of times per iteration for algorithms running the  same number of iterations). We call these 'occasions' a micro-iteration.\n\nThis datastructure keeps track internally of appropriate unique  tags to coordinate the communication between MPI processes  without having to do any explicit synchronization. \n\nThis struct contains:\n\ncommunicator: An MPI Comm object (or nothing if a single process is involved).\n\nload: How a set of tasks or \"global indices\" are distributed across processes.\n\ncurrent_received_bits: An internal datastructure used during MPI calls.\n\nn_transmits: The current micro-iteration. Do not rely on it to count logical steps as it is reset to zero after transmit_counter_bound micro-iterations to avoid underflows to negative tags which cause MPI to crash.\n\ntransmit_counter_bound: Calculated from MPI.tagub and nglobal_indices to ensure MPI tags stay valid (i.e. do not overflow into negative values).\n\nThe key operations supported:\n\ntransmit() and transmit!(): encapsulates    pairwise communications in which each MPI process is holding     a Vector, the elements of which are to be permuted across the processes.\nall_reduce_deterministically and reduce_deterministically,    to perform MPI collective reduction while maintaining the    Parallelism Invariance property.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.FromCheckpoint","page":"Reference","title":"Pigeons.FromCheckpoint","text":"Flag create_replicas (and related functions) that replicas  should be loaded from a checkpoint. Fields:\n\ncheckpoint_folder\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.GaussianReference","page":"Reference","title":"Pigeons.GaussianReference","text":"A Gaussian mean-field variational reference (i.e., with a diagonal covariance matrix).\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.IdentityPreconditioner","page":"Reference","title":"Pigeons.IdentityPreconditioner","text":"Uses the identity as preconditioner. Equivalent to no preconditioning.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Indexer","page":"Reference","title":"Pigeons.Indexer","text":"A bijection between integers and some type T.  T is assumed to have consistent hash and ==. The two sides of the bijection can be obtained with the fields:\n\ni2t: A Vector mapping integers to objects t of type T.\n\nt2i: A Dict mapping objects t of type T to integers.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Indexer-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T","page":"Reference","title":"Pigeons.Indexer","text":"Indexer(i2t)\n\n\nCreate an Indexer with the given Int to T mapping.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.Inputs","page":"Reference","title":"Pigeons.Inputs","text":"A Base.@kwdef struct  used to create Parallel Tempering algorithms. \n\nFields (see source file for default values):\n\ntarget:  The target distribution.\nseed:  The master random seed.\nn_rounds:  The number of rounds to run.\nn_chains:  The number of chains to use (but see also n_chains_variational).\nn_chains_variational:  The number of chains to use for a variational leg of parallel tempering. The default value is zero. If the variational argument is not specified, this argument does nothing. Otherwise, a value of zero corresponds to basic single-leg variational parallel tempering, where the number of chains is taken from the n_chains argument. A positive value yields \"stabilized\" two-leg variational parallel tempering. In that case, the number of chains for the prior-reference leg is taken from n_chains, and the number of chains for the variational leg is taken from this argument. See https://arxiv.org/abs/2206.00080\n\nreference:  The reference distribution (e.g. a prior), or if nothing and a fixed reference is needed (i.e. variational inference is disabled or two-legged variational inference is used), then default_reference() will be called to automatically determine the reference based on the type of the target.\nvariational:  The variational reference family, or nothing to disable variational inference.\ncheckpoint:  Whether a checkpoint should be written to disk at the end of each round.\n\nrecord: Determine what should be stored from the simulation. A Vector with elements of type recorder_builder.\n\nchecked_round: The round index where run_checks() will be performed. Set to 0 to skip these checks.\n\nmultithreaded: If multithreaded explorers should be allowed. False by default since it incurs an overhead.\n\nexplorer:  The explorer to use, or if nothing, will use default_explorer() to automatically determine the explorer based on the type of the target.\n\nextractor:  Passed to extract_sample and sample_names to determine how samples should be extracted for traces.\nThe value nothing signals default behaviour. Use LogPotentialExtractor to extract only the log potential.\n\nshow_report: Show sampling report?\n\nextended_traces: Whether the traces and disk recorders will store samples for all the chains (extended = true) or just for the target(s) (extended = false).\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.InterpolatedAD","page":"Reference","title":"Pigeons.InterpolatedAD","text":"The target and reference may used different autodiff frameworks;  provided both are non-allocating, this allows autodiff of  InterpolatedLogPotential's to also be non-allocating.  For example, this is useful when the target is a stan log potential  and the reference is a variational distribution with a hand-crafted,  also allocation-free differentiation.\n\nFields:\n\nenclosed:  The enclosed InterpolatedLogPotential.\nref_ad:  The result of LogDensityProblemsAD.ADgradient() on the reference, often a BufferedAD.\n\ntarget_ad:  The same as ref_ad but with the target.\n\nbuffer:  An extra buffer to combine the two distribution endpoints gradients.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.InterpolatedLogPotential","page":"Reference","title":"Pigeons.InterpolatedLogPotential","text":"A log_potential obtained by evaluation of a path at a  point beta in the closed interval 0 1.  \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.InterpolatingPath-Tuple{Any, Any}","page":"Reference","title":"Pigeons.InterpolatingPath","text":"InterpolatingPath(ref, target)\n\n\nGiven a reference log_potential and a target log_potential,  return a path interpolating between them. \n\nBy default, the interpolator is a LinearInterpolator, i.e.  standard annealing.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.Iterators","page":"Reference","title":"Pigeons.Iterators","text":"Iterators used in Parallel Tempering. Stored in a struct so that  recorder's can access it when outputting  sample statistics.\n\nFields:\n\nround: Index of the Parallel Tempering adaptation round, as defined in Algorithm 4 of Syed et al., 2021. Set to zero when when pigeons() not yet started.\n\nscan: Number of (exploration, communication) pairs performed so far, corresponds to n in Algorithm 1 of Syed et al., 2021. Round i typically performs 2^i scans. Set to zero when runoneround!() is not yet started.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.JuliaBUGSPath","page":"Reference","title":"Pigeons.JuliaBUGSPath","text":"A thin wrapper around a JuliaBUGS.BUGSModel to provide a prior-posterior path. To work with Pigeons, JuliaBUGS needs to be imported into the current session.\n\nmodel: A JuliaBUGS.BUGSModel.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.LazyTarget","page":"Reference","title":"Pigeons.LazyTarget","text":"Use when a target contains information that cannot  be serialized, e.g. FFT plans  (https://discourse.julialang.org/t/distributing-a-function-that-uses-fftw/69564) so that the target is constructed just in time by each MPI node. \n\n# in a script.jl:\nstruct MyTargetFlag end \nimport Pigeons.instantiate_target\nPigeons.instantiate_target(flag::MyTargetFlag) = toy_mvn_target(1)\n\n# to run\npigeons(target = Pigeons.LazyTarget(MyTargetFlag()), on = ChildProcess(dependencies = [\"script.jl\"]))\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.LoadBalance","page":"Reference","title":"Pigeons.LoadBalance","text":"Split a list of indices across processes.  These indices are denoted 1 2  N. They are usually some kind of task,  for example in the context of parallel tempering,  two kinds of tasks arise:\n\nin replicas.state, task i consists in keeping track of the state of    replica i.\nin replicas.chain_to_replica_global_indices, task i consists in    storing which replica index corresponds to chain i.\n\nOne such task index is called a global_index. \n\nLoadBalance splits the global indices among n_processes. LoadBalance  is constructed so that the difference in the number of global indices  a process is responsible of (its \"load\")  is at most one.\n\nA LoadBalance contains:\n\nmy_process_index: A unique index for this process. We use 1-indexed, i.e. hide MPI's 0-indexed ranks.\n\nn_processes: Total number of processes involved.\n\nn_global_indices: The total number of global indices shared between all the processes.\n\nThe set {1, 2, .., load()} is called a set of local indices.  A local index indexes a slice in {1, 2, ..., n_global_indices}.  Collectively over the n_processes, these slices form a partition of  the global indices.\n\nKey functions to utilize a LoadBalance struct:\n\nmy_global_indices()\nfind_process()\nfind_local_index()\nmy_load()\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.LogPotentialExtractor","page":"Reference","title":"Pigeons.LogPotentialExtractor","text":"Signal that only the log potential should be recorded into  traces. See pt.inputs.extractor.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.MALA","page":"Reference","title":"Pigeons.MALA","text":"The Metropolis-Adjusted Langevin Algorithm (MALA). \n\nMALA is based on an approximation to overdamped Langevin dynamics followed by a  Metropolis-Hastings correction to ensure that we target the correct distribution.\n\nThis round-based version of MALA allows for the use of a preconditioner,  which is updated after every PT tuning round.  This setting can also be turned off by specifying the type of preconditioner to use.   However, MALA will not automatically adjust the step size.  For such functionality, use autoMALA.\n\nAs for autoMALA, the number of steps per exploration is base_n_refresh * ceil(Int, dim^exponent_n_refresh). \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.MPIProcesses","page":"Reference","title":"Pigeons.MPIProcesses","text":"Flag to run on MPI. Settings can be changed by calling setup_mpi before running.\n\nFields: \n\nn_threads: The number of threads per MPI process, 1 by default.\n\nwalltime: The walltime limit, 00:30:00 by default (i.e., 30 minutes).\n\nn_mpi_processes: The number of MPI processes, 2 by default.\n\nmemory: The memory allocated to each MPI process, 8gb by default.\n\ndependencies: Julia modules (if of type Module) or paths to include (if of type String) needed by the child process.\n\nmpiexec_args: MPI exec command arguments (can also be provided globally in MPISettings).\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.MPISettings","page":"Reference","title":"Pigeons.MPISettings","text":"Global settings needed for MPI job submission:\n\nsubmission_system: E.g.: :pbs, :slurm, etc\nUse Pigeons.supported_submission_systems() to see the list of available options.\n\nadd_to_submission: Add lines to the submission scripts.\nE.g. in Compute Canada if you are member of several accounts (see https://docs.alliancecan.ca/wiki/Running_jobs):\nadd_to_submission = [\"#SBATCH --account=my_user_name\"]\n\nenvironment_modules: \"Environment modules\" to load (not to be confused with Julia modules). Run module avail in the HPC login node to see what is available on your HPC.\n\nlibrary_name: In most case, leave empty as MPIPreferences.use_system_binary() will autodetect, but if it does not, the path to libmpi.so can be specified manually, e.g. this is needed on compute Canada clusters (as they are not setting that environment variable correctly) where it needs to be set to paths of the form \"/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Compiler/intel2020/openmpi/4.0.3/lib/libmpi\" (notice the .so is not included).\nOne heuristic to find this .so file is to modify the path returned by which mpiexec. See find_libmpi_from_mpiexec for an automated way to perform this heuristic.\n\nmpiexec: The mpiexec command or equivalent. For example, in other systems, it needs to be set to srun -n \"$SLURM_NTASKS\", potentially with the argument --mpi=pmi2 in some cases.\nNote: for the utility watch() to work correctly, the output-filename should be $MPI_OUTPUT_PATH/mpi_out.\nNote: the strings $MPI_OUTPUT_PATH and $SLURM_NTASKS should have the dollar sign escaped, see the source code for an example.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Mix","page":"Reference","title":"Pigeons.Mix","text":"Randomly alternate between different explorers. \n\nexplorers: A tuple consisting of exploration kernels\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.MixDiagonalPreconditioner","page":"Reference","title":"Pigeons.MixDiagonalPreconditioner","text":"Similar to DiagonalPreconditioner but the actual preconditioner used at each iteration is a random mixture of the identity and the adapted diagonal matrix. This helps with targets featuring distantly separated modes, which induces average standard deviations that are much higher than the ones within each mode. Even in the family of Gaussian targets, Hird & Livingstone (2023) identify cases where a fixed diagonal preconditioner performs worse than using  no preconditioner at all. We use a zero-one-inflated Uniform(0,1) distribution for the mixing proportion in order to make the preconditioner robust to extreme mismatch of scales (see the automala paper for more details).\n\np0: Proportion of zeros\np1: Proportion of ones\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.NonReversiblePT","page":"Reference","title":"Pigeons.NonReversiblePT","text":"Variables needed for the non-reversible Parallel Tempering described in  Syed et al., 2021:\n\npath:  The path.\nschedule:  The Schedule.\nlog_potentials:  The log_potentials.\nswap_graphs:  The swap_graphs.\ncommunication_barriers:  The communication barriers computed by communication_barriers() at the same time as this tempering was created; or nothing before adaptation, i.e. before the first call to adapt_tempering.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.NonReversiblePT-Tuple{Inputs}","page":"Reference","title":"Pigeons.NonReversiblePT","text":"NonReversiblePT(inputs)\n\n\nThe adaptive non-reversible Parallel Tempering described in  Syed et al., 2021. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.OddEven","page":"Reference","title":"Pigeons.OddEven","text":"Provides a swap_graph. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.OnlineStateRecorder","page":"Reference","title":"Pigeons.OnlineStateRecorder","text":"See online().\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.PT","page":"Reference","title":"Pigeons.PT","text":"Storage involved in PT algorithms:\n\ninputs: The user-provided Inputs that determine the execution of a PT algorithm.\n\nreplicas: The replicas held by this machine.\n\nshared: Information shared across all machines, updated between rounds.\n\nexec_folder: Either a path to a folder shared by all processes, which is used to save information to disk (checkpoints, samples etc); or nothing if a completely in-memory algorithm is used.\n\nreduced_recorders: recorders from the last round, or empty recorders.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.PT-Tuple{AbstractString}","page":"Reference","title":"Pigeons.PT","text":"PT(source_exec_folder; round, exec_folder)\n\n\nCreate a PT struct from a saved  checkpoint. The input source_exec_folder should point to a folder of the form  results/all/[exec_folder].\n\nThe checkpoint carries all the information stored in  a PT struct. It is possible for an MPI-based  execution to load a checkpoint written by a single-process  execution and vice versa.\n\nA new unique folder will be created with symlinks to  the source one, so that e.g. running more rounds of  PT will results in a new space-efficient checkpoint  containing all the information for the new run.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.PT-Tuple{Inputs}","page":"Reference","title":"Pigeons.PT","text":"PT(inputs; exec_folder)\n\n\nCreate a PT struct from provided Inputs.  Optionally, provide a specific exec_folder path (AbstractString),  if not one will be created via next_exec_folder().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.PermutedDistributedArray","page":"Reference","title":"Pigeons.PermutedDistributedArray","text":"A distributed array making special assumptions on how  it will be accessed and written to.  The indices of this distributed array correspond to the  notion of \"global indices\" defined in LoadBalance.  Several MPI processes cooperate, each processing storing  data for a slice of this distributed array. \n\nWe make the following assumptions:\n\nEach MPI process will set/get    entries the same number of times in their lifetime, at    logically related episodes (e.g. a set    number of times per iteration for algorithms running the    same number of iterations).    These episodes are called micro-iterations as in Entangler,    which this datastructure is built on.\nMoreover, at each time all processes perform a get or a set,    we assume that each global index is manipulated by exactly one    process (i.e. an implicit permutation of the global indices).\n\nWe use these assumptions to achieve read/write costs that are  near-constant in the number of machines participating. \n\nThis struct contains:\n\nlocal_data: The slice of the distributed array maintained by this MPI process.\n\nentangler: An Entangler used to coordinate communication.\n\nThe operations supported are:\n\npermuted_get()\npermuted_set!()\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Preconditioner","page":"Reference","title":"Pigeons.Preconditioner","text":"An abstract type for preconditioners. See IdentityPreconditioner,  DiagonalPreconditioner, and MixDiagonalPreconditioner.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Replica","page":"Reference","title":"Pigeons.Replica","text":"One of the N components that forms the state maintained by a PT algorithm. A Replica contains:\n\nstate:  Configuration in the state space.\nchain:  The index of the distribution currently associated with this replica, modified during swaps.\n\nrng:  Random operations involving this state should use only this random number generator.\n\nrecorders: Records statistics. Each replica carries its own for thread safety/distribution; then they are reduced at end of each round.\n\nreplica_index: A global id associated with this replica.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Result","page":"Reference","title":"Pigeons.Result","text":"A link to an execution folder able to  deserialize type T via a string constructor.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.RoundTripRecorder","page":"Reference","title":"Pigeons.RoundTripRecorder","text":"See round_trip().\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.SampleArray","page":"Reference","title":"Pigeons.SampleArray","text":"struct SampleArray{T, PT} <: AbstractArray{T, 1}\n\nArray convience wrapper for traces reduced recorder. We require a PT object, and the chain number which specifies the chain index (has to be a target chain) you wish to extract.\n\nThis should not be called directly and the user should instead look at get_sample.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ScaledPrecisionNormalPath","page":"Reference","title":"Pigeons.ScaledPrecisionNormalPath","text":"A path of zero-mean normals for testing; contains:\n\nprecision0: Precision parameter of the reference.\nprecision1: Precision parameter of the target.\ndim: Dimensionality.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ScaledPrecisionNormalPath-Tuple{Int64}","page":"Reference","title":"Pigeons.ScaledPrecisionNormalPath","text":"ScaledPrecisionNormalPath(dim)\n\n\nToy Multivariate Normal (MVN) path of distributions for testing: see section I.4.1 in Syed et al 2021.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.Schedule","page":"Reference","title":"Pigeons.Schedule","text":"A partition of 0 1 encoded by monotonically increasing grid points  starting at zero and ending at one.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Shared","page":"Reference","title":"Pigeons.Shared","text":"Information shared by all processes involved in  a round of distributed parallel tempering.  This is updated between rounds but only read during  a round. \n\nFields:\n\niterators: See Iterators.\n\ntempering: See tempering.\n\nexplorer: See explorer.\n\nreports: Named tuple of DataFrame's\n\nOnly one instance maintained per process. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Shared-Tuple{Any}","page":"Reference","title":"Pigeons.Shared","text":"Shared(inputs)\n\n\nCreate a Shared struct based on an Inputs.  Uses create_tempering() and create_explorer().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.SliceSampler","page":"Reference","title":"Pigeons.SliceSampler","text":"Slice sampler based on Neal, 2003.\n\nFields:\n\nw:  Initial slice size.\np:  Slices are no larger than 2^p * w\nn_passes:  Number of passes through all variables per exploration step.\nmax_iter:  Maximum number of interations inside shrink_slice! before erroring out\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.StabilizedPT","page":"Reference","title":"Pigeons.StabilizedPT","text":"Stabilized Variational Parallel Tempering as described in   Surjanovic et al., 2022.\n\nFields:\n\nfixed_leg:  The fixed leg of stabilized PT. Contains a path, Schedule, log_potentials, and communication_barriers. swap_graphs is also included but is overwritten by this struct's swap_graphs.\n\nvariational_leg:  The variational leg of stabilized PT.\nswap_graphs:  A swap_graphs spanning both legs.\nlog_potentials:  The log_potentials.\nindexer:  An Indexer mapping between global indices and leg-specific indices.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.StabilizedPT-Tuple{Inputs}","page":"Reference","title":"Pigeons.StabilizedPT","text":"StabilizedPT(inputs)\n\n\nParallel tempering with a variational reference described in  Surjanovic et al., 2022.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.StanLogPotential","page":"Reference","title":"Pigeons.StanLogPotential","text":"Uses BridgeStan to perform efficient ccall loglikelihood and allcoation-free gradient calls to a Stan model.\n\nTo work with Pigeons BridgeStan needs to be imported into the current session.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.StanState","page":"Reference","title":"Pigeons.StanState","text":"A state for stan target. Holds a vector in BridgeStan's unconstrained parameterization.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.StreamState","page":"Reference","title":"Pigeons.StreamState","text":"States used in the replicas when a stream target is used. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.StreamTarget","page":"Reference","title":"Pigeons.StreamTarget","text":"A target based on running worker processes, one for each replica, each communicating with Pigeons  using standard streams.  These worker processes can be implemented in an arbitrary programming language. \n\nStreamTarget implements log_potential and explorer  by invoking worker processes via standard stream communication. The standard stream is less efficient than alternatives such as  protobuff, but it has the advantage of being supported by nearly all  programming languages in existence.  Also in many practical cases, since the worker  process is invoked only three times per chain per iteration, it is unlikely to be the bottleneck (overhead is in the order of 0.1ms).  \n\nThe worker process should be able to reply to commands of the following forms (one command per line):\n\nlog_potential(0.6) in the worker's stdin to which it should return a response of the form    response(-124.23) in its stdout, providing in this example the joint log density at beta = 0.6;\ncall_sampler!(0.4) signaling that one round of local exploration should be performed    at beta = 0.4, after which the worker should signal it is done with response().\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Submission","page":"Reference","title":"Pigeons.Submission","text":"Specifies where to submit a task.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.SubmissionSyntax","page":"Reference","title":"Pigeons.SubmissionSyntax","text":"Specify the syntax of job submission systems such as SLURM.\n\nFields:\n\nsubmit: The command to submit the job.\n\ndel: The command to delete the job.\n\ndirective: The directive to add as a prefix to resource allocation requests.\n\njob_name: The flag to specify the job name.\n\noutput_file: The flag to specify the output file.\n\nerror_file: The flag to specify the error file.\n\nsubmit_dir: The flag to specify the submit directory.\n\njob_status: The command to check the job status.\n\njob_stats_all: The command to check the job status for all users.\n\nncpu_info: The command to check the number of CPUs available.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.SwapStat","page":"Reference","title":"Pigeons.SwapStat","text":"Default statistics exchanged by a pair of chains in the process of proposing a swap:\n\nlog_ratio\nuniform\n\nSee swap_stat()\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.TestSwapper","page":"Reference","title":"Pigeons.TestSwapper","text":"For testing/benchmarking purposes, a simple  pair_swapper where all swaps have equal  acceptance probability. \n\nCould also be used to warm-start swap connections  during exploration phase by setting that  constant probability to zero.  \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ThisProcess","page":"Reference","title":"Pigeons.ThisProcess","text":"Flag to ask to run a function within the  current process. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ToyExplorer","page":"Reference","title":"Pigeons.ToyExplorer","text":"Toy explorer for toy paths where each log_potential supports  i.i.d. sampling via rand!(rng, x, log_potential).\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.TreePPLBinary","page":"Reference","title":"Pigeons.TreePPLBinary","text":"A struct representing a compiled TreePPL binary along with metadata about how it was compiled.\n\nThe TreePPLBinary should be constructed by compiling the model with the tppl_compile_model function to ensure that all compilation metadata is kept. The fields below map directly to options in the tppl_compile_model function. For more information about what each field means, please run tpplc --help  or visit treeppl.org.\n\npath: The path to the compiled TreePPL binary\n\ncontainer_engine: The container engine to use for running the TreePPL binary. The supported options are \"docker\", \"podman\", \"apptainer\" and \"singularity\".\n\nimg_name: The container image name where the TreePPL binary was compiled\n\nlocal_exploration_steps: The number of local exploration steps to perform before communicating with Pigeons\n\nuse_global: Whether the binary was compiled to use global proposals at temperature 0.\n\nrecord_samples: Whether the binary was compiled to record samples.\n\nsampling_period: The frequency of sample recording in terms of steps in the local kernel.\n\ncps: The type of CPS transformation applied to the model.\n\nalign: Whether the model was compiled to use the aligned lightweight MCMC algorithm.\n\nkernel: Whether the model was compiled to use non-independent updates (drift kernels) at each assume statement.\n\ndrift: The scale of the proposal distribution for the drift kernels.\n\nglobalProb: The probability of redrawing the whole program per local exploration step.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.TreePPLTarget","page":"Reference","title":"Pigeons.TreePPLTarget","text":"A StreamTarget delegating exploration to a TreePPL worker processes.\n\nTo install TreePPL locally please see the  official TreePPL installation instructions. TreePPL can also be run inside Docker, Podman and Apptainer/Singularity containers, e.g.\n\nusing Pigeons\n\n# Get the TreePPL models\nrun(`git clone https://github.com/treeppl/treeppl.git`)\ncd(\"treeppl\") do\n    run(`git checkout 597a65a`) # Checkout a specific revision for reproducibility\nend\n\n# Set up paths to a CRBD model \nmodel_path = \"treeppl/models/host-repertoire-evolution/flat-root-prior-HRM.tppl\"\nbin_path = \"treeppl/models/host-repertoire-evolution/flat-root-prior-HRM.bin\"\ndata_path = \"treeppl/models/host-repertoire-evolution/data/testdata_flat-root-prior-HRM.json\"\noutput_path = \"treeppl/HRM_outputs\"\n\n# Compile the TreePPL model with the correct flags using a Docker container\ntppl_bin = Pigeons.tppl_compile_model(\n    model_path, bin_path;\n    local_exploration_steps=10, sampling_period=10,\n    kernel=true, drift=0.01,\n    container_engine=\"docker\",\n    img_name=\"docker.io/danielssonerik/treeppl:597a65a\"\n) \n\n# Construct the TreePPL target\ntppl_target = Pigeons.tppl_construct_target(tppl_bin, data_path, output_path)\n\n# Let Pigeons run the TreePPL model\npt  = pigeons(target = tppl_target, n_rounds = 2, n_chains = 2)\n\nPlease see treeppl.org for more examples and documentation.\n\nbin_path: The path to the TreePPL binary to be executed.\n\ndata_path: The path to the input data JSON file.\n\noutput_dir: The directory path where TreePPL will save output samples.\n\nrecord_samples: Whether the binary should be set up to record samples. Note: This requires that the TreePPL binary was compiled with record_samples=true in the tppl_compile_model function or with the --incremental-printing flag if the model was compiled manually.\n\ncontainer_engine: The container engine to use for running the TreePPL binary. The supported options are \"docker\", \"podman\", \"apptainer\" and \"singularity\".\n\nimg_name: The container image name where the TreePPL binary should be run\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.TuringLogPotential","page":"Reference","title":"Pigeons.TuringLogPotential","text":"Uses DynamicPPL i.e. Turing's backend to construct the log density.\n\nTo work with Pigeons DynamicPPL or Turing needs to be imported into the current session.\n\nmodel: A DynamicPPL.Model.\n\ncontext: Either DynamicPPL.DefaultContext for evaluating the full joint, or DynamicPPL.PriorContext for evaluating only the prior.\n\ndimension: The total number of scalar values observed in a single random sample from model. It is used by the LogDensityProblems and LogDensityProblemsAD interfaces when a gradient-based sampler is used as explorer in models with static computational graphs.\nwarning: Warning\nExplorers targeting models with dynamic computational graphs should not depend on the value of this field.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.VariationalOddEven","page":"Reference","title":"Pigeons.VariationalOddEven","text":"Provides a swap_graph. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons._transformed_online-Tuple{}","page":"Reference","title":"Pigeons._transformed_online","text":"Online statistics on potentially transformed samples for the target chain.  For example, if a gradient-based method is used, the target is often  transformed to be defined on an unconstrained space.  This is used internally by explorer's for adaptation purposes  (in particular, pre-conditioning and variational references).\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.aaps!-Tuple{Random.AbstractRNG, AAPS, Any, Vector, Any, Any}","page":"Reference","title":"Pigeons.aaps!","text":"Main function for AAPS. Note that this implementation uses scheme (1)  from the AAPS paper, which results in an acceptance probability of one.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.activate_variational-Tuple{Any, Any}","page":"Reference","title":"Pigeons.activate_variational","text":"activate_variational(variational, iterators)\n\n\nChoose on which rounds/scans to activate the variational reference.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.ad_buffers-Tuple{}","page":"Reference","title":"Pigeons.ad_buffers","text":"ad_buffers()\n\n\nAn Augmentation for Pigeons.BufferedAD.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.adapt-Tuple{Any, Any}","page":"Reference","title":"Pigeons.adapt","text":"adapt(pt, reduced_recorders)\n\n\nCall adapt_tempering() followed by  adapt_explorer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.adapt_explorer-NTuple{4, Any}","page":"Reference","title":"Pigeons.adapt_explorer","text":"adapt_explorer(\n    explorer,\n    reduced_recorders,\n    current_pt,\n    new_tempering\n)\n\n\nCalled between successive rounds (run_one_round!). \n\nBy default, return the explorer without further adaptation.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.adapt_tempering-NTuple{5, Any}","page":"Reference","title":"Pigeons.adapt_tempering","text":"adapt_tempering(\n    tempering,\n    reduced_recorders,\n    iterators,\n    variational,\n    state\n)\n\n\nCalled between successive rounds (run_one_round!). \n\nGiven a tempering and reduced recorders  return an updated tempering.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.all_reduce_deterministically-Union{Tuple{T}, Tuple{Any, AbstractVector{T}, Pigeons.Entangler}} where T","page":"Reference","title":"Pigeons.all_reduce_deterministically","text":"all_reduce_deterministically(operation, source_data, e)\n\n\nSame as reduce_deterministically() except that the result at the root of the  tree is then broadcast to all machines so that the output of all_reduce_deterministically()  is the root of the reduction tree for all MPI processes involved. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.all_reports-Tuple{}","page":"Reference","title":"Pigeons.all_reports","text":"all_reports()\n\n\nThe interim diagnostics computed and printed to  standard out at the end of every iteration  (this can be disabled using show_report = false).\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.allocation_extrema-Tuple{}","page":"Reference","title":"Pigeons.allocation_extrema","text":"Allocations informations. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.analytic_cumulativebarrier-Tuple{Pigeons.ScaledPrecisionNormalPath}","page":"Reference","title":"Pigeons.analytic_cumulativebarrier","text":"analytic_cumulativebarrier(path)\n\n\nKnown cumulative barrier used for testing, from Predescu et al., 2003.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.blang_ising-Tuple{Any}","page":"Reference","title":"Pigeons.blang_ising","text":"blang_ising(model_options)\n\n\nTwo-dimensional Ising model.\n\nFor more information:\n\nusing Pigeons\n\nPigeons.setup_blang(\"blangDemos\") \nrun(Pigeons.blang_ising(`--help`).command);\n\nE.g., use arguments `model.N` to set the size \nof the grid. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.blang_ising-Tuple{}","page":"Reference","title":"Pigeons.blang_ising","text":"blang_ising()\n\n\n15x15 Ising model. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.blang_sitka-Tuple{Any}","page":"Reference","title":"Pigeons.blang_sitka","text":"blang_sitka(model_options)\n\n\nModel for phylogenetic inference from single-cell copy-number alteration from  Salehi et al., 2020. \n\nFor more information:\n\nusing Pigeons\n\nPigeons.setup_blang(\"nowellpack\") \nrun(Pigeons.blang_sitka(`--help`).command);\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.blang_sitka-Tuple{}","page":"Reference","title":"Pigeons.blang_sitka","text":"blang_sitka()\n\n\nDefault options for infering a posterior distribution on  phylogenetic trees for   the 535 triple negative breast cancer dataset in  Salehi et al., 2020.   \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.buffers-Union{Tuple{}, Tuple{Type{T}}, Tuple{T}} where T","page":"Reference","title":"Pigeons.buffers","text":"buffers()\nbuffers()\n\n\nA buffering system used internally by explorers in Pigeons.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.check_against_serial-Tuple{Any}","page":"Reference","title":"Pigeons.check_against_serial","text":"check_against_serial(pt)\n\n\nRun a separate, fully serial version of the PT algorithm, and compare the checkpoint files to ensure the two produce exactly the same output.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.communicate!-Tuple{Any}","page":"Reference","title":"Pigeons.communicate!","text":"communicate!(pt)\n\n\nUse create_pair_swapper() and  create_swap_graph to construct the  inputs needed for swap!.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.communication_barriers-Tuple{AbstractVector, AbstractVector}","page":"Reference","title":"Pigeons.communication_barriers","text":"communication_barriers(intensity, schedule)\n\n\nCompute the local communication barrier and cumulative barrier functions from the  intensity rates (i.e. rejection rates in the context of Parallel Tempering) and  the current annealing schedule. The estimation of the barriers  is based on Fritsch-Carlson monotonic interpolation.\n\nReturns a NamedTuple with fields:\n\nlocalbarrier\ncumulativebarrier\nglobalbarrier\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.communicator-Tuple{Any}","page":"Reference","title":"Pigeons.communicator","text":"communicator(replicas)\n\n\nReturn the replicas's MPI.Comm or nothing if no MPI needed\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.continuous_variables-Tuple{Any}","page":"Reference","title":"Pigeons.continuous_variables","text":"continuous_variables(state)\n\n\nThe names (each a Symbol) of the continuous variables in the given state.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.continuous_variables-Tuple{PT}","page":"Reference","title":"Pigeons.continuous_variables","text":"continuous_variables(pt)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_entangled_replicas-Tuple{Inputs, Shared, Any}","page":"Reference","title":"Pigeons.create_entangled_replicas","text":"create_entangled_replicas(inputs, shared, source)\n\n\nCreate distributed replicas. \n\nSee create_replicas.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_explorer-Tuple{Any}","page":"Reference","title":"Pigeons.create_explorer","text":"create_explorer(inputs)\n\n\nGiven an Inputs object, either use inputs.explorer,  of if it is equal to nothing dispatch on  default_explorer(inputs.target) to construct the  explorer associated with the input target distribution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_pair_swapper-Tuple{Any, Any}","page":"Reference","title":"Pigeons.create_pair_swapper","text":"create_pair_swapper(tempering, target)\n\n\nGiven a tempering and a target,  create a pair_swapper. \n\nIf omitted, by default will return the standard Metropolis-Hastings  accept-reject. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_path-Tuple{Any, Inputs}","page":"Reference","title":"Pigeons.create_path","text":"create_path(target, inputs)\n\n\nCreate a path, by default linking the given target to  the refence provided by create_reference_log_potential().\n\nFor this default to work, the target should conform both  target and log_potential.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_path-Tuple{Pigeons.ScaledPrecisionNormalPath, Inputs}","page":"Reference","title":"Pigeons.create_path","text":"create_path(target, inputs)\n\n\nIn this case, the target is already a path, so return it.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_recorders-Tuple{Any}","page":"Reference","title":"Pigeons.create_recorders","text":"create_recorders(recorder_builders)\n\n\nCreate a recorders from an iterable with element  type recorder_builder.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_recorders-Tuple{Inputs, Shared}","page":"Reference","title":"Pigeons.create_recorders","text":"create_recorders(inputs, shared)\n\n\nCreate a recorders from an Inputs and Shared.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_reference_log_potential-Tuple{Any}","page":"Reference","title":"Pigeons.create_reference_log_potential","text":"create_reference_log_potential(inputs)\n\n\nGiven an Inputs object, either use inputs.reference,  of if it is equal to nothing dispatch on  default_reference(inputs.target) to construct the  reference log_potential associated with the input target distribution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_replica_indexer-Tuple{Int64, Int64}","page":"Reference","title":"Pigeons.create_replica_indexer","text":"create_replica_indexer(n_chains_fixed, n_chains_var)\n\n\nCreate an Indexer for stabilized variational PT.  Given a chain number, return a tuple indicating the relative chain number  within a leg of PT and the leg in which it is located.  Given a tuple, return the global chain number.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_replicas","page":"Reference","title":"Pigeons.create_replicas","text":"create_replicas(inputs, shared)\ncreate_replicas(inputs, shared, source)\n\n\nCreate replicas, detecting automatically if MPI is needed. \n\nArgument source is either nothing, when creating new states,  or FromCheckpoint to load from  a saved checkpoint.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.create_swap_graph-Tuple{Any, Any}","page":"Reference","title":"Pigeons.create_swap_graph","text":"create_swap_graph(swap_graphs, shared)\n\n\nGiven a swap_graphs and Shared, return  the swap_graph for the current iteration. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_tempering-Tuple{Inputs}","page":"Reference","title":"Pigeons.create_tempering","text":"create_tempering(inputs)\n\n\nBuild the tempering needed for communicate!(). \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_vector_replicas-Tuple{Inputs, Shared, Any}","page":"Reference","title":"Pigeons.create_vector_replicas","text":"create_vector_replicas(inputs, shared, source)\n\n\nCreate replicas when distributed computing is not needed. \n\nSee create_replicas.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.default_explorer-Tuple{Any}","page":"Reference","title":"Pigeons.default_explorer","text":"default_explorer(target)\n\n\nThe default explorer for the given target. \n\nIt can be overwritten by the argument explorer in pigeons().\n\nBy default, a SliceSampler.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.default_reference-Tuple{Any}","page":"Reference","title":"Pigeons.default_reference","text":"default_reference(target)\n\n\nCreate a default reference distribution, by returning a  log_potential. \n\nThe returned object will get  passed to sample_iid!() at the \"hot chains\" of  the Parallel Tempering algorithm. \n\nIt can be overwritten by the argument reference in pigeons().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.deo-Tuple{Any}","page":"Reference","title":"Pigeons.deo","text":"deo(n_chains)\n\n\nImplements the Deterministic Even Odd (DEO) scheme proposed in Okabe, 2001 and analyzed in Syed et al., 2021.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.deserialize_immutables!-Tuple{AbstractString}","page":"Reference","title":"Pigeons.deserialize_immutables!","text":"deserialize_immutables!(filename)\n\n\nSee Immutable's.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.discrete_variables-Tuple{Any}","page":"Reference","title":"Pigeons.discrete_variables","text":"discrete_variables(state)\n\n\nThe names (each a Symbol) of the discrete (Int) variables in the given state.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.discretize-Tuple{Any, Pigeons.Schedule}","page":"Reference","title":"Pigeons.discretize","text":"discretize(path, betas)\n\n\nCreate log_potentials from a path by interpolating the  path at each grid point specified in the Schedule.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.disk-Tuple{}","page":"Reference","title":"Pigeons.disk","text":"Save the full trace for the target chain to disk. \n\nThe disk recorders are safe to use in a multi-threaded and/or  distributed context as each replica uses its own file.\n\nTo post-process files in the correct order, use process_sample.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.energy_ac1-Tuple{}","page":"Reference","title":"Pigeons.energy_ac1","text":"Auto-correlation before and after an exploration step, grouped by   chain.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.energy_ac1s","page":"Reference","title":"Pigeons.energy_ac1s","text":"energy_ac1s(reduced_recorders)\nenergy_ac1s(reduced_recorders, skip_reference)\nenergy_ac1s(reduced_recorders, skip_reference, pt)\n\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.energy_ac1s-2","page":"Reference","title":"Pigeons.energy_ac1s","text":"energy_ac1s(pt)\nenergy_ac1s(pt, skip_reference)\n\n\nAuto-correlations between energy before and after an exploration step,  for each chain. Organized as a Vector where component i corresponds  to chain i.\n\nIt is often useful to skip the reference chain, for two reasons, first,  exploration should be iid there, second, if the prior is flat the  auto-correlation of the energy will be NaN for the reference.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.entangler-Tuple{Any}","page":"Reference","title":"Pigeons.entangler","text":"entangler(replicas)\n\n\nReturn the replicas's Entangler (possibly a no-communication Entangler if a single process is involved)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.equally_spaced_schedule-Tuple{Int64}","page":"Reference","title":"Pigeons.equally_spaced_schedule","text":"equally_spaced_schedule(n_chains)\n\n\nCreate a Schedule with n_chains equally spaced grid points.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explore!-Tuple{Any, Any, Val{false}}","page":"Reference","title":"Pigeons.explore!","text":"explore!(pt, explorer, multithreaded)\n\n\nThe @threads macro brings a large overhead even  when Threads.nthreads == 1, so a separate method  is used for the single thread mode.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explore!-Tuple{Any, Any, Val{true}}","page":"Reference","title":"Pigeons.explore!","text":"explore!(pt, explorer, multithreaded_flag)\n\n\nCall sample_iid! or step!() on  each chain (depending if it is a reference or not  respectively). \n\nUses @threads to parallelize across threads.  This is safe by the contract described in  sample_iid!() and step!().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explorer_acceptance_pr-Tuple{}","page":"Reference","title":"Pigeons.explorer_acceptance_pr","text":"Average MH swap acceptance probabilities for explorers.  \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explorer_n_steps-Tuple{}","page":"Reference","title":"Pigeons.explorer_n_steps","text":"Number of steps used by explorers.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explorer_recorder_builders-Tuple{Any}","page":"Reference","title":"Pigeons.explorer_recorder_builders","text":"explorer_recorder_builders(explorer)\n\n\nWhat information is needed to perform adapt_explorer? Answer this by specifying an iterator containing recorder_builder's.  Return [] if none are needed (default behaviour). \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explorer_step-Tuple{SplittableRandoms.SplittableRandom, Any, Any, Any}","page":"Reference","title":"Pigeons.explorer_step","text":"explorer_step(rng, target, explorer, init_state)\n\n\nUtility for taking a single step of an explorer under a given target and initial state init_state. Returns the modified state.\n\nnote: Taking multiple steps\nNote that taking more than a single step can be achieved in many Pigeons explorers by modifying their arguments for number of passes or refreshements.  For example, SliceSampler takes an n_passes::Int argument, while  AutoMALA takes the base_n_refresh::Int argument.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.extract_sample-Tuple{Any, Any, Nothing}","page":"Reference","title":"Pigeons.extract_sample","text":"extract_sample(state, log_potential, extractor)\n\n\nExtract a sample for postprocessing. By default, calls copy() but many overloads are      defined for different kinds of states.\n\nTypically, this will be a flattened vector (i.e. concatenation of all variables, with discrete ones converted to Float64) ready for post-processing. \n\nThe corresponding un-normalized log density might be appended at the very end.\n\nIf the state is transformed (e.g. for HMC), this will create a fresh vector with an un-transformed (i.e. original parameterization) state in it.\n\nThe argument extractor is passed from the Inputs.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_global_index-Tuple{Pigeons.LoadBalance, Int64}","page":"Reference","title":"Pigeons.find_global_index","text":"find_global_index(lb, local_idx)\n\n\nFind the global index corresponding to the given local_index. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_libmpi_from_mpiexec-Tuple{}","page":"Reference","title":"Pigeons.find_libmpi_from_mpiexec","text":"A heuristic to try to locate libmpi.so by locating  mpiexec and modifying the path appropriately. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_local_index-Tuple{Pigeons.LoadBalance, Int64}","page":"Reference","title":"Pigeons.find_local_index","text":"find_local_index(lb, global_idx)\n\n\nFind the local index corresponding to the given global_index.  Assumes the given global_index is one of this process'. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_log_potential-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.find_log_potential","text":"find_log_potential(replica, tempering, shared)\n\n\nFind the log_potential for the chain  the replica is at, based on the tempering and Shared objects.  \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_process-Tuple{Pigeons.LoadBalance, Int64}","page":"Reference","title":"Pigeons.find_process","text":"find_process(lb, global_idx)\n\n\nFind the process id (1-indexed) responsible for the given global_idx. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.flush_immutables!-Tuple{}","page":"Reference","title":"Pigeons.flush_immutables!","text":"flush_immutables!()\n\n\nSee Immutable's.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.forward_sample_condition_and_explore","page":"Reference","title":"Pigeons.forward_sample_condition_and_explore","text":"The workhorse under invariance_test. It starts with a full forward pass for the probabilistic model underlying target, thats simulates latent variables and observations. Then a modified model is created that conditions the original model on the observations produced. Finally, the function takes a step using the explorer targetting the conditioned model and the final state is returned. The exploration can be optionally disabled by passing run_explorer=false, in which case the initial simulated state is returned.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.forward_sample_condition_and_explore-Tuple{Pigeons.ScaledPrecisionNormalPath, SplittableRandoms.SplittableRandom}","page":"Reference","title":"Pigeons.forward_sample_condition_and_explore","text":"forward_sample_condition_and_explore(target, rng; explorer)\n\n\nImplementation for ScaledPrecisionNormalPath. Since this toy model  allows direct iid sampling from the target, conditioning is not necessary.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.get_buffer-Tuple{Pigeons.Augmentation{<:Dict{Symbol, Pigeons.BufferedAD}}, Symbol, Vararg{Any}}","page":"Reference","title":"Pigeons.get_buffer","text":"get_buffer(a, key, args)\n\n\nReturn a Pigeons.BufferedAD if it exists in the Augmentation. Otherwise it constructs one and then stores it to avoid reconstructing it in the future.\n\nnote: Note\nThis implementation is not type stable (the value type of the Dict is not  concrete). However, the runtime dispatch cost incurred should be more than  compensated by the ability to avoid reconstructing AD objects at each  exploration step.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.get_buffer-Union{Tuple{T}, Tuple{Pigeons.Augmentation{Dict{Symbol, T}}, Symbol, Any}} where T<:Array","page":"Reference","title":"Pigeons.get_buffer","text":"get_buffer(a, key, dims)\n\n\nReturn an array in the buffer. Allocating only the first  time; after that, the buffer is recycled and stored in the  Replica's recorders.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.get_sample","page":"Reference","title":"Pigeons.get_sample","text":"get_sample(pt)\nget_sample(pt, chain)\n\n\nThe chain option can be omitted and by default the  first chain targetting the distribution of interest will be used  (in many cases, there will be only one, in variational cases, two).\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.get_sample-Tuple{PT, Int64, Int64}","page":"Reference","title":"Pigeons.get_sample","text":"get_sample(pt, chain, scan)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.get_statistic-Union{Tuple{T}, Tuple{PT, Symbol, Type{T}}} where T","page":"Reference","title":"Pigeons.get_statistic","text":"get_statistic(pt, variable_name, t)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.global_barrier-Tuple{Any}","page":"Reference","title":"Pigeons.global_barrier","text":"global_barrier(pt)\n\n\nThe global communication barrier.  If the PT algorithm has both a fixed and variational  references, return the barrier to the fixed one.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.index_process-Tuple{}","page":"Reference","title":"Pigeons.index_process","text":"Full index process stored in memory. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.informal_doc-Tuple{Any, Module}","page":"Reference","title":"Pigeons.informal_doc","text":"informal_doc(doc_dir, mod)\n\n\nGenerate informal interface documentation, e.g.: \n\nmakedocs(;\n    ...\n    pages=[\n        \"Home\" => \"index.md\", \n        \"Interfaces\" => informal_doc(@__DIR__, MyModuleName),\n        ...\n    ]\n)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.initialization-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.initialization","text":"initialization(target, rng, replica_index)\n\n\nCreate a fresh state used to populate  the states at the beginning of the first round of  Parallel Tempering. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.initialization-Tuple{Pigeons.StreamTarget, Random.AbstractRNG, Int64}","page":"Reference","title":"Pigeons.initialization","text":"initialization(target, rng, replica_index)\n\n\nReturn StreamState by following these steps:\n\ncreate a Cmd that uses the provided rng to set the random seed properly, as well   as target-specific configurations provided by target.\nCreate StreamState from the Cmd created in step 1 and return it.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.interpolate-Tuple{Any, Any}","page":"Reference","title":"Pigeons.interpolate","text":"interpolate(path, beta)\n\n\nReturns the log_potential at point beta in the path.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.invariance_test","page":"Reference","title":"Pigeons.invariance_test","text":"Run an invariance test of explorer on the provided target. Corresponds to a modified Geweke test where the simulated data is kept fixed.\n\nReferences\n\nBouchard-Côté, A., Chern, K., Cubranic, D., Hosseini, S., Hume, J., Lepur, M.,  Ouyang, Z., & Sgarbi, G. (2022). Blang: Bayesian Declarative Modeling of General  Data Structures and Inference via Algorithms Based on Distribution Continua.  Journal of Statistical Software, 103(11), 1–98.\n\nGeweke, J. (2004). Getting It Right: Joint Distribution Tests of Posterior  Simulators. Journal of the American Statistical Association, 99(467), 799–804.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.is_finished-Tuple{AbstractString, Any}","page":"Reference","title":"Pigeons.is_finished","text":"is_finished(checkpoint_folder, inputs)\n\n\nIs the provided path to a checkpoint folder complete?  I.e. check in the .signal subfolder that all MPI processes have  signaled that they are done.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.is_reference-Tuple{Any, Int64}","page":"Reference","title":"Pigeons.is_reference","text":"is_reference(swap_graph, chain)\n\n\nFor a given swap_graph and input chain index, is the current chain a reference distribution?\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.is_target-Tuple{Any, Int64}","page":"Reference","title":"Pigeons.is_target","text":"is_target(swap_graph, chain)\n\n\nFor a given swap_graph and input chain index, is the current chain a target distribution?\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.json-Tuple{}","page":"Reference","title":"Pigeons.json","text":"json(; variables...)\n\n\nCreate a JSON string based on the scalar or array variables provided.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.kill_child_processes-Tuple{Any}","page":"Reference","title":"Pigeons.kill_child_processes","text":"kill_child_processes(pt)\n\n\nDispose of the child processes associated with the pt's  StreamState's\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.kill_job-Tuple{Result}","page":"Reference","title":"Pigeons.kill_job","text":"kill_job(result)\n\n\nInstruct the scheduler to cancel or kill a job. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.last_round_max_allocation-Tuple{Any}","page":"Reference","title":"Pigeons.last_round_max_allocation","text":"Maximum bytes allocated (over the MPI process) to compute the last Parallel Tempering round. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.last_round_max_time-Tuple{Any}","page":"Reference","title":"Pigeons.last_round_max_time","text":"Maximum time (over the MPI process) to compute the last Parallel Tempering round. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.latest_checkpoint_folder-Tuple{Any}","page":"Reference","title":"Pigeons.latest_checkpoint_folder","text":"latest_checkpoint_folder(exec_folder)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.load-Tuple{Any}","page":"Reference","title":"Pigeons.load","text":"load(replicas)\n\n\nReturn the replicas's LoadBalance (possibly single_process_load)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.load-Union{Tuple{Result{T}}, Tuple{T}} where T","page":"Reference","title":"Pigeons.load","text":"load(replicas)\nload(result)\n\n\nLoad the result in memory.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.locals-Tuple{Any}","page":"Reference","title":"Pigeons.locals","text":"locals(replicas)\n\n\nReturn the replica's that are stored in this machine\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.log_sum_ratio-Tuple{}","page":"Reference","title":"Pigeons.log_sum_ratio","text":"Log of the sum of density ratios between neighbour chains, used  to compute stepping stone estimators of lognormalization contants.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.log_unnormalized_ratio-Tuple{AbstractVector, Int64, Int64, Any}","page":"Reference","title":"Pigeons.log_unnormalized_ratio","text":"log_unnormalized_ratio(\n    log_potentials,\n    numerator,\n    denominator,\n    state\n)\n\n\nAssumes the input log_potentials is a vector where each element is a log_potential.\n\nThis default implementation is sufficient in most cases, but in less standard scenarios, e.g. where the state space is infinite dimensional, this can be overridden. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.log_unnormalized_ratio-Tuple{Any, Int64, Int64, Any}","page":"Reference","title":"Pigeons.log_unnormalized_ratio","text":"log_unnormalized_ratio(\n    log_potentials,\n    numerator,\n    denominator,\n    state\n)\n\n\nThe argument numerator selects one distribution pi_i from the collection log_potentials,  and similarly denominator selects pi_j. Let x denote the input state. The ratio:\n\nf(x) = fractextdpi_itextdpi_j(x)\n\nmay only be known up to a normalization constant which can depend on i and j but  not x, g(x) = C_ij f(x).\n\nThis function should return log g evaluated at state.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.mpi_active-Tuple{}","page":"Reference","title":"Pigeons.mpi_active","text":"mpi_active()\n\n\nA flag is set by launch scripts (see ChildProcess.jl) to indicate  if this process is a child MPI process under an mpiexec.  Otherwise, that flag is false by default.\n\nThis function retrieves the value of that flag. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.my_global_indices-Tuple{Pigeons.LoadBalance}","page":"Reference","title":"Pigeons.my_global_indices","text":"my_global_indices(lb)\n\n\nThe slice of lb.global_indices this process is reponsible for.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.my_load-Tuple{Pigeons.LoadBalance}","page":"Reference","title":"Pigeons.my_load","text":"my_load(lb)\n\n\nReturn the number of indices (task) this process is responsible for. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_chains-Tuple{Any}","page":"Reference","title":"Pigeons.n_chains","text":"n_chains(log_potentials)\n\n\nThe number of chains in the log_potentials.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_chains-Tuple{Inputs}","page":"Reference","title":"Pigeons.n_chains","text":"Extract the number of Parallel Tempering chains from Inputs.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_round_trips-Tuple{Any}","page":"Reference","title":"Pigeons.n_round_trips","text":"n_round_trips(reduced_recorders)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_round_trips-Tuple{PT}","page":"Reference","title":"Pigeons.n_round_trips","text":"n_round_trips(pt)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_tempered_restarts-Tuple{Any}","page":"Reference","title":"Pigeons.n_tempered_restarts","text":"n_tempered_restarts(reduced_recorders)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_tempered_restarts-Tuple{PT}","page":"Reference","title":"Pigeons.n_tempered_restarts","text":"n_tempered_restarts(pt)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.next_exec_folder-Tuple{}","page":"Reference","title":"Pigeons.next_exec_folder","text":"Return a unique subfolder of  results/all/, making sure the  unique folder and its parents are created.  It will also create a soft symlink to it  called results/latest`\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.online-Tuple{}","page":"Reference","title":"Pigeons.online","text":"Online statistics on the target chain.  The samples are processed in the original model parameterization.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.only_one_process-Tuple{Any, Any}","page":"Reference","title":"Pigeons.only_one_process","text":"only_one_process(task, pt)\n\n\nA task that should be ran on only one of the processes.  Using the do .. end syntax, this can be used as:\n\nonly_one_process(pt) do \n    ...\nend\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.optimal_schedule-Tuple{AbstractVector, Pigeons.Schedule, Int64}","page":"Reference","title":"Pigeons.optimal_schedule","text":"optimal_schedule(\n    intensity,\n    old_schedule,\n    new_schedule_n_chains\n)\n\n\nReturn an optimal Schedule based on statistics from a previous round. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.partner_chain-Tuple{Any, Int64}","page":"Reference","title":"Pigeons.partner_chain","text":"partner_chain(swap_graph, chain)\n\n\nFor a given swap_graph and input chain index, what chain will it interact with at the current iteration? Convention: if a chain is not interacting, return its index.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.permuted_get-Union{Tuple{T}, Tuple{Pigeons.PermutedDistributedArray{T}, AbstractVector{Int64}}} where T","page":"Reference","title":"Pigeons.permuted_get","text":"permuted_get(p, indices)\n\n\nRetreive the values for the given indices, using MPI communication when needed. \n\nWe make the following assumptions:\n\nlength(indices) == my_load(p.entangler.load)\nthe indices across all participating processes form a permutation of the global indices. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.permuted_set!-Union{Tuple{T}, Tuple{Pigeons.PermutedDistributedArray{T}, AbstractVector{T}, AbstractVector{T}}} where T","page":"Reference","title":"Pigeons.permuted_set!","text":"permuted_set!(p, indices, new_values)\n\n\nSet the values for the given indices to the given new_values, using MPI communication when needed. \n\nWe make the same assumptions as in permuted_get().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{Any, ChildProcess}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(\n    pt_arguments,\n    new_process::ChildProcess\n) -> Result{PT}\n\n\nRun Parallel Tempering in a new process.  See ChildProcess.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{Any, MPIProcesses}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(\n    pt_arguments,\n    mpi_submission::MPIProcesses\n) -> Result{PT}\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{Any}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(pt_arguments; on)\n\n\npt_arguments can be either an Inputs, to start  a new Parallel Tempering algorithm, or a string pointing to  an execution to resume. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{PT}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(pt::PT) -> Any\n\n\nRun (a generalization of) Parallel Tempering. \n\nThis will call several rounds of run_one_round!(),  performing adaptation between each round via adapt().\n\nThis will also call report!(), write_checkpoint(),  and run_checks() between rounds. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(; on, args...)\n\n\nPasses the args... to Inputs and start  a new Parallel Tempering algorithm with that inputs. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.process_sample","page":"Reference","title":"Pigeons.process_sample","text":"process_sample(processor, pt)\nprocess_sample(processor, pt, round)\n\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.process_sample-2","page":"Reference","title":"Pigeons.process_sample","text":"process_sample(processor, pt)\nprocess_sample(processor, pt, round)\n\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.process_sample-Tuple{Function, String, Int64}","page":"Reference","title":"Pigeons.process_sample","text":"process_sample(processor, exec_folder, round)\n\n\nProcess samples that were saved to disk using the disk recorder, at the given round.\n\nEach sample is passed to the processor function, by calling processor(chain_index, scan_index, sample) where chain_index is the index of the target chain (in classical parallel tempering, there is only one chain at target temperature, so in that case it can be ignored, but it will be non-trivial in e.g. stabilized variational parallel tempering), scan_index is the iteration index within the round, starting at 1, and sample is the deserialized sample.\n\nThis iterates over the samples in increasing order, looping over chain_index in the outer loop and scan_index in the inner loop.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.providers-Tuple{Module, Symbol}","page":"Reference","title":"Pigeons.providers","text":"providers(mod, name)\n\n\nProvides a Set{Expr} containing all the providers of the  given name in the given module. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.queue_status-Tuple{Result}","page":"Reference","title":"Pigeons.queue_status","text":"queue_status(result)\n\n\nDisplay the queue status for one MPI job. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.queue_status-Tuple{}","page":"Reference","title":"Pigeons.queue_status","text":"queue_status()\n\n\nDisplay the queue status for all the user's jobs. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record!-Tuple{Any, Any}","page":"Reference","title":"Pigeons.record!","text":"record!(recorder, value)\n\n\nAdd value to the statistics accumulated by recorder. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record!-Tuple{OnlineStatsBase.OnlineStat, Any}","page":"Reference","title":"Pigeons.record!","text":"record!(recorder, value)\n\n\nForwards to OnlineStats' fit!.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record!-Union{Tuple{V}, Tuple{K}, Tuple{Dict{K, Vector{V}}, Tuple{K, V}}} where {K, V}","page":"Reference","title":"Pigeons.record!","text":"record!(recorder, value)\n\n\nGiven a value, a pair (a, b), and a Dict{K, Vector{V}} backed  recorder,  append b to the vector corresponding to a, inserting an empty  vector into the dictionary first if needed.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record_default-Tuple{}","page":"Reference","title":"Pigeons.record_default","text":"Set of recorders with no measurable impact on performance. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record_if_requested!-Tuple{Any, Symbol, Any}","page":"Reference","title":"Pigeons.record_if_requested!","text":"record_if_requested!(recorders, recorder_key, value)\n\n\nIf the recorders contains the given recorder_key,  send the value to the recorder corresponding to the  recorder_key. Otherwise, do nothing.\n\nWhen value is costly or may cause allocation, use @record_if_requested!() instead.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record_online-Tuple{}","page":"Reference","title":"Pigeons.record_online","text":"Set of constant memory recorders.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record_swap_stats!-Tuple{Any, Any, Int64, Any, Int64, Any}","page":"Reference","title":"Pigeons.record_swap_stats!","text":"record_swap_stats!(\n    pair_swapper,\n    recorders,\n    chain1,\n    stat1,\n    chain2,\n    stat2\n)\n\n\nGiven a pair_swapper, a recorders, the provided chain indices, and  the sufficient statistics computed by swap_stat(), record statistics. \n\nTo avoid accumulating twice the same statistic with (chain1, chain2) and  (chain2, chain2), swap!() only calls this for the pair with chain1 < chain2.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record_swap_stats!-Tuple{Pigeons.TestSwapper, Any, Int64, Any, Int64, Any}","page":"Reference","title":"Pigeons.record_swap_stats!","text":"record_swap_stats!(\n    swapper,\n    recorder,\n    chain1,\n    stat1,\n    chain2,\n    stat2\n)\n\n\nSee TestSwapper.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.recorded_continuous_variables-Tuple{Any}","page":"Reference","title":"Pigeons.recorded_continuous_variables","text":"recorded_continuous_variables(state)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.recorder_values-Tuple{PT, Symbol}","page":"Reference","title":"Pigeons.recorder_values","text":"recorder_values(pt, recorder_name)\n\n\nReturns a generator for the values of a recorder of type OnlineStatsBase.GroupBy.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.recursive_equal-Tuple{Any, Any}","page":"Reference","title":"Pigeons.recursive_equal","text":"recursive_equal(a, b)\n\n\nRecursively check equality between two objects by comparing their fields. By default calls == but for certain types we dispatch a custom method.  This is necessary because for some mutable structs (and even immutable ones with mutable fields) == actually dispatches ===. The latter is too strict for the  purpose of checking that two checkpoints are equal.\n\nIf you are using custom struct and encounter a failed correctness check, you may need to provide a special equality check for this type. In most cases it will be enough to overload recursive_equal as follows\n\nPigeons.recursive_equal(a::MyType, b::MyType) = Pigeons._recursive_equal(a,b)\n\nFor examples of more specific checks, refer to the code of PigeonsBridgeStanExt.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.reduce_deterministically-Union{Tuple{T}, Tuple{Any, AbstractVector{T}, Pigeons.Entangler}} where T","page":"Reference","title":"Pigeons.reduce_deterministically","text":"reduce_deterministically(operation, source_data, e)\n\n\nPerform a binary reduction of the  source_data, using MPI when needed. \n\nConsider the binary tree with leaves given by the global indices specified in e.load and stored  in the different MPI processes' input source_data vectors.  At each node of the tree, a reduction is performed using operation, i.e.  by calling operation(left_child, right_child). When, and only when a branch of the tree crosses from one MPI process to another one,  MPI communication is used to transmit the intermediate reduction. \n\nAt the end, for process 1, reduce_deterministically() will return the root of the  binary tree, and for the other processes, reduce_deterministically() will return  nothing. \n\nNote that even when the operation is only approximately associative (typical situation  for floating point reductions), the output of this function is invariant to the  number of MPI processes involved (hence the terminology 'deterministically').  This contrasts to direct use of MPI collective communications where the leaves are  MPI processes and hence will give slightly different outputs given different  numbers of MPI processes. In the context of randomized algorithms, these minor  differences are then amplified. \n\nIn contrast to transmit!(), we do not assume isbitstype(T) == true and use  serialization when messages are transmitted over MPI.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.reduce_recorders!-Tuple{Any, EntangledReplicas}","page":"Reference","title":"Pigeons.reduce_recorders!","text":"reduce_recorders!(pt, replicas)\n\n\nPerform a reduction across all the replicas' individual recorders,  using Base.merge() on each individual recorder held. Returns a recorders with all the information merged. \n\nWill reset the replicas' recorders at the same time using Base.empty!().\n\nSince this uses all_reduce_deterministically, the output is  identical, no matter how many MPI processes are used, even when  the reduction involves only approximately associative Base.merge() operations (e.g. most floating point ones).\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.register_online_type-Tuple{Any}","page":"Reference","title":"Pigeons.register_online_type","text":"register_online_type(type)\n\n\nRegister an additional OnlineStat sub-types to be computed when the [online()]  recorder is enabled. \n\nThe provided type should have a zero-argument constructor. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.rejections-Tuple{Any, AbstractVector}","page":"Reference","title":"Pigeons.rejections","text":"Similar to above except that instead of the number of chains,  provide the full vector of chain indices. Note that chain_indices starts at the reference and ends at the chain one before the target. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.report!-Tuple{Any, Any}","page":"Reference","title":"Pigeons.report!","text":"report!(pt, prev_header)\n\n\nReport summary information on the progress of pigeons().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.resource_string-Tuple{MPIProcesses, Any}","page":"Reference","title":"Pigeons.resource_string","text":"resource_string(m::MPIProcesses, symbol) -> String\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.reversibility_rate-Tuple{}","page":"Reference","title":"Pigeons.reversibility_rate","text":"reversibility_rate()\n\n\nRecords the success rate for the AutoMALA reversibility check. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.round_trip-Tuple{}","page":"Reference","title":"Pigeons.round_trip","text":"Restart and round-trip counts. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.run_checks-Tuple{Any}","page":"Reference","title":"Pigeons.run_checks","text":"Perform checks to detect software defects. Unable via field checked_round in Inputs\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.run_one_round!-Tuple{Any}","page":"Reference","title":"Pigeons.run_one_round!","text":"run_one_round!(pt)\n\n\nFrom a PT object, run one round of  a generalized version of Algorithm 1 in  Syed et al., 2021.\n\nAlternates between communicate!(),  which consists of any pairwise communicating  moves and [explore!()], which consists of   moves independent to each chain. \n\nConcrete specification of how to communicate and  explore are specified by the field of type Shared  contained in the provided PT. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.safelink-Tuple{AbstractString, AbstractString}","page":"Reference","title":"Pigeons.safelink","text":"safelink(target, link)\n\n\nWork around two issues with symlink():\n\nnaively calling symlink() when there are relative paths leads to broken links\non windows, one needs admin permission to do symlinks, so print a helpful error message in that case\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.sample_array-Tuple{PT}","page":"Reference","title":"Pigeons.sample_array","text":"sample_array(pt)\n\n\nCopy the target chain(s) samples into an array with axes:  iteration x variable x target chain.  For example, with StabilizedPT there  are two target chains.  By default, there is only one chain produced. \n\nSee extract_sample() for information how the variables are  flattened, and use sample_names() to obtain string  names for the flattened variables. \n\nThe combination of this function and sample_names() is useful for  creating MCMCChains  which can then be used to obtain summary statistics, diagnostics, create trace plots,  and pair plots (via PairPlots).\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.sample_iid!-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.sample_iid!","text":"sample_iid!(reference_log_potential, replica, shared)\n\n\nPerform i.i.d. sampling on the given Replica  during its visit to the reference_log_potential created  by create_reference_log_potential().\n\nImplementations should provide samples exactly distributed  according to the reference, otherwise several theoretical guarantees of  Parallel Tempering are invalidated. \n\nOptional but recommended for e.g. jumping modes in  multi-modal problems.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.sample_names-Tuple{Any, Any, Nothing}","page":"Reference","title":"Pigeons.sample_names","text":"sample_names(state, log_potential, extractor)\n\n\nA list of string labels for the flattened vectors returned by extract_sample().\n\nThe key :log_density is used when the un-normalized log density  is included.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.sample_segment!-Tuple{AAPS, Pigeons.AAPSState, Any, Random.AbstractRNG, Vector}","page":"Reference","title":"Pigeons.sample_segment!","text":"Sample a segment of the trajectory until an apogee is reached. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.serialize_immutables-Tuple{AbstractString}","page":"Reference","title":"Pigeons.serialize_immutables","text":"serialize_immutables(filename)\n\n\nSee Immutable's.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.setup_blang","page":"Reference","title":"Pigeons.setup_blang","text":"setup_blang(repo_name)\nsetup_blang(repo_name, organization)\n\n\nDownload the github repo with the given repo_name and organization in ~.pigeons,  and compile the blang code. \n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.setup_mpi-Tuple{Pigeons.MPISettings}","page":"Reference","title":"Pigeons.setup_mpi","text":"setup_mpi(settings::Pigeons.MPISettings)\n\n\nExecute this function once before running MPI jobs.  This should be done on the head node of a compute cluster. The setting are permanently saved.  See MPISettings.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.setup_mpi-Tuple{}","page":"Reference","title":"Pigeons.setup_mpi","text":"setup_mpi(; args...)\n\n\nLook first at the list of clusters that have \"presets\" available,  by typing Pigeons.setup_mpi_ and then tab. These are the most  straightforward to use. \n\nUse setup_mpi() if presets are not available. See MPISettings for information on the arguments of setup_mpi(),  (i.e. args... are passed to the constructor of MPISettings). \n\nPull requests to Pigeons/src/submission/presets.jl are welcome  if you would like to add a new \"preset\" functions of the form  Pigeons.setup_mpi_...().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.setup_mpi_compute_canada-Tuple{}","page":"Reference","title":"Pigeons.setup_mpi_compute_canada","text":"setup_mpi_compute_canada()\n\n\nCompute Canada clusters. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.setup_mpi_harvard_canon-Tuple{}","page":"Reference","title":"Pigeons.setup_mpi_harvard_canon","text":"setup_mpi_harvard_canon()\n\n\nHarvard Canon clusters. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.setup_mpi_sockeye-Tuple{Any}","page":"Reference","title":"Pigeons.setup_mpi_sockeye","text":"setup_mpi_sockeye(my_user_allocation_code)\n\n\nUBC Sockeye cluster. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.single_process_load-Tuple{Any}","page":"Reference","title":"Pigeons.single_process_load","text":"single_process_load(n_global_indices)\n\n\nA load balance with only one process.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.sort_includes!-Tuple{Any}","page":"Reference","title":"Pigeons.sort_includes!","text":"sort_includes!(main)\n\n\nHeuristic to automate the process  of sorting include()'s.\n\nTopological sorting of the source files under src  (excluding main) is attempted, if successful, print the  include string to copy and paste to the main file, otherwise,  print the detected loops. \n\nInternally, this function will:\n\nConstruct a graph where the vertices are the .jl files   under src, excluding the provided main file (i.e. where the module is   defined and the includes will sit in).\nEach file starting with a capital letter is assumed to   contain a struct with the same name as the file after   removal of the .jl suffix. Similarly, files starting   with @ are assumed to contain a macro with the similarly   obtained name.\nEach source file is inspected to see if the above struct and   macro strings are detected. This defines edges in the graph.  (known limitation: this includes spurious edges when e.g.   the string occurs in a comment).\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.split_slice-Tuple{UnitRange, Any}","page":"Reference","title":"Pigeons.split_slice","text":"split_slice(slice, rng)\n\n\nFrom one splittable random object, one can conceptualize an infinite list of splittable random objects.  Return a slice from this infinite list.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.step!-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.step!","text":"step!(explorer, replica, shared)\n\n\nPerform a transition on the given Replica  invariant with respect to the distribution of the  replica's chain. \n\nThe input explorer and Shared should only  be read, not written to. \n\nSee also find_log_potential. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.stepping_stone-Tuple{PT}","page":"Reference","title":"Pigeons.stepping_stone","text":"stepping_stone(pt)\n\n\nLet Z1 denote the normalization constant of the target, and Z0, of the reference, this  function approximates log(Z1/Z2) using the  stepping stone estimator  computed on the parallel tempering output. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.stepping_stone_pair-Tuple{PT}","page":"Reference","title":"Pigeons.stepping_stone_pair","text":"stepping_stone_pair(pt)\n\n\nReturn a pair, one such that its exponential is unbiased under  Assumptions (A1-2) in Syed et al., 2021 for Z and the  other, for 1Z.  Both are consistent in the number of MCMC iterations without these strong assumptions. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap!-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.swap!","text":"swap!(pair_swapper, replicas, swap_graph)\n\n\nFor each pair of chains encoded in swap_graph, use  pair_swapper to decide if the pair will swap or not,  and write the changes in-place into replicas (i.e. exchanging  the Replica's chain fields for those that swapped.)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap!-Tuple{Any, EntangledReplicas, Any}","page":"Reference","title":"Pigeons.swap!","text":"swap!(pair_swapper, replicas, swap_graph)\n\n\nEntangled MPI swap! implementation.\n\nThis implementation is designed to support distributed PT with the following guarantees\n\nThe running time is independent of the size of the state space      ('swapping annealing parameters rather than states')\nThe output is identical no matter how many MPI processes are used. In particular,      this means that we can check correctness by comparing to the serial, single-process version.\nScalability to 1000s of processes communicating over MPI (see details below).\nThe same function can be used when a single process is used and MPI is not available.\nFlexibility to extend PT to e.g. networks of targets and general paths.\n\nRunning time analysis:\n\nLet N denote the number of chains, P, the number of processes, and K = textceil(NP),   the maximum number of chains held by one process.  Assuming the running time is dominated by communication latency and  a constant time for the latency of each   peer-to-peer communication, the theoretical running time is O(K).  In practice, latency will grow as a function of P, but empirically, this growth appears to be slow enough that for say P = N = a few 1000s,  swapping will not be the computational bottleneck.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap!-Union{Tuple{R}, Tuple{Any, Vector{R}, Any}} where R","page":"Reference","title":"Pigeons.swap!","text":"swap!(pair_swapper, replicas, swap_graph)\n\n\nSingle process, non-allocating swap! implementation. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_acceptance_pr-Tuple{}","page":"Reference","title":"Pigeons.swap_acceptance_pr","text":"Average MH swap acceptance probabilities for each pairs  of interacting chains. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_decision-Tuple{Any, Int64, Any, Int64, Any}","page":"Reference","title":"Pigeons.swap_decision","text":"swap_decision(pair_swapper, chain1, stat1, chain2, stat2)\n\n\nGiven a pair_swapper, a recorders, the provided chain indices, and  the sufficient statistics computed by swap_stat(), make a swap decision.\n\nBy default, this is done as follows:\n\ncompute the standard swap acceptance probability min(1, exp(stat1.log_ratio + stat2.log_ratio))\nmake sure the two chains share the same uniform by picking the uniform from the chain with the smallest chain index \nswap if the shared uniform is smaller than the swap acceptance probability.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_decision-Tuple{Pigeons.TestSwapper, Int64, Float64, Int64, Float64}","page":"Reference","title":"Pigeons.swap_decision","text":"swap_decision(swapper, chain1, stat1, chain2, stat2)\n\n\nSee TestSwapper.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_stat-Tuple{Any, Pigeons.Replica, Int64}","page":"Reference","title":"Pigeons.swap_stat","text":"swap_stat(pair_swapper, replica, partner_chain)\n\n\nBy default, two sufficient statistics are computed and stored in the SwapStat struct:\n\nThe result of calling log_unnormalized_ratio() on pair_swapper\nA uniform number to coordinate the swap decision.\n\nThis can be extended by dispatching on other pair_swapper types, with the  constraint that the returned sufficient statistics should satisfy isbitstype().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_stat-Tuple{Pigeons.TestSwapper, Pigeons.Replica, Int64}","page":"Reference","title":"Pigeons.swap_stat","text":"swap_stat(swapper, replica, partner_chain)\n\n\nSee TestSwapper.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.tempering_recorder_builders-Tuple{Any}","page":"Reference","title":"Pigeons.tempering_recorder_builders","text":"tempering_recorder_builders(tempering)\n\n\nWhat information is needed to perform adapt_tempering? Answer this by specifying an iterator containing recorder_builder's.  Return [] if none are needed.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.timing_extrema-Tuple{}","page":"Reference","title":"Pigeons.timing_extrema","text":"Timing informations. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.toy_mvn_target-Tuple{Int64}","page":"Reference","title":"Pigeons.toy_mvn_target","text":"toy_mvn_target(dim)\n\n\nA toy multi-variate normal (mvn) target distribution used for testing. Uses a specialized path, ScaledPrecisionNormalPath, such that i.i.d. sampling is possible at all chains (via ToyExplorer).\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.toy_stan_target","page":"Reference","title":"Pigeons.toy_stan_target","text":"A multivariate normal implemented in Stan for testing/benchmarking.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.toy_turing_unid_target","page":"Reference","title":"Pigeons.toy_turing_unid_target","text":"A toy Turing model used for testing (unidentifiable 2-dim params for a bernoulli).\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.tppl_compile_model","page":"Reference","title":"Pigeons.tppl_compile_model","text":"tppl_compile_model(model_path; ...)\ntppl_compile_model(\n    model_path,\n    bin;\n    tpplc,\n    container_engine,\n    img_name,\n    local_exploration_steps,\n    use_global,\n    record_samples,\n    sampling_period,\n    cps,\n    align,\n    kernel,\n    drift,\n    globalProb\n)\n\n\nCompile a TreePPL model with a lightweight MCMC inference algorithm.\n\nThe arguments container_engine and img_name can be used to run the TreePPL compiler inside a Docker or Podman container. See TreePPLTarget for an example. Leave unset or set to nothing to use a local TreePPL installation. If your local TreePPL compiler is not available in your PATH point to it with the argument tpplc.\n\nThe rest of the function arguments map to command line arguments in the TreePPL compiler.  For more information, run tpplc --help in your terminal or visit treeppl.org.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.tppl_compile_samples-Tuple{AbstractString, Int64, AbstractString}","page":"Reference","title":"Pigeons.tppl_compile_samples","text":"tppl_compile_samples(output_dir, n_chains, output_file)\n\n\nCompile a TreePPL the samples from a TreePPL model into a single file. Use this method when you no longer have access to the PT instance but have access to the output directory and know the number of chains you ran.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.tppl_compile_samples-Tuple{PT, AbstractString}","page":"Reference","title":"Pigeons.tppl_compile_samples","text":"tppl_compile_samples(pt, output_file)\n\n\nCompile a TreePPL the samples from a TreePPL model into a single file. If one wishes, the output file can subsequently be post processed using TreePPL's  companion Python or R packages.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.tppl_construct_target","page":"Reference","title":"Pigeons.tppl_construct_target","text":"tppl_construct_target(binary, data_path)\ntppl_construct_target(binary, data_path, output_dir)\n\n\nConstruct a TreePPLTarget from a TreePPLBinary while keeping necessary metadata about how the binary was compiled.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.traces-Tuple{}","page":"Reference","title":"Pigeons.traces","text":"Save the full trace for the target chain in memory.  Call copy() on each state on the target chain. Index them by  the (chain index, scan index). \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.transmit!-Union{Tuple{T}, Tuple{Pigeons.Entangler, AbstractVector{T}, AbstractVector{Int64}, Vector{T}}} where T","page":"Reference","title":"Pigeons.transmit!","text":"transmit!(\n    e,\n    source_data,\n    to_global_indices,\n    write_received_data_here\n)\n\n\nUse MPI point-to-point communication to  permute the contents of source_data across MPI processes, writing the permuted data into  write_received_data_here.  The permutation is specified by the load balance in the input argument e as well as the  argument to_global_indices.\n\nMore precisely, assume the Vectors source_data, to_global_indices, and write_received_data_here  are all of the length specified in my_load(e.load). \n\nFor each i, source_data[i] is sent to MPI process p = find_process(e.load, g),  where g = to_global_indices[i] and  written into this p 's write_received_data_here[j], where j = find_local_index(e.load, g)\n\nSee Entangler's comments regarding the requirement that all machines call transmit() the  same number of times and at logically related intervals. \n\nAdditionally, at each micro-iteration, we assume that  {to_global_indices_p : p ranges over the different processes} forms a partition of  {1, ..., e.load.n_global_indices} If ran in single-process mode, this 'partition property' is checked;  if ran in multi-process, opportunistic checks will be made, namely when several entries in to_global_indices  lie in the same process, but systematic checks are not made for performance reasons. \n\nWe also assume isbitstype(T) == true. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.transmit-Union{Tuple{T}, Tuple{Pigeons.Entangler, AbstractVector{T}, AbstractVector{Int64}}} where T","page":"Reference","title":"Pigeons.transmit","text":"transmit(e, source_data, to_global_indices)\n\n\nThe same as transmit!() but instead of writing the result to an input argument, provide the result  as a returned Vector. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.update_reference!-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.update_reference!","text":"update_reference!(reduced_recorders, variational, state)\n\n\nUpdate the variational reference and the annealing path. Returns the new annealing path.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.update_state!-Tuple{Any, Symbol, Any, Any}","page":"Reference","title":"Pigeons.update_state!","text":"update_state!(state, name, index, value)\n\n\nUpdate the state's entry at symbol name and index with value.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.variable-Tuple{Any, Symbol}","page":"Reference","title":"Pigeons.variable","text":"variable(state, name)\n\n\nThe storage within the state of the variable of the given name, typically an Array.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.variational_deo-Tuple{Any, Any}","page":"Reference","title":"Pigeons.variational_deo","text":"variational_deo(n_chains_fixed, n_chains_var)\n\n\nImplements the Deterministic Even Odd (DEO) scheme but with two references  (one fixed and one variational) as in Surjanovic et al., 2022.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.variational_recorder_builders-Tuple{Any}","page":"Reference","title":"Pigeons.variational_recorder_builders","text":"variational_recorder_builders(variational)\n\n\nSpecify the recorder builders for this variational reference family.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.watch-Tuple{Result}","page":"Reference","title":"Pigeons.watch","text":"watch(result)\n\n\nPrint the standard out  and error streams for an MPI job. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.write_checkpoint-Tuple{Any}","page":"Reference","title":"Pigeons.write_checkpoint","text":"write_checkpoint(pt)\n\n\nIf pt.inputs.checkpoint == true, save a checkpoint under  [pt.exec_folder]/[unique folder]/round=[x]/checkpoint. \n\nBy default, pt.exec_folder is results/all/[unique folder].\n\nIn an MPI context, each MPI process will write its local replicas,  while only one of the MPI processes will write the Shared  and reduced recorders data. Moreover, only one MPI process will  write once at the first round the Inputs data. \n\nIn cases where the sampled model contains large immutable data, consider using  Immutable's to save disk space (Immutables will be written only by  one MPI process at the first round). \n\n\n\n\n\n","category":"method"},{"location":"reference/#RecipesBase.apply_recipe-Tuple{AbstractDict{Symbol, Any}, Dict{Int64, Vector{Int64}}}","page":"Reference","title":"RecipesBase.apply_recipe","text":"using Pigeons\nusing Plots \npt = pigeons(\n        target = toy_mvn_target(1), \n        record = [index_process], \n        n_rounds = 5)\nplot(pt.reduced_recorders.index_process)\n\n\n\n\n\n","category":"method"},{"location":"reference/#RecipesBase.apply_recipe-Tuple{AbstractDict{Symbol, Any}, LocalBarrier}","page":"Reference","title":"RecipesBase.apply_recipe","text":"using Pigeons\nusing Plots \npt = pigeons(target = toy_mvn_target(1))\nplot(pt.shared.tempering.communication_barriers.localbarrier)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Statistics.mean","page":"Reference","title":"Statistics.mean","text":"mean(pt)\nmean(pt, variable_name)\n\n\nthe online statistics are computed on the  result of calling extract_sample(). \n\n\n\n\n\n","category":"function"},{"location":"reference/#Statistics.var","page":"Reference","title":"Statistics.var","text":"var(pt)\nvar(pt, variable_name)\n\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.@abstract-Tuple{}","page":"Reference","title":"Pigeons.@abstract","text":"my_fct() = @abstract()\n\nDefine an abstract function (i.e. which gives an error message if calling it  is attempted). \n\n\n\n\n\n","category":"macro"},{"location":"reference/#Pigeons.@auto-Tuple{Any}","page":"Reference","title":"Pigeons.@auto","text":"Based on ConcreteStruct.jl, but (1) with a more descriptive name and   (2) outputs elided type information  (ConcreteStruct.jl has this feature but does not seem to work at the  moment). \n\n\n\n\n\n","category":"macro"},{"location":"reference/#Pigeons.@informal-Tuple{Symbol, Expr}","page":"Reference","title":"Pigeons.@informal","text":"@informal name begin ... end\n\nDocument an informal interface with provided name, and functions  specified in a begin .. end block. \n\n@informal will spit back the contents of the begin .. end block so  this macro can be essentially ignored at first read. \n\nWhen building documentation, this allows us to use the  function informal_doc() to automatically document the  informal interface.\n\n\n\n\n\n","category":"macro"},{"location":"reference/#Pigeons.@record_if_requested!-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.@record_if_requested!","text":"@record_if_requested!(recorders, recorder_key, value)\n\nSame behaviour as record_if_requested! but only evaluate  value when the recorder is present. \n\n\n\n\n\n","category":"macro"},{"location":"output-normalization/#output-normalization","page":"log(Z)","title":"Approximation of the normalization constant","text":"","category":"section"},{"location":"output-normalization/#Background","page":"log(Z)","title":"Background","text":"Let pi(x) denote a probability density called the target.  In many problems, e.g. in Bayesian statistics, the density pi is typically  known only up to a normalization constant, \n\npi(x) = fracgamma(x)Z\n\nwhere gamma can be evaluated pointwise, but Z is unknown.\n\nIn many applications, it is useful to approximate the constant Z. For  example, in Bayesian statistics, this corresponds to the  marginal likelihood, and it is used for model selection. ","category":"section"},{"location":"output-normalization/#Normalization-constant-approximation-in-Pigeons","page":"log(Z)","title":"Normalization constant approximation in Pigeons","text":"As a side-product of parallel tempering, we automatically obtain an approximation of the logarithm of the normalization constant log Z. This is done automatically using the  stepping stone estimator computed in stepping_stone(). \n\nIt is shown in the standard output report produced at each round:\n\nusing DynamicPPL\nusing Pigeons\n\n# example target: Binomial likelihood with parameter p = p1 * p2\nan_unidentifiable_model = Pigeons.toy_turing_unid_target(100, 50)\n\npt = pigeons(target = an_unidentifiable_model)\n\nnothing # hide\n\nand can also be accessed using:\n\nstepping_stone(pt)","category":"section"},{"location":"output-normalization/#From-ratios-to-normalization-constants","page":"log(Z)","title":"From ratios to normalization constants","text":"To be more precise, the steppping stone estimator computes the  log of the ratio, log (Z_1 Z_0) where Z_1 and Z_0 are the normalization constants of the target and reference respectively. \n\nHence to estimate log Z_1 the reference distribution pi_1 should have a known normalization constant. In cases where the reference is a proper prior distribution, for example in Turing.jl models, this is typically the case. \n\nIn scenarios where the reference is specified manually, e.g. for black-box functions or Stan models, more care is needed. In such cases, one alternative is to use variational PT in which case the built-in variational distribution is constructed so that its normalization constant is one. \n\nnote: Normalization of Stan models\nBridgeStan offers an option propto to skip constants  that do not depend on the sampled parameters. Every calls  to BridgeStan made by Pigeons disable this option to make  it easier to design reference distributions with a known  normalization constant. ","category":"section"},{"location":"distributed/#distributed","page":"More on distributed PT","title":"Distributed and parallel implementation of PT","text":"","category":"section"},{"location":"distributed/#Introduction","page":"More on distributed PT","title":"Introduction","text":"Pigeons provides an implementation of Distributed PT based on Syed et al., 2021,  Algorithm 5. This page describes our strategies for addressing the challenges of implementing this distributed,  parallelized, and randomized algorithm.\n\nnote: Note\nRead this page if you are interested in extending Pigeons or  understanding how it works under the hood.  Reading this page is not required to use Pigeons. Instead, refer to the  user guide. \n\nIn Distributed PT, one or several computers run MCMC simulations in parallel and  communicate with each other to improve MCMC efficiency.  We use the terminology machine for one of these computers, or, to be more precise,  process. In the typical setting, each machine will run one process, since our implementation also supports  the use of several Julia threads.\n\nPigeons is designed so that it is suitable in all these scenarios:\n\none machine running PT on one thread,\none machine running PT on several threads,\nseveral machines running PT, each using one thread, and\nseveral machines running PT, each using several threads.\n\nEnsuring code correctness at the intersection of randomized, parallel, and distributed algorithms is a challenge.  To address this challenge, we designed Pigeons based on the following principle:\n\nnote: Parallelism Invariance\nThe output of Pigeons is invariant to the number of machines and/or threads.\n\nIn other words, if X_m t(s) denotes the output of Pigeons when provided m machines, t threads  per machine, and random seed s, we guarantee that X_m t(s) = X_m t(s) for all m t. \n\nWithout explicitly keeping Parallelism Invariance in mind during software construction,  parallel/distributed implementations of randomized algorithms will  typically only guarantee EX_m t = EX_m t for all m m t t. While equality in distribution is technically  sufficient, the stronger pointwise equality required by Parallelism Invariance makes  debugging and software validation considerably easier.  This is because the developer can first focus on the fully serial randomized algorithm,  and then use it as an easy-to-compare gold-standard reference for parallel/distributed  implementations.  This strategy is used extensively in Pigeons to ensure correctness.  In contrast, testing equality in distribution, while possible (e.g., see  Geweke, 2004), incurs additional  false negatives due to statistical error. \n\nTwo factors tend to cause violations of Parallelism Invariance: \n\nGlobal, thread-local and task-local random number generators (the dominant approaches to parallel   random number generators in current languages).\nNon-associativity of floating point operations. As a result, when several workers    perform Distributed reduction of    floating point values, the output of this reduction will be slightly different.    When these reductions are then fed into further random operations, this implies    two randomized algorithms with the same seed but using a different number of workers    will eventually arbitrarily diverge pointwise. \n\nOne focus in the remainder of this page is to describe how our implementation sidesteps  the two above issues while maintaining the same asymptotic runtime complexity.","category":"section"},{"location":"distributed/#Overview-of-the-algorithm","page":"More on distributed PT","title":"Overview of the algorithm","text":"Let us start with a high-level picture of the distributed PT algorithm. \n\nThe high-level code is the function pigeons() which is identical to the single-machine algorithm.  A first difference lay in the replicas datastructure taking on a different type. Also, as promised the  output is identical despite a vastly different swap logic: this can be checked using the checked_round  argument described in the user guide.  A second difference between the execution of pigeons() in single vs many machine context is the behaviour  of swap! which is dispatched  based on the type of  replicas. \n\nIn the following, we go over the main building block of  our distributed PT algorithm. ","category":"section"},{"location":"distributed/#Splittable-random-streams","page":"More on distributed PT","title":"Splittable random streams","text":"The first building block is a splittable random stream.  To motivate splittable random streams, consider the following example violating Parallelism Invariance.\n\nJulia uses task-local random number generators, a notion which  is related but distinct from parallelism invariance.  We will now explain the difference between task-local random number  generators and parallelism invariance, and why the latter is more  advantageous for checking correctness of distributed randomized algorithms. \n\nConsider the following toy example:\n\nusing Random\nimport Base.Threads.@threads\n\nprintln(\"Number of threads: $(Threads.nthreads())\")\n\nconst n_iters = 10000;\nresult = zeros(n_iters);\nRandom.seed!(1);\n@threads for i in 1:n_iters\n    # in a real problem, do some expensive calculation here...\n    result[i] = rand();\nend\nprintln(\"Result: $(last(result))\")\n\nWhen using 8 threads, this outputs:\n\nNumber of threads: 8\nResult: 0.25679999169092793\n\nJulia guarantees that if we rerun this code, as long as we  are using 8 threads, we will always get the same result,  irrespective of the multi-threading scheduling decisions  implied by the @threads-loop (hence, a step ahead another  concept known as thread-local random number generation, which does not guarantee replicability even for a fixed number of  threads). \n\nHowever, when we use a different number of threads (e.g.,  the key example is one thread), the result is different:\n\nNumber of threads: 1\nResult: 0.8785201210435906\n\nIn this simple example above, it is not a big deal, but for our parallel tempering use case, the  distributed version of the algorithm is significantly more complex and  harder to debug compared to the single-threaded one. Hence we take  task-local random number generation one step further, into parallelism  invariance, which will guarantee that the output is not only  reproducible with respect to repetitions for a fixed number of threads,  but also for different numbers of threads. \n\nIn our context, a first step to achieve this is to associate one random number generator to each PT chain. To do so, we use the  SplittableRandoms.jl library which allows  us to turn one seed into an arbitrary collection pseudo-independent random number generators.  Since each MPI process holds a subset of the chains, we internally use the  function split_slice() to  get the random number generators for the slice of replicas held in a given MPI process.","category":"section"},{"location":"distributed/#Distributed-replicas","page":"More on distributed PT","title":"Distributed replicas","text":"Calling create_entangled_replicas() will produce a fresh EntangledReplicas,  taking care of distributed random seed splitting internally.  An EntangledReplicas contains the list of replicas that are local to the machine, in addition to three data structures allowing distributed communication:  a LoadBalance which keeps track of  how to split work across machines; an Entangler, which encapsulates MPI calls;  and a PermutedDistributedArray, which   maps chain indices to replica indices. These datastructures can be obtained using load(), entangler(), and  replicas.chain_to_replica_global_indices respectively.","category":"section"},{"location":"distributed/#Distributed-swaps","page":"More on distributed PT","title":"Distributed swaps","text":"To perform distributed swaps, swap!() proceeds as follows:\n\nUse the swap_graph to determine swapping partner chains,\ntranslate partner chains into partner replicas (global indices) using  replicas.chain_to_replica_global_indices,\ncompute swap_stat() for local chains, and use   transmit() to obtain partner swap stats,\nuse swap_decision() to decide if each pair should swap, and \nupdate the replicas.chain_to_replica_global_indices datastructure. ","category":"section"},{"location":"distributed/#Distributed-reduction","page":"More on distributed PT","title":"Distributed reduction","text":"After each round of PT, the workers need to exchange richer messages compared to the information exchanged in the swaps.  These richer messages include swap acceptance probabilities,  statistics to adapt a variational reference, etc. \n\nThis part of the communication is performed using reduce_recorders!() which  in turn calls all_reduce_deterministically() with the appropriate   merging operations. See reduce_recorders!() and  all_reduce_deterministically() for more information on how  our implementation preserves Parallelism Invariance, while maintaining the logarithmic runtime of binary-tree based  collective operations. (More precisely, all_reduce_deterministically() runs in time log(N)  when each machine holds a single chain.)","category":"section"},{"location":"output-extended/#output-extended","page":"Extended output","title":"Extended output (i.e., for all chains)","text":"So far when outputting traces (either to memory via traces or to disk via disk),  we have been storing only the target distribution's samples.  This is the most common scenario and the default.  Here we show how to instead store the samples from all chains. \n\nThis can be useful in scenarios where all distributions pi_i are of interest, e.g.  in certain statistical mechanics applications and for Bayesian inference under model  mis-specification. \n\nThe key argument to add is extended_traces = true, which we demonstrate for  various common scenarios below.","category":"section"},{"location":"output-extended/#Posterior-densities-and-trace-plots-for-all-chains","page":"Extended output","title":"Posterior densities and trace plots for all chains","text":"Make sure to have the third party DynamicPPL, MCMCChains, and StatsPlots packages installed via \n\nusing Pkg; Pkg.add(\"DynamicPPL\", \"MCMCChains\", \"StatsPlots\")\n\nThen use the following:\n\nusing DynamicPPL\nusing Pigeons\nusing MCMCChains\nusing StatsPlots\nplotlyjs()\n\n# example target: Binomial likelihood with parameter p = p1 * p2\nan_unidentifiable_model = Pigeons.toy_turing_unid_target(100, 50)\n\npt = pigeons(target = an_unidentifiable_model, \n                n_rounds = 12,\n                extended_traces = true, \n                # make sure to record the trace:\n                record = [traces; round_trip; record_default()])\n\n# collect the statistics and convert to MCMCChains' Chains\n# to have axes labels matching variable names in Turing and Stan\nsamples = Chains(pt)\n\n# create the trace plots\nmy_plot = StatsPlots.plot(samples)\nStatsPlots.savefig(my_plot, \"posterior_densities_and_traces_extended.html\"); \nnothing # hide\n\nHere the ten different colours correspond to the 10 chains interpolating between  the posterior and the prior (here a uniform distribution).\n\n<iframe src=\"../posterior_densities_and_traces_extended.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"output-extended/#Off-memory-processing-for-all-chains","page":"Extended output","title":"Off-memory processing for all chains","text":"The same option, extended_traces = true can  be used in the same fashion to save to disk  samples from all chains:\n\nusing Pigeons\n\n# example target: a 1000 dimensional target\nhigh_d_target = Pigeons.toy_mvn_target(1000)\n\npt = pigeons(target = high_d_target, \n                checkpoint = true,\n                extended_traces = true,\n                record = [disk])\n\nfirst_dim_of_each = zeros(10, 1024)\nprocess_sample(pt) do chain, scan, sample # ordered as if we had an inner loop over scans\n    # each sample here is a Vector{Float64} of length 1000 \n    # in general, it will is produced by extract_sample()\n    first_dim_of_each[chain, scan] = sample[1]\nend","category":"section"},{"location":"output-extended/#Accessing-the-annealing-parameters","page":"Extended output","title":"Accessing the annealing parameters","text":"To obtain the annealing parameter used to define each intermediate distribution, use:\n\nusing Pigeons\n\nan_unidentifiable_model = Pigeons.toy_turing_unid_target(100, 50)\n\npt = pigeons(target = an_unidentifiable_model)\n\npt.shared.tempering.schedule","category":"section"},{"location":"output-mpi-postprocessing/#output-mpi-postprocessing","page":"MPI output","title":"Post-processing for MPI runs (plotting, summaries, etc)","text":"Two options are available to post-process samples produced from  MPI runs: (1) loading   the distributed output back into your interactive shell, or (2) perform post-processing by loading samples from disk one at a time. \n\nOption (1) is more convenient than (2) but it uses more RAM.","category":"section"},{"location":"output-mpi-postprocessing/#Loading-the-distributed-output-back-into-your-interactive-shell","page":"MPI output","title":"Loading the distributed output back into your interactive shell","text":"Many of Pigeons' post-processing tools take as input a PT struct. When running locally, pigeons() returns a PT struct,  however, when running a job via MPIProcesses or ChildProcess,  pigeons() returns a Result struct (which only holds the   directory where samples are stored). \n\nUse Pigeons.load(..) to convert a Result into a  PT struct.  This will load the information distributed across several machines  into the interactive node.\n\nOnce you have a PT struct, proceed in the same way as  when running PT locally, e.g. see the page on plotting,  the page on online statistics,  and the page on sample summaries and diagnostics.\n\nFor example, here is how to modify the posterior density and trace plot  example from the plotting page to run as a local MPI job  instead of in-process (the lines differing from the local version are marked  with (*)):\n\nusing DynamicPPL\nusing Pigeons\nusing MCMCChains\nusing StatsPlots\nplotlyjs()\n\n# example target: Binomial likelihood with parameter p = p1 * p2\nan_unidentifiable_model = Pigeons.toy_turing_unid_target(100, 50)\n\npt_result = pigeons(target = an_unidentifiable_model, \n                # (*) run in two new MPI processes \n                # make sure the MPI processes load DynamicPPL\n                on = ChildProcess(n_local_mpi_processes = 2, dependencies=[DynamicPPL]), \n                # (*) signal that we want the PT object to be \n                #     serialized at the end of each round\n                checkpoint = true,\n                n_rounds = 12,\n                # make sure to record the trace \n                # (each machine keeps its own during sampling)\n                record = [traces; round_trip; record_default()])\n\n# (*) load the result across all machines into this interactive node\npt = Pigeons.load(pt_result)\n\n# collect the statistics and convert to MCMCChains' Chains\n# to have axes labels matching variable names in Turing and Stan\nsamples = Chains(pt)\n\n# create the trace plots\nmy_plot = StatsPlots.plot(samples)\nStatsPlots.savefig(my_plot, \"mpi_posterior_densities_and_traces.html\"); \nnothing # hide\n\n<iframe src=\"../mpi_posterior_densities_and_traces.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"output-mpi-postprocessing/#Perform-post-processing-by-loading-samples-from-disk-one-at-a-time","page":"MPI output","title":"Perform post-processing by loading samples from disk one at a time","text":"Here instead of keeping samples in memory, we instruct the machines to  store them on the fly in a shared directory.  We do this using the disk recorder. \n\nThen we process the sample one at the time using process_sample(). \n\nHere is an example where the target is 1000-dimensional but we are only  interested in the first coordinate:\n\nusing Pigeons\nusing Plots\n\n# example target: a 1000 dimensional target\nhigh_d_target = Pigeons.toy_mvn_target(1000)\n\npt_result = pigeons(target = high_d_target, \n                # run in two new MPI processes \n                on = ChildProcess(n_local_mpi_processes = 2), \n                checkpoint = true,\n                # save samples to disk as we go\n                record = [disk])\n\n# process the samples one by one, keeping only the first dimension\nfirst_dim_of_each = Vector{Float64}()\nprocess_sample(pt_result) do chain, scan, sample\n    # each sample here is a Vector{Float64} of length 1000 \n    # in general, it will is produced by extract_sample()\n    push!(first_dim_of_each, sample[1])\nend\n\nplotlyjs()\nmyplot = Plots.plot(first_dim_of_each)\nPlots.savefig(myplot, \"first_dim_of_each.html\"); \nnothing # hide\n\n<iframe src=\"../first_dim_of_each.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"output-overview/#output-overview","page":"Outputs overview","title":"Manipulating the output of pigeons","text":"Pigeons supports several methods to post-process the output of parallel tempering, including convenient methods that  store in memory all the samples,  as well as memory efficient  methods using either the disk or  constant-memory statistics. \n\nAutomated reports\nInterpreting pigeons' standard output\nWorking with traces\nCreating plots.\nApproximation of the normalization constant.\nNumerical summaries and diagnostics.\nOnline (constant-memory) statistics.\nOff-memory processing.\nPT-specific diagnostics.\nPost-processing for MPI runs.\nOutput for custom types.\nExtended output, i.e. including non-target chains\nFurther customization using \"recorders\".","category":"section"},{"location":"input-overview/#input-overview","page":"Inputs overview","title":"Overview: inputting an integral/expectation problem into pigeons","text":"Pigeons takes as input an expectation or integration problem. Pigeons supports a wide range of methods for specifying the input problem,  described in the pages below. \n\nTuring.jl model: a succinct specification of a joint distribution from which a posterior (target) and prior (reference) are extracted. \nBlack-box Julia function: less automated, but more general and fully configurable. \nStan model: a convenient adaptor for the most popular Bayesian modelling language. \nMCMC code implemented in another language: bridging your MCMC code to pigeons to make it distributed and parallel. \nCustomize the MCMC explorers used by PT.\n\nWe exemplify these different input methods on a recurrent example:  an unidentifiable toy model,  see the page describing the recurrent example in more details. ","category":"section"},{"location":"variational/#variational-pt","page":"Variational PT","title":"Variational PT","text":"We describe here the implementation  of Variational PT, Surjanovic et al., 2022 included in Pigeons.  Both the basic variational PT and stabilized variants  introduced in  Surjanovic et al., 2022 are available. ","category":"section"},{"location":"variational/#Basic-variational-PT","page":"Variational PT","title":"Basic variational PT","text":"Enable variational PT by supplier the variational option  to pigeons(...):\n\nusing DynamicPPL\nusing Pigeons\n\npigeons(\n    target = Pigeons.toy_turing_unid_target(100, 50), \n    variational = GaussianReference(first_tuning_round = 5))\nnothing # hide\n\nNote variational fitting only starts at first_tuning_round.  The fixed reference is used before that point.","category":"section"},{"location":"variational/#Stabilized-variational-PT","page":"Variational PT","title":"Stabilized variational PT","text":"Surjanovic et al., 2022 describes situations where the variational fitting can  cause catastrophic forgetting of modes.  This is remediated by using both a fixed and a variational  reference each linked to two copies of the target, which  are also swapped according to a non-reversible swapping  scheme. \n\nEnable stabilized variational PT by adding the n_chains_variational option  to pigeons(...):\n\npigeons(\n    target = Pigeons.toy_turing_unid_target(100, 50), \n    variational = GaussianReference(first_tuning_round = 5), \n    n_chains_variational = 10)\nnothing # hide","category":"section"},{"location":"input-stan/#input-stan","page":"Stan model","title":"Stan model as input to pigeons","text":"note: Note\nWe use the package BridgeStan.jl as a package extension which will attempt  to automatically install Stan.  For BridgeStan.jl to work, a C++ compiler and  make are needed, see  the BridgeStan requirements.\n\nTo target the posterior distribution specified by  a Stan model, use  a StanLogPotential. \n\nHere we show how this is done using our familiar unidentifiable toy example ported to the Stan language.\n\nusing BridgeStan\nusing Pigeons \nusing Random\n\n# We will use this type to make sure our iid sampler (next section) will \n# be used only for this model\nstruct StanUnidentifiableExample end\n\nfunction stan_unid(n_trials, n_successes)\n    # path to a .stan file (compiled files will be cached in the same directory)\n    stan_file = dirname(dirname(pathof(Pigeons))) * \"/examples/stan/unid.stan\"\n\n    # data can be specified either using...\n    #   - a path to a json file with suffix .json containing the data to condition on\n    #   - the JSON string itself (here via the utility Pigeons.json())\n    stan_data = Pigeons.json(; n_trials, n_successes)\n\n    return StanLogPotential(stan_file, stan_data, StanUnidentifiableExample())\nend\n\npt = pigeons(target = stan_unid(100, 50), reference = stan_unid(0, 0))\nnothing #hide\n\nNotice that we have specified a reference distribution, in this case the same model but with  no observations (hence the prior). This needs to be done with Stan targets because it is  not possible to automatically extract a prior from a .stan file. \n\nFor a StanLogPotential, the default_explorer() is AutoMALA[1]. ","category":"section"},{"location":"input-stan/#Sampling-from-the-reference-distribution","page":"Stan model","title":"Sampling from the reference distribution","text":"Ability to sample from the reference distribution can be beneficial, e.g. to jump modes  in multi-modal distribution.  For stan targets, this is done as follows:\n\nusing BridgeStan\n\nfunction Pigeons.sample_iid!(\n        log_potential::StanLogPotential{M, S, D, StanUnidentifiableExample}, replica, shared) where {M, S, D}\n    # sample in constrained space\n    constrained = rand(replica.rng, 2)\n    # transform to unconstrained space\n    replica.state.unconstrained_parameters .= BridgeStan.param_unconstrain(log_potential.model, constrained)\nend\n\npt = pigeons(target = stan_unid(100, 50), reference = stan_unid(0, 0))\nnothing # hide","category":"section"},{"location":"input-stan/#Manipulating-the-output","page":"Stan model","title":"Manipulating the output","text":"Internally, Stan target's states are stored in an unconstrained  parameterization provided by Stan  (for example, bounded support variables are mapped to the full real line).  However, sample post-processing functions such as sample_array() and process_sample()  convert back to the original (\"constrained\") parameterization via extract_sample(). \n\nAs a result parameterization issues can be essentially ignored when post-processing, for example some  common post-processing are shown below, see the section on output processing for more information. \n\nusing MCMCChains\nusing StatsPlots\nplotlyjs()\n\npt = pigeons(\n        target = stan_unid(100, 50), \n        reference = stan_unid(0, 0), \n        record = [traces])\nsamples = Chains(pt)\nmy_plot = StatsPlots.plot(samples)\nStatsPlots.savefig(my_plot, \"stan_posterior_densities_and_traces.html\"); \n\nsamples\n\n<iframe src=\"../stan_posterior_densities_and_traces.html\" style=\"height:500px;width:100%;\"></iframe>\n\n[1]: Biron-Lattes, M., Surjanovic, N., Syed, S., Campbell, T., & Bouchard-Côté, A.. (2024). autoMALA: Locally adaptive Metropolis-adjusted Langevin algorithm. Proceedings of The 27th International Conference on Artificial Intelligence and Statistics, in Proceedings of Machine Learning Research 238:4600-4608.","category":"section"},{"location":"output-reports/#output-reports","page":"Standard output","title":"Interpreting pigeons' standard output","text":"During the execution of parallel tempering, interim diagnostics  can be computed and printed to standard out at the end of every iteration (this can be disabled using show_report = false):\n\nusing Pigeons\n\npigeons(target = toy_mvn_target(100))\nnothing # hide\n\nThe functions called to emit each of these can  be found at all_reports(). Some key quantities:\n\nΛ: the global communication barrier, as described in Syed et al., 2021 and estimated using the sum of rejection estimator analyzed in the same reference. Syed et al., 2021 also developed a rule of thumb to configure the number of chains: PT should be set to roughly 2Λ. \ntime and allc: the time (in second) and allocation (in bytes) used in each round. \nlog(Z₁/Z₀): the stepping_stone() estimator for the log of the normalization constant, see the documentation page on approximation of the normalization constant. \nmin(α) and mean(α): minimum and average swap acceptance rates over the PT chains. \n\nAdditional statistics can be shown when more recorders  are added. For example, to accumulate other constant-memory summary statistics:\n\npigeons(target = toy_mvn_target(100), record = record_online(), explorer = AutoMALA())\nnothing # hide\n\nmax|ρ| and mean|ρ|: maximum and average (across chains) correlation of the random variables L^t_i = V(X_i) and L^t+1_i = V(X_i) where V = log pi_N  pi_1, X_i sim pi_beta_i, and t t+1 are indices just before and after a call to step!(). \nmin(αₑ) and mean(αₑ): minimum and average (across chains) of the explorer's acceptance rates. ","category":"section"},{"location":"output-reports/#Programmatic-access","page":"Standard output","title":"Programmatic access","text":"The tables described above can also be accessed as a DataFrame via:\n\nusing Pigeons\npt = pigeons(target = toy_mvn_target(100))\npt.shared.reports.summary\n\nDetailed statistics can be accessed via these DataFrames.  For example  to obtain mean swap acceptance probabilities for each round and  pair of communicating chains, use:\n\nfirst(pt.shared.reports.swap_prs, 20)\n\nCreating a plot from this:\n\nusing StatsPlots\nplotlyjs()\nmy_plot =  @df pt.shared.reports.swap_prs StatsPlots.plot(:round, :mean, group = :first)\nStatsPlots.savefig(my_plot, \"swap_prs.html\"); \nnothing # hide\n\n<iframe src=\"../swap_prs.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"#index","page":"Basic usage (local)","title":"Pigeons","text":"","category":"section"},{"location":"#Summary","page":"Basic usage (local)","title":"Summary","text":"Pigeons is a Julia package to approximate challenging posterior distributions, and more broadly, Lebesgue integration problems. Pigeons can be used in a multi-threaded context, and/or distributed over hundreds or thousands of MPI-communicating machines.\n\nPigeons supports many different ways to specify integration/expectation problems and  provides rich and configurable output. \n\nPigeons' core algorithm is a distributed and parallel implementation  of the following algorithms: \n\nNon-Reversible Parallel Tempering (NRPT),    Syed et al., 2021.\nVariational parallel tempering (Variational PT), Surjanovic et al., 2022. \nautoMALA, Biron-Lattes et al., 2024.\n\nThese algorithms achieve state-of-the-art performance for approximation  of challenging probability distributions.\n\nnote: Note\nWe are recruiting graduate students! Click here for more information.","category":"section"},{"location":"#installing-pigeons","page":"Basic usage (local)","title":"Installing Pigeons","text":"If you have not done so, install Julia. Julia 1.8 and higher are supported. \nInstall Pigeons using\n\nusing Pkg; Pkg.add(\"Pigeons\")","category":"section"},{"location":"#Basic-usage","page":"Basic usage (local)","title":"Basic usage","text":"Specify the target distribution and, optionally,  parameters like random seed, etc by creating an  Inputs:\n\nusing Pigeons\n\ninputs = Inputs(target = toy_mvn_target(100))\n\nHave a look at the Inputs documentation for an overview of the many options available to configure pigeons. You will find information there on setting the random seed,  controlling the number of iterations (via n_rounds),  and many more options\n\nThen, run parallel tempering (PT) locally on one process using the function pigeons():\n\npt = pigeons(inputs);\nnothing # hide\n\nThis runs PT on a 100-dimensional MVN toy example with 10 chains  for 2047 = 2^11 - 1 iterations, and  returns a PT struct containing the results of  this run (more later on how to access information inside  a PT struct). Each line in the output provides information on a round, where the number of iteration  per round doubles at each round and adaptation is performed  between rounds. \n\nSince the above two julia lines are the most common operations in this package, creating inputs and running PT can be done in one line  as follows:\n\npt = pigeons(target = toy_mvn_target(100));\nnothing # hide\n\nwhere the args... passed to pigeons are forwarded  to Inputs.\n\nContinuing on the above example, to perform two additional rounds of sampling, use the following (see also: more advanced checkpoint/resume options at the checkpoint page):\n\npt = increment_n_rounds!(pt, 2)\npigeons(pt)\nnothing # hide","category":"section"},{"location":"#Scope","page":"Basic usage (local)","title":"Scope","text":"We describe here the class of problems that can be approached using Pigeons.  In summary: computational Lebesgue integration.\n\nLet pi(x) denote a probability density called the target.  In many problems, e.g. in Bayesian statistics, the density pi is typically  known only up to a normalization constant, \n\npi(x) = fracgamma(x)Z\n\nwhere gamma can be evaluated pointwise, but Z is unknown. Pigeons takes as input the function gamma.\n\n!!! terminology log_potential\n\nSince we work in log-scale, we use the terminology \n`log_potential` as a shorthand for the \nunnormalized log density ``\\log \\gamma(x)``. \nSee informal interface [`log_potential`](@ref).\n\nPigeons' outputs can be used for two tasks:\n\nApproximating expectations of the form Ef(X), where X sim pi.    For example, the choice f(x) = x computes the mean, and    f(x) = Ix in A computes the probability of A under pi.   See manipulating the output of pigeons\nApproximating the value of the normalization constant Z. For    example, in Bayesian statistics, this corresponds to the    marginal likelihood. See approximation of the normalization constant\n\nPigeons shines in the following scenarios:\n\nWhen the posterior density pi is challenging due to    non-convexity and/or concentration on a    sub-manifolds due to unidentifiability.\nWhen the user needs not only Ef(X) but also Z. Many existing MCMC tools   focus on the former and struggle to do the latter in high dimensional    problems. \nWhen the posterior density pi is defined over a non-standard state-space,    e.g. a combinatorial object such as a phylogenetic tree.   See defining custom explorers    and targeting non-julian models.","category":"section"},{"location":"#How-to-cite-Pigeons","page":"Basic usage (local)","title":"How to cite Pigeons","text":"Our team works hard to maintain and improve the Pigeons package. Please consider  citing our work by referring to our Pigeons paper.\n\nBibTeX code for citing Pigeons\n\n@article{surjanovic2023pigeons,\n  title={Pigeons.jl: {D}istributed sampling from intractable distributions},\n  author={Surjanovic, Nikola and Biron-Lattes, Miguel and Tiede, Paul and Syed, Saifuddin and Campbell, Trevor and Bouchard-C{\\^o}t{\\'e}, Alexandre},\n  journal={arXiv:2308.09769},\n  year={2023}\n}\n\nAPA\n\nSurjanovic, N., Biron-Lattes, M., Tiede, P., Syed, S., Campbell, T., & Bouchard-Côté, A. (2023). Pigeons.jl: Distributed sampling from intractable distributions. arXiv:2308.09769.","category":"section"},{"location":"output-plotting/#output-plotting","page":"Plots","title":"Plotting","text":"Use sample_array() to convert target chain  samples into a format that can then be consumed by  third party plotting packages such as  MCMCChains.jl  and PairPlots.jl.\n\nSee below for examples of posterior densities and trace plots.","category":"section"},{"location":"output-plotting/#Posterior-densities-and-trace-plots","page":"Plots","title":"Posterior densities and trace plots","text":"Make sure to have the third party DynamicPPL, MCMCChains, and StatsPlots packages installed via\n\nusing Pkg; Pkg.add(\"DynamicPPL\", \"MCMCChains\", \"StatsPlots\")\n\nThen use the following:\n\nusing DynamicPPL\nusing Pigeons\nusing MCMCChains\nusing StatsPlots\nplotlyjs()\n\n# example target: Binomial likelihood with parameter p = p1 * p2\nan_unidentifiable_model = Pigeons.toy_turing_unid_target(100, 50)\n\npt = pigeons(target = an_unidentifiable_model, \n                n_rounds = 12,\n                # make sure to record the trace:\n                record = [traces; round_trip; record_default()])\n\n# collect the statistics and convert to MCMCChains' Chains\n# to have axes labels matching variable names in Turing and Stan\nsamples = Chains(sample_array(pt), sample_names(pt))\n\n# since the above line is frequently needed, Pigeons includes \n# an MCMCChains extension allowinging you to use the shorter form:\nsamples = Chains(pt)\n\n# create the trace plots\nmy_plot = StatsPlots.plot(samples)\nStatsPlots.savefig(my_plot, \"posterior_densities_and_traces.html\"); \nnothing # hide\n\n<iframe src=\"../posterior_densities_and_traces.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"output-plotting/#Monitoring-the-log-density","page":"Plots","title":"Monitoring the log density","text":"The value of the log density is appended to each sample. Continuing the  above example, this can be seen  from the variable names indexing the flattened vector created by  sample_array():\n\nsample_names(pt)\n\nWhen using the Chains(pt) constructor as shown above, the  un-normalized log density is stored inside MCMCChains' \"internal\"  storage so will not appear in plots by default. To show it, use the following:\n\nparams, internals = MCMCChains.get_sections(samples) \n\nmy_plot = StatsPlots.plot(internals)\nStatsPlots.savefig(my_plot, \"logdensity.html\"); \nnothing # hide\n\n<iframe src=\"../logdensity.html\" style=\"height:500px;width:100%;\"></iframe>","category":"section"},{"location":"output-plotting/#Posterior-pair-plots","page":"Plots","title":"Posterior pair plots","text":"note: Note\nThe code snippet in this section only works with Julia 1.9.  See https://sefffal.github.io/PairPlots.jl/dev/chains/ for a workaround.\n\nMake sure to have the third party packages DynamicPPL, MCMCChains, CairoMakie, and PairPlots installed via \n\nusing Pkg; Pkg.add(\"DynamicPPL\", \"MCMCChains\", \"CairoMakie\", \"PairPlots\")\n\nusing DynamicPPL\nusing Pigeons\nusing MCMCChains\nusing CairoMakie\nusing PairPlots\n\n# same examples as last section\nan_unidentifiable_model = Pigeons.toy_turing_unid_target(100, 50)\n\npt = pigeons(target = an_unidentifiable_model, \n                n_rounds = 12,\n                # make sure to record the trace:\n                record = [traces; round_trip; record_default()])\n\nsamples = Chains(pt)\n# Warning: the line below only works for Julia 1.9\n#          see https://sefffal.github.io/PairPlots.jl/dev/chains/ for a workaround\nmy_plot = PairPlots.pairplot(samples) \n\nCairoMakie.save(\"pair_plot.svg\", my_plot)\nnothing # hide\n\n<iframe src=\"../pair_plot.svg\" style=\"height:500px;width:100%;\"></iframe>","category":"section"}]
}
