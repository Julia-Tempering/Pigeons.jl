<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Guide · Pigeons.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://Julia-Tempering.github.io/Pigeons.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>Pigeons.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Guide</a><ul class="internal"><li><a class="tocitem" href="#Scope"><span>Scope</span></a></li><li><a class="tocitem" href="#Installing-Pigeons"><span>Installing <code>Pigeons</code></span></a></li><li><a class="tocitem" href="#Running-PT"><span>Running PT</span></a></li><li><a class="tocitem" href="#Estimating-the-log-normalization-constant"><span>Estimating the log normalization constant</span></a></li><li><a class="tocitem" href="#Accessing-the-output-of-PT"><span>Accessing the output of PT</span></a></li><li><a class="tocitem" href="#Loading-and-resuming-a-checkpoint"><span>Loading and resuming a checkpoint</span></a></li><li><a class="tocitem" href="#Automatic-correctness-checks"><span>Automatic correctness checks</span></a></li><li><a class="tocitem" href="#Running-MPI-locally"><span>Running MPI locally</span></a></li><li><a class="tocitem" href="#Running-MPI-on-a-cluster"><span>Running MPI on a cluster</span></a></li><li><a class="tocitem" href="#Specification-of-general-models"><span>Specification of general models</span></a></li><li><a class="tocitem" href="#Targeting-a-Turing.jl-model"><span>Targeting a Turing.jl model</span></a></li><li><a class="tocitem" href="#Targeting-a-non-Julian-model"><span>Targeting a non-Julian model</span></a></li></ul></li><li><a class="tocitem" href="pt/">Parallel Tempering (PT)</a></li><li><a class="tocitem" href="distributed/">Distributed PT</a></li><li><a class="tocitem" href="interfaces/">Interfaces</a></li><li><a class="tocitem" href="reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Guide</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Guide</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/Julia-Tempering/Pigeons.jl/blob/main/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Pigeons"><a class="docs-heading-anchor" href="#Pigeons">Pigeons</a><a id="Pigeons-1"></a><a class="docs-heading-anchor-permalink" href="#Pigeons" title="Permalink"></a></h1><p>Facing a challenging integration problem? Tired of waiting for hours or days for your high-dimensional, multimodal Bayesian posterior approximation? Summing over your combinatorial space is taking months? </p><p>Try <code>Pigeons</code>: a Julia package to efficiently approximate posterior distributions, and more broadly, Lebesgue integration problems. </p><p>Pigeons&#39; core algorithm is a distributed and parallel implementation  of the following algorithms: </p><ul><li>Non-Reversible Parallel Tempering (NRPT),    <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12464">Syed et al., 2021</a>.</li><li>Variational PT, <a href="https://arxiv.org/abs/2206.00080">Surjanovic et al., 2022</a>. </li></ul><p>These algorithms achieve state-of-the-art performance for approximation  of challenging probability distributions.</p><p>Pigeons can be used in a multi-threaded context, and/or  distributed over hundreds or thousands of MPI-communicating machines.</p><h2 id="Scope"><a class="docs-heading-anchor" href="#Scope">Scope</a><a id="Scope-1"></a><a class="docs-heading-anchor-permalink" href="#Scope" title="Permalink"></a></h2><p>We describe here the class of problems that can be approached using Pigeons.</p><p>Let <span>$\pi(x)$</span> denote a probability density called the <strong>target</strong>.  In many problems, e.g. in Bayesian statistics, the density <span>$\pi$</span> is typically  known only up to a normalization constant, </p><p class="math-container">\[\pi(x) = \frac{\gamma(x)}{Z},\]</p><p>where <span>$\gamma$</span> can be evaluated pointwise, but <span>$Z$</span> is unknown. Pigeons takes as input the function <span>$\gamma$</span>.</p><div class="admonition is-category-terminology"><header class="admonition-header">log_potential</header><div class="admonition-body"><p>Since we work in log-scale, we use the terminology  <code>log_potential</code> as a shorthand for the  unnormalized log density <span>$\log \gamma(x)$</span>.  See informal interface <a href="interfaces/#Pigeons.log_potential"><code>log_potential</code></a>.</p></div></div><p>Pigeons&#39; outputs can be used for two tasks:</p><ul><li>Approximating expecations of the form <span>$E[f(X)]$</span>, where <span>$X \sim \pi$</span>.    For example, the choice <span>$f(x) = x$</span> computes the mean, and    <span>$f(x) = I[x \in A]$</span> computes the probability of <span>$A$</span> under <span>$\pi$</span>.</li><li>Approximating the value of the normalization constant <span>$Z$</span>. For    example, in Bayesian statistics, this corresponds to the    <a href="https://en.wikipedia.org/wiki/Marginal_likelihood">marginal likelihood</a>.</li></ul><p>Pigeons shines in the following scenarios:</p><ul><li>When the posterior density <span>$\pi$</span> is challenging due to    non-convexity and/or concentration on a    sub-manifolds due to unidentifiability.</li><li>When the user needs not only <span>$E[f(X)]$</span> but also <span>$Z$</span>. Many existing MCMC tools   focus on the former and struggle to do the latter in high dimensional    problems. </li><li>When the posterior density <span>$\pi$</span> is defined over a non-standard state-space,    e.g. a combinatorial object such as a phylogenetic tree. </li></ul><h2 id="Installing-Pigeons"><a class="docs-heading-anchor" href="#Installing-Pigeons">Installing <code>Pigeons</code></a><a id="Installing-Pigeons-1"></a><a class="docs-heading-anchor-permalink" href="#Installing-Pigeons" title="Permalink"></a></h2><ol><li>If you have not done so, install <a href="https://julialang.org/downloads/">Julia</a>. So far, we have tested the code on Julia 1.8.x.</li><li>Install <code>Pigeons</code> using</li></ol><pre><code class="nohighlight hljs">using Pkg; Pkg.add(&quot;Pigeons&quot;)</code></pre><h2 id="Running-PT"><a class="docs-heading-anchor" href="#Running-PT">Running PT</a><a id="Running-PT-1"></a><a class="docs-heading-anchor-permalink" href="#Running-PT" title="Permalink"></a></h2><p>Specify the target distribution and, optionally,  parameters like random seed, etc by creating an  <a href="reference/#Pigeons.Inputs"><code>Inputs</code></a>:</p><pre><code class="language-julia hljs">using Pigeons

inputs = Inputs(target = toy_mvn_target(100))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Inputs{Pigeons.ScaledPrecisionNormalPath, NoVarReference, Nothing}(Pigeons.ScaledPrecisionNormalPath(1.0, 10.0, 100), 1, 10, 10, 0, NoVarReference(), false, Function[Pigeons.log_sum_ratio, Pigeons.timing_extrema, Pigeons.allocation_extrema], 0, false, nothing, true, :samples)</code></pre><p>See <a href="reference/#Pigeons.Inputs"><code>Inputs</code></a> for more options. </p><p>Then, run PT (locally on one process) using the function <a href="reference/#Pigeons.pigeons-Tuple{}"><code>pigeons()</code></a>:</p><pre><code class="language-julia hljs">pt = pigeons(inputs);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">────────────────────────────────────────────────────────────────────────────
  #scans       Λ        time(s)    allc(B)    log(Z)     min(α)     mean(α)
────────── ────────── ────────── ────────── ────────── ────────── ──────────
        2        7.5   0.000129   1.28e+04       -122   2.66e-15      0.167
        4       5.59   0.000149   1.47e+04       -119    2.6e-07      0.378
        8       6.04   0.000183   1.86e+04       -115    0.00129      0.329
       16       7.27   0.000289   2.42e+04       -118     0.0134      0.193
       32       6.97   0.000428   3.05e+04       -114      0.107      0.225
       64       7.03   0.000692   4.13e+04       -117     0.0531      0.219
      128       7.23    0.00138   6.08e+04       -114     0.0944      0.196
      256       7.05    0.00231   6.77e+04       -115       0.13      0.217
      512       7.14    0.00427   7.18e+04       -115      0.171      0.207
 1.02e+03       7.19    0.00827   7.91e+04       -115      0.172      0.201
────────────────────────────────────────────────────────────────────────────</code></pre><p>This runs PT on a 100-dimensional MVN toy example with 10 chains  for <span>$2047 = 2^{11} - 1$</span> iterations, and  returns a <a href="reference/#Pigeons.PT"><code>PT</code></a> struct containing the results of  this run (more later on how to access information inside  a PT struct). Each line in the output provides information on a <em>round</em>, where the number of iteration  per round doubles at each round and adaptation is performed  between rounds. </p><p>Since the above two julia lines are the most common operations in this package, creating inputs and running PT can be done in one line  as follows:</p><pre><code class="language-julia hljs">pt = pigeons(target = toy_mvn_target(100));</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">────────────────────────────────────────────────────────────────────────────
  #scans       Λ        time(s)    allc(B)    log(Z)     min(α)     mean(α)
────────── ────────── ────────── ────────── ────────── ────────── ──────────
        2        7.5   9.67e-05   1.28e+04       -122   2.66e-15      0.167
        4       5.59   0.000116   1.47e+04       -119    2.6e-07      0.378
        8       6.04   0.000159   1.86e+04       -115    0.00129      0.329
       16       7.27   0.000222   2.42e+04       -118     0.0134      0.193
       32       6.97     0.0007   3.05e+04       -114      0.107      0.225
       64       7.03   0.000743   4.13e+04       -117     0.0531      0.219
      128       7.23    0.00128   6.08e+04       -114     0.0944      0.196
      256       7.05    0.00238   6.77e+04       -115       0.13      0.217
      512       7.14    0.00425   7.18e+04       -115      0.171      0.207
 1.02e+03       7.19    0.00812   7.91e+04       -115      0.172      0.201
────────────────────────────────────────────────────────────────────────────</code></pre><p>where the <code>args...</code> passed to <code>pigeons</code> are forwarded  to <a href="reference/#Pigeons.Inputs"><code>Inputs</code></a>.</p><h2 id="Estimating-the-log-normalization-constant"><a class="docs-heading-anchor" href="#Estimating-the-log-normalization-constant">Estimating the log normalization constant</a><a id="Estimating-the-log-normalization-constant-1"></a><a class="docs-heading-anchor-permalink" href="#Estimating-the-log-normalization-constant" title="Permalink"></a></h2><p>To estimate the log normalization constant, use <a href="reference/#Pigeons.stepping_stone_pair-Tuple{PT}"><code>stepping_stone_pair()</code></a>,  for example: </p><pre><code class="language-julia hljs">stepping_stone_pair(pt)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(-115.94888041658844, -114.87387825759738)</code></pre><p>we can see that this is close to the close-form expression available for this  toy example:</p><pre><code class="language-julia hljs">Pigeons.analytic_lognormalization(toy_mvn_target(100))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">-115.12925464970229</code></pre><h2 id="Accessing-the-output-of-PT"><a class="docs-heading-anchor" href="#Accessing-the-output-of-PT">Accessing the output of PT</a><a id="Accessing-the-output-of-PT-1"></a><a class="docs-heading-anchor-permalink" href="#Accessing-the-output-of-PT" title="Permalink"></a></h2><p>The <a href="reference/#Pigeons.PT"><code>PT</code></a> struct returned by <a href="reference/#Pigeons.pigeons-Tuple{Any, ChildProcess}"><code>pigeons</code></a>  contains a field called <code>reduced_recorders</code>, which is just  a NamedTuple containing <code>recorder</code>&#39;s which can be used to collect  arbitary statistics computed along the execution of PT. </p><p>By default, the statistics collected use constant-memory summaries  (i.e. constant in the number of iteration, leveraging the package <a href="https://github.com/joshday/OnlineStats.jl">OnlineStats.jl</a>), however it is possible to customize which statistics to collect. We provide three examples below. </p><p>As a first example, we show how to store all the samples in the reference chain in memory, using  the <code>traces</code> <code>recorder</code>. We specify which <code>recorder</code> to use via the <code>recorder_builders</code> argument:</p><pre><code class="language-julia hljs">p = pigeons(
        target = toy_mvn_target(100),
        recorder_builders = [traces]);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">──────────────────────────────────────────────────────
  #scans       Λ        log(Z)     min(α)     mean(α)
────────── ────────── ────────── ────────── ──────────
        2        7.5       -122   2.66e-15      0.167
        4       5.59       -119    2.6e-07      0.378
        8       6.04       -115    0.00129      0.329
       16       7.27       -118     0.0134      0.193
       32       6.97       -114      0.107      0.225
       64       7.03       -117     0.0531      0.219
      128       7.23       -114     0.0944      0.196
      256       7.05       -115       0.13      0.217
      512       7.14       -115      0.171      0.207
 1.02e+03       7.19       -115      0.172      0.201
──────────────────────────────────────────────────────</code></pre><p>Then we can access the sample at chain 10 (the reference) at iteration say 42 using:</p><pre><code class="language-julia hljs">example_sample = get_sample(p, 10, 42)
size(example_sample)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(100,)</code></pre><p>Note that the <code>traces</code> recorder only stores data for reference chain(s).</p><p>As a second example, we show next how to store samples to disk:</p><pre><code class="language-julia hljs"># save both to disk and to memory
pt = pigeons(target = toy_mvn_target(10), recorder_builders = [traces, disk], checkpoint = true)

# example of how to post-process the samples from disk
# this loads the samples one at the time so can be useful if the
# full trace would not fit in memory
# By default, only the samples from the last rounds are loaded
# i.e. a burn-in of 50%.
process_samples(pt) do chain, scan, sample
    # check the results are identical for the disk and traces recorders
    @assert sample == get_sample(pt, chain, scan)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">──────────────────────────────────────────────────────
  #scans       Λ        log(Z)     min(α)     mean(α)
────────── ────────── ────────── ────────── ──────────
        2       1.54      -12.5    0.00786      0.829
        4        1.9      -12.9     0.0483      0.789
        8       3.22        -12      0.218      0.642
       16       2.93      -11.1      0.477      0.675
       32       3.05      -11.7      0.343      0.661
       64       2.67      -11.3      0.605      0.703
      128       2.92      -11.5      0.572      0.676
      256       2.71      -11.7      0.618      0.699
      512       2.83      -11.7      0.629      0.686
 1.02e+03       2.81      -11.5      0.645      0.688
──────────────────────────────────────────────────────</code></pre><p>As a third example, we show here how to plot the <em>index process</em>, a  useful diagnostic to assess the efficiency of PT algorithms  (<a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12464">Syed et al., 2021</a>). </p><p>Again we use the argument <code>recorder_builders</code> to  specify that we wish to collect the full index process:</p><pre><code class="language-julia hljs">p = pigeons(
        target = toy_mvn_target(1),
        recorder_builders = [index_process],
        n_rounds = 5);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">──────────────────────────────────────────────────────
  #scans       Λ        log(Z)     min(α)     mean(α)
────────── ────────── ────────── ────────── ──────────
        2      0.417      -1.56      0.782      0.954
        4      0.564     -0.653       0.61      0.937
        8      0.597     -0.833      0.869      0.934
       16      0.686      -1.35      0.729      0.924
       32      0.818      -1.19        0.8      0.909
──────────────────────────────────────────────────────</code></pre><p>Then we can access the information via:</p><pre><code class="language-julia hljs">p.reduced_recorders.index_process

using Plots
plot(p.reduced_recorders.index_process);
savefig(&quot;index_process_plot.svg&quot;);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">qt.qpa.xcb: could not connect to display
qt.qpa.plugin: Could not load the Qt platform plugin &quot;xcb&quot; in &quot;&quot; even though it was found.
This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.

Available platform plugins are: linuxfb, minimal, offscreen, vnc, xcb.

Aborted (core dumped)
connect: Connection refused
GKS: can&#39;t connect to GKS socket application

GKS: Open failed in routine OPEN_WS
GKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS</code></pre><p><img src="index_process_plot.svg" alt/></p><p>Other statistics follow the same general usage,  see <a href="pt.html">Parallel Tempering (PT)</a> for  more details. </p><h2 id="Loading-and-resuming-a-checkpoint"><a class="docs-heading-anchor" href="#Loading-and-resuming-a-checkpoint">Loading and resuming a checkpoint</a><a id="Loading-and-resuming-a-checkpoint-1"></a><a class="docs-heading-anchor-permalink" href="#Loading-and-resuming-a-checkpoint" title="Permalink"></a></h2><p>Pigeons can write a &quot;checkpoint&quot; periodically  to ensure that not more than half of the work is lost in  the event of e.g. a server failure. This is enabled as follows:</p><pre><code class="language-julia hljs">pt = pigeons(target = toy_mvn_target(100), checkpoint = true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">PT(&quot;/home/runner/work/Pigeons.jl/Pigeons.jl/docs/build/results/all/2023-05-25-03-41-54-vBIaBySB&quot;)</code></pre><p>See <a href="reference/#Pigeons.write_checkpoint-Tuple{Any}"><code>write_checkpoint()</code></a> for details of how this  is accomplished in a way compatible to both the single-machine  and MPI contexts.  Each checkpoint is located in  <code>results/all/[unique folder]/round=[x]/checkpoint</code>,  with the latest run in <code>results/latest/[unique folder]/round=[x]/checkpoint</code>. </p><p>Checkpoints are also useful when an MPI-distributed PT has been  ran, and the user wants to load the full set of  results in one interactive session. </p><p>To load a checkpoint, create a <a href="reference/#Pigeons.PT"><code>PT</code></a> struct by passing in the path  string to the checkpoint folder, for example to re-load the latest checkpoint  from the latest run:</p><pre><code class="language-julia hljs">pt_from_checkpoint = PT(&quot;results/latest&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">PT(&quot;/home/runner/work/Pigeons.jl/Pigeons.jl/docs/build/results/all/2023-05-25-03-41-54-IuJLK0r8&quot;)</code></pre><h2 id="Automatic-correctness-checks"><a class="docs-heading-anchor" href="#Automatic-correctness-checks">Automatic correctness checks</a><a id="Automatic-correctness-checks-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-correctness-checks" title="Permalink"></a></h2><p>It is notoriously difficult to implement correct parallel/distributed algorithms.  One strategy we use to address this is to guarantee that the code will output  precisely the same output no matter how many threads/machines are used.  We describe how this is done under the hood in the page <a href="distributed.html">Distributed PT</a>. </p><p>In practice, how is this useful? Let us say you developed a new target and you would like to make sure that it works correctly in a multi-threaded environment. To do so, add a flag to indicate to &quot;check&quot; one of the PT rounds as follows, and  enable checkpointing</p><pre><code class="language-julia hljs">pigeons(target = toy_mvn_target(100), checked_round = 3, checkpoint = true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">PT(&quot;/home/runner/work/Pigeons.jl/Pigeons.jl/docs/build/results/all/2023-05-25-03-41-54-e8UvEBSp&quot;)</code></pre><p>The above line does the following: the PT algorithm will pause at the end of round 3, spawn  a separate process with only one thread in it, run 3 rounds of PT with the same  <a href="reference/#Pigeons.Inputs"><code>Inputs</code></a> object in it, and verify that the checkpoints of the single-threaded run  is identical to   the one that ran in the main process. If not, an error will be raised with some  information on where the discrepancy comes from.  Try to pick the checked round to be small enough that it does not dominate the running time  (since it runs in single-threaded, single-process mode), but big enough to achieve  the same code coverage as the full algorithm. Setting it to zero (or omitting the argument),  disable this functionality.</p><p>Did the code above actually used many threads? This depends on the value of <code>Threads.nthreads()</code>. Julia currently does not allow you to change this value at  runtime, so for convenience we provide the following way to run the job in a  child process with a set number of Julia threads:</p><pre><code class="language-julia hljs">pt_result = pigeons(target = toy_mvn_target(100), multithreaded = true, checked_round = 3, checkpoint = true, on = ChildProcess(n_threads = 4))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Result{PT}(&quot;/home/runner/work/Pigeons.jl/Pigeons.jl/docs/build/results/all/2023-05-25-03-45-50-KIHVvaqN&quot;)</code></pre><p>Notice that we also add the flag <code>multithreaded = true</code>. </p><p>Notice that this time, instead of returning a <a href="reference/#Pigeons.PT"><code>PT</code></a> struct, this time we obtain  a <a href="reference/#Pigeons.Result"><code>Result</code></a>, which only holds the path where the checkpoints can be found.  If you would like to load a result in memory, use:</p><pre><code class="language-julia hljs">pt = load(pt_result)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">PT(&quot;/home/runner/work/Pigeons.jl/Pigeons.jl/docs/build/results/all/2023-05-25-03-46-41-a6F8vLS6&quot;)</code></pre><p>In this case, since the model is built-in, the check passed successfully as expected. But what  if you had a third-party target distribution that is not multi-threaded friendly?  I.e. it may write in global variables or  other non-thread safe construct. Then you can probably still  use your thread-naive  target over MPI <em>processes</em>.  For example, if the thread-unsafety comes from the use of global variables, then each  process will have its own copy of the global variables. </p><p>We described how MPI can be used in the next two sections.</p><h2 id="Running-MPI-locally"><a class="docs-heading-anchor" href="#Running-MPI-locally">Running MPI locally</a><a id="Running-MPI-locally-1"></a><a class="docs-heading-anchor-permalink" href="#Running-MPI-locally" title="Permalink"></a></h2><p>To run MPI locally on one machine, using 4 MPI processes and 1 thread per process use:</p><pre><code class="language-julia hljs">pigeons(
    target = toy_mvn_target(100),
    checked_round = 3,
    checkpoint = true,
    on = ChildProcess(
            n_local_mpi_processes = 4,
            n_threads = 1))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Result{PT}(&quot;/home/runner/work/Pigeons.jl/Pigeons.jl/docs/build/results/all/2023-05-25-03-46-41-d7uSbKcX&quot;)</code></pre><p>Note that if <code>n_local_mpi_processes</code> exceeds the number of cores, performance  will steeply degrade (in contrast to threads, for which performance degrades  much more gracefully when the number of threads exceeds the number of cores). </p><h2 id="Running-MPI-on-a-cluster"><a class="docs-heading-anchor" href="#Running-MPI-on-a-cluster">Running MPI on a cluster</a><a id="Running-MPI-on-a-cluster-1"></a><a class="docs-heading-anchor-permalink" href="#Running-MPI-on-a-cluster" title="Permalink"></a></h2><div class="admonition is-info"><header class="admonition-header">The magic of distributed Parallel Tempering</header><div class="admonition-body"><p>If the dimensionality of the state space is large, you may worry that  the time to transmit states over the network would dominate the running time.  Remarkably, the size of the messages transmitted in the inner loop of our  algorithm does <strong>not</strong> depend on the state space. In a nutshell, the  machines only need to transmit the value of log density ratios (a single float).  See <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12464">Algorithm 5 in Syed et al., 2021</a> for details.</p></div></div><p>MPI is typically available via a cluster scheduling system. At the time of  writing, <a href="https://github.com/openpbs/openpbs">PBS</a> and  <a href="https://slurm.schedmd.com/documentation.html">SLURM</a> are supported,  and an experimental implementation of <a href="https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=overview-lsf-introduction">LSF</a> is included.  Create an issue if you would like another submission system included. </p><p>Follow these instructions to run MPI over several machines:</p><ol><li>In the cluster login node, follow the <a href="#Installing-Pigeons">installation instruction as above</a>. </li><li>Start Julia in the login node, and perform a one-time setup by calling <a href="reference/#Pigeons.setup_mpi-Tuple{}"><code>setup_mpi()</code></a>.</li><li>Still in the Julia REPL running in the login node, use:</li></ol><pre><code class="nohighlight hljs">mpi_run = pigeons(
    target = toy_mvn_target(1000000), 
    n_chains = 1000,
    on = MPI(
        n_mpi_processes = 1000,
        n_threads = 1))</code></pre><p>This will start a distributed PT algorithm with 1000 chains on 1000 MPI processes, each using one thread, targeting a one million  dimensional target distribution. On the UBC Sockeye cluster, the last  round of this run (i.e. the last 1024 iterations) takes 10 seconds to complete, versus more than  2 hours if ran serially, i.e. a &gt;700x speed-up.  This is reasonably close to the theoretical 1000x speedup, i.e. we see that the communication costs are negligible. </p><p>You can &quot;watch&quot; the progress of your job (queue status and  standard output once it is available), using:</p><pre><code class="nohighlight hljs">watch(mpi_run)</code></pre><p>and cancel/kill a job using </p><pre><code class="nohighlight hljs">kill_job(mpi_run)</code></pre><h2 id="Specification-of-general-models"><a class="docs-heading-anchor" href="#Specification-of-general-models">Specification of general models</a><a id="Specification-of-general-models-1"></a><a class="docs-heading-anchor-permalink" href="#Specification-of-general-models" title="Permalink"></a></h2><p>The most general way to invoke Pigeons is by specifying two ingredients: a sequence of distributions,  <span>$\pi_1, \pi_2, \dots, \pi_N$</span>, and for each <span>$\pi_i$</span>, a <span>$\pi_i$</span>-invariant Markov transition kernel.</p><p>See <a href="https://github.com/Julia-Tempering/Pigeons.jl/tree/main/examples/general-target.jl">examples/general-target.jl</a>  for an example of how to input an arbitrary Julia function as the  target distribution.</p><p>Typically, <span>$\pi_1$</span> is a distribution from which we can sample i.i.d. (e.g. the prior, or a variational  approximation), while the last distribution coincides with the distribution of interest,  <span>$\pi_N = \pi$</span>, the target.  We use an informal interface called <a href="interfaces/#Pigeons.target"><code>target</code></a> to orchestrate the creation of the ingredients  needed by parallel tempering algorithms.  The main pieces to specify are <a href="reference/#Pigeons.create_state_initializer-Tuple{Any, Inputs}"><code>create_state_initializer()</code></a>, to provide initial states,  <a href="reference/#Pigeons.default_explorer-Tuple{Any}"><code>default_explorer</code></a>, to construct <a href="interfaces/#Pigeons.explorer"><code>explorer</code></a>&#39;s  which are <span>$\pi_i$</span>-invariant Markov transition kernel,  and finally, <a href="reference/#Pigeons.create_reference_log_potential-Tuple{Any, Inputs}"><code>create_reference_log_potential()</code></a>,  to construct <span>$\pi_1$</span>. </p><p>A range of other extension points are defined, to control  the <a href="interfaces/#Pigeons.tempering"><code>tempering</code></a>, interpolating <a href="interfaces/#Pigeons.path"><code>path</code></a>&#39;s,  adaptation, but those all have reasonable default implementations built-in. See the <a href="pt.html">Parallel Tempering (PT) page</a> for more information.</p><h2 id="Targeting-a-Turing.jl-model"><a class="docs-heading-anchor" href="#Targeting-a-Turing.jl-model">Targeting a Turing.jl model</a><a id="Targeting-a-Turing.jl-model-1"></a><a class="docs-heading-anchor-permalink" href="#Targeting-a-Turing.jl-model" title="Permalink"></a></h2><p>To demonstrate how to integrate a third-party target distribution into  Pigeons, we show in this section how to sample from target distributions defined using a <a href="https://turing.ml/stable/">Turing.jl</a> model. <strong>This integration is currently experimental.</strong> </p><p>We consider an unidentifiable Beta-Binomial model for instructional purposes. Typically, MCMC samplers would have difficulty sampling from  posterior distributions of unidentifiable models. However, Pigeons excels in this scenario compared to traditional samplers.</p><p>First, we define the Turing model.</p><pre><code class="language-julia hljs">using Turing

# *Unidentifiable* unconditioned coinflip model with `N` observations.
@model function coinflip_unidentifiable(; N::Int)
    p1 ~ Uniform(0, 1) # prior on p1
    p2 ~ Uniform(0, 1) # prior on p2
    y ~ filldist(Bernoulli(p1*p2), N) # data-generating model
    return y
end;
coinflip_unidentifiable(y::AbstractVector{&lt;:Real}) = coinflip_unidentifiable(; N=length(y)) | (; y)

function flip_model_unidentifiable()
    p_true = 0.5; # true probability of heads is 0.5
    N = 100;
    data = rand(Bernoulli(p_true), N); # generate N data points
    return coinflip_unidentifiable(data)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">flip_model_unidentifiable (generic function with 1 method)</code></pre><p>Once we have defined our Turing model, it is straightforward to sample from the posterior distribution of <code>p1</code> and <code>p2</code> as follows:</p><pre><code class="language-julia hljs">using Pigeons
model = flip_model_unidentifiable()
pt = pigeons(target = TuringLogPotential(model));</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">──────────────────────────────────────────────────────────────────────────────────────────────────
  #scans       Λ        time(s)    allc(B)    log(Z)     min(α)     mean(α)    min(αₑ)   mean(αₑ)
────────── ────────── ────────── ────────── ────────── ────────── ────────── ────────── ──────────
        2       1.36      0.586   4.17e+06      -73.9   0.000666      0.849          1          1
        4        2.4    0.00646   1.63e+06      -72.4      0.331      0.733          1          1
        8       1.13     0.0122   3.29e+06      -71.1      0.801      0.874          1          1
       16       1.63     0.0245   6.45e+06      -71.3      0.704      0.819          1          1
       32       1.68     0.0494   1.29e+07      -71.4      0.716      0.814          1          1
       64       1.69      0.127   2.55e+07      -71.6      0.708      0.812          1          1
      128       1.67      0.217   5.11e+07      -71.6      0.769      0.815          1          1
      256       1.63      0.422   1.02e+08      -71.5      0.789      0.819          1          1
      512        1.6      0.845   2.04e+08      -71.7      0.775      0.822          1          1
 1.02e+03       1.59       1.81    4.1e+08      -71.6      0.801      0.823          1          1
──────────────────────────────────────────────────────────────────────────────────────────────────</code></pre><h2 id="Targeting-a-non-Julian-model"><a class="docs-heading-anchor" href="#Targeting-a-non-Julian-model">Targeting a non-Julian model</a><a id="Targeting-a-non-Julian-model-1"></a><a class="docs-heading-anchor-permalink" href="#Targeting-a-non-Julian-model" title="Permalink"></a></h2><p>Suppose you have some code implementing vanilla MCMC, written  in an arbitrary &quot;foreign&quot; language such as C++, Python, R, Java, etc.  You would like to turn this vanilla MCMC code into a Parallel Tempering  algorithm able to harness large numbers of cores, including  distributing this algorithm over MPI.  However, you do not wish to learn anything about  MPI/multi-threading/Parallel Tempering. </p><p>Surprisingly, it is very simple to bridge such code with Pigeons.  The only requirement on the &quot;foreign&quot; language is that it supports  reading the standard in and writing to the standard out, hence  virtually any languages can be interfaced in this fashion.  Based on this minimalist &quot;standard stream bridge&quot; with worker  processes running foreign code (one such process per replica; not  necessarily running on the same machine), Pigeons will  coordinate the execution of an adaptive non-reversible parallel  tempering algorithm. </p><p>To see how to accomplish this, see <a href="reference/#Pigeons.StreamTarget"><code>StreamTarget</code></a>. A concrete example is also shown in <a href="reference/#Pigeons.BlangTarget"><code>BlangTarget</code></a>, which  uses this infrastructure to run arbitrary  code in the <a href="https://www.stat.ubc.ca/~bouchard/blang/">Blang modelling language</a> over MPI.</p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="pt/">Parallel Tempering (PT) »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Thursday 25 May 2023 03:50">Thursday 25 May 2023</span>. Using Julia version 1.9.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
