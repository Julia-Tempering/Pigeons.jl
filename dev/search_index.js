var documenterSearchIndex = {"docs":
[{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Descriptions of informal interfaces.","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#explorer","page":"Interfaces","title":"explorer","text":"","category":"section"},{"location":"interfaces/#Description","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.explorer","category":"page"},{"location":"interfaces/#Pigeons.explorer","page":"Interfaces","title":"Pigeons.explorer","text":"Orchestrate the explore!() phase  of Parallel Tempering. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.step!()\nPigeons.adapt_explorer()\nPigeons.explorer_recorder_builders()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_explorer()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#log_potential","page":"Interfaces","title":"log_potential","text":"","category":"section"},{"location":"interfaces/#Description-2","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.log_potential","category":"page"},{"location":"interfaces/#Pigeons.log_potential","page":"Interfaces","title":"Pigeons.log_potential","text":"A log_potential encodes a probability distribution, where only the  un-normalized probability density function is known. \n\nTo make MyType conform to this informal interface, implement \n\n(log_potential::MyType)(x)\n\nwhich should return the log of the un-normalized density.\n\nFor example, we provide this behaviour for any distribution  in Distributions.jl. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#log_potentials","page":"Interfaces","title":"log_potentials","text":"","category":"section"},{"location":"interfaces/#Description-3","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.log_potentials","category":"page"},{"location":"interfaces/#Pigeons.log_potentials","page":"Interfaces","title":"Pigeons.log_potentials","text":"An encoding of a discrete set of probability distributions, where only the un-normalized  probability density functions are known.  Each distribution is allowed to have a different normalization constant. \n\nFor example, we provide this behaviour for any Vector containing log_potential's. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-2","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.log_unnormalized_ratio()\nPigeons.n_chains()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#pair_swapper","page":"Interfaces","title":"pair_swapper","text":"","category":"section"},{"location":"interfaces/#Description-4","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.pair_swapper","category":"page"},{"location":"interfaces/#Pigeons.pair_swapper","page":"Interfaces","title":"Pigeons.pair_swapper","text":"Informs swap!() of how to perform a swap between a given pair of chains.\n\nThis is done in two steps:\n\nUse swap_stat() to extract sufficient statistics needed to make a swap decision. \nGiven these statistics for the two chains, swap_decision() then perform the swap.\n\nThe rationale for breaking this down into two steps is that in a distributed swap context, swap!() will take care of transmitting the sufficient statistics over the network if necessary.\n\nThe function record_swap_stats!() is used to record information about swapping,  in particular mean swap acceptance probabilities.\n\nA default implementation of all of pair_swapper's methods is provided,  where the pair_swapper is assumed to follow the log_potentials interface.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-3","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.swap_stat()\nPigeons.record_swap_stats!()\nPigeons.swap_decision()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-2","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.TestSwapper()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#path","page":"Interfaces","title":"path","text":"","category":"section"},{"location":"interfaces/#Description-5","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.path","category":"page"},{"location":"interfaces/#Pigeons.path","page":"Interfaces","title":"Pigeons.path","text":"A continuum of log_potential's interpolating between two end-points. More precisely, a mapping from [0, 1] to the space of probability distributions.\n\nThe main use of this interface is to pass it to discretize().\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-4","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.interpolate()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-3","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.InterpolatingPath()\nPigeons.ScaledPrecisionNormalPath()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#recorder","page":"Interfaces","title":"recorder","text":"","category":"section"},{"location":"interfaces/#Description-6","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.recorder","category":"page"},{"location":"interfaces/#Pigeons.recorder","page":"Interfaces","title":"Pigeons.recorder","text":"Accumulate a specific type of statistic, for example  by keeping constant size sufficient statistics  (via OnlineStat, which conforms this interface),  storing samples to a file, etc. \n\nIn addition to the contract below, a recorder should support \n\nBase.merge()\nBase.empty!()\n\nSee also recorders.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-5","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.record!()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-4","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.timing_extrema()\nPigeons.round_trip()\nPigeons.allocation_extrema()\nPigeons.log_sum_ratio()\nPigeons.target_online()\nPigeons.swap_acceptance_pr()\nPigeons.energy_ac1()\nPigeons.index_process()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#recorder_builder","page":"Interfaces","title":"recorder_builder","text":"","category":"section"},{"location":"interfaces/#Description-7","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.recorder_builder","category":"page"},{"location":"interfaces/#Pigeons.recorder_builder","page":"Interfaces","title":"Pigeons.recorder_builder","text":"A function such that calling it returns a fresh  recorder.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#recorders","page":"Interfaces","title":"recorders","text":"","category":"section"},{"location":"interfaces/#Description-8","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.recorders","category":"page"},{"location":"interfaces/#Pigeons.recorders","page":"Interfaces","title":"Pigeons.recorders","text":"A NamedTuple containing several recorder's.  Each recorder is responsible for a type of statistic to be  accumulated (e.g. one for swap accept prs, one for round trip  info; some are in-memory, some are on file). \n\nDuring PT execution, each recorders object keep track of only the  statistics for one replica (for thread safety and/or  distribution purpose). After a PT round, reduce_recorders!() is used to do  a reduction before  accessing statistic values. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-6","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.record_if_requested!()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-5","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_recorders()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#replicas","page":"Interfaces","title":"replicas","text":"","category":"section"},{"location":"interfaces/#Description-9","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.replicas","category":"page"},{"location":"interfaces/#Pigeons.replicas","page":"Interfaces","title":"Pigeons.replicas","text":"Stores the process' replicas.  Since we provide MPI implementations, do not assume that this will contain all the replicas, as  others can be located in other processes/machines\n\nImplementations provided\n\nEntangledReplicas: an MPI-based implementation\nVector{Replica}: single-process case (above can handle that case, but the array based implementation is non-allocating)\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-7","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.swap!()\nPigeons.locals()\nPigeons.load()\nPigeons.communicator()\nPigeons.entangler()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-6","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_entangled_replicas()\nPigeons.create_replicas()\nPigeons.create_vector_replicas()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#state","page":"Interfaces","title":"state","text":"","category":"section"},{"location":"interfaces/#Description-10","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.state","category":"page"},{"location":"interfaces/#Pigeons.state","page":"Interfaces","title":"Pigeons.state","text":"The state held in each Parallel Tempering Replica.  This interface is only needed for variational Parallel Tempering and for  some recorders such as OnlineStateRecorder. (Note that, at the moment, explorers automatically detect the variable type  and dispatch accordingly.)\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-8","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.continuous_variables()\nPigeons.discrete_variables()\nPigeons.variable()\nPigeons.update_state!()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#state_initializer","page":"Interfaces","title":"state_initializer","text":"","category":"section"},{"location":"interfaces/#Description-11","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.state_initializer","category":"page"},{"location":"interfaces/#Pigeons.state_initializer","page":"Interfaces","title":"Pigeons.state_initializer","text":"Determine how to initialize the states in the replicas.  Implementations include Ref(my_state), to signal all replicas will  be initalized to my_state, or a Vector(...) for chain-specific  initializations. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-9","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.initialization()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#swap_graph","page":"Interfaces","title":"swap_graph","text":"","category":"section"},{"location":"interfaces/#Description-12","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.swap_graph","category":"page"},{"location":"interfaces/#Pigeons.swap_graph","page":"Interfaces","title":"Pigeons.swap_graph","text":"Informs swap!() about which chain will interact with which.\n\nThese are instantiated by swap_graphs. \n\nCanonical example is the standard Odd and Even swap. Extension point for e.g. \n\nparallel parallel tempering,\nvariational methods with more than 2 legs,\nPT algorithms dealing with more than one target simultaneously for the purpose of model selection. \n\nShould implement the methods below, in addition to is_reference() and  is_target().\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-10","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.partner_chain()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#swap_graphs","page":"Interfaces","title":"swap_graphs","text":"","category":"section"},{"location":"interfaces/#Description-13","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.swap_graphs","category":"page"},{"location":"interfaces/#Pigeons.swap_graphs","page":"Interfaces","title":"Pigeons.swap_graphs","text":"Creates one swap_graph for each communication  iteration.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-11","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_swap_graph()\nPigeons.is_reference()\nPigeons.is_target()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-7","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.deo()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#target","page":"Interfaces","title":"target","text":"","category":"section"},{"location":"interfaces/#Description-14","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.target","category":"page"},{"location":"interfaces/#Pigeons.target","page":"Interfaces","title":"Pigeons.target","text":"The probability distribution of interest. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-12","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_state_initializer()\nPigeons.create_explorer()\nPigeons.create_reference_log_potential()\nPigeons.sample_iid!()\nPigeons.create_path()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-8","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.toy_mvn_target()\nPigeons.TuringLogPotential()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#tempering","page":"Interfaces","title":"tempering","text":"","category":"section"},{"location":"interfaces/#Description-15","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.tempering","category":"page"},{"location":"interfaces/#Pigeons.tempering","page":"Interfaces","title":"Pigeons.tempering","text":"Orchestrate the communicate!() phase  of Parallel Tempering. \n\nIn addition to the methods in the contract below,  we also assume the presence of the following fields:\n\nlog_potentials\nswap_graphs\ncommunication_barriers\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-13","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.adapt_tempering()\nPigeons.tempering_recorder_builders()\nPigeons.create_pair_swapper()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-9","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_tempering()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#var_reference","page":"Interfaces","title":"var_reference","text":"","category":"section"},{"location":"interfaces/#Description-16","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.var_reference","category":"page"},{"location":"interfaces/#Pigeons.var_reference","page":"Interfaces","title":"Pigeons.var_reference","text":"A variational family of reference distributions.  Implementations should also satisfy the log_potential  contract. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-14","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.activate_var_reference()\nPigeons.update_reference!()\nPigeons.var_reference_recorder_builders()\nPigeons.sample_iid!()","category":"page"},{"location":"collect/#Collecting-the-PT-output","page":"Collecting the PT output","title":"Collecting the PT output","text":"","category":"section"},{"location":"collect/","page":"Collecting the PT output","title":"Collecting the PT output","text":"Parallel tempering produces a set of samples which can be  used to perform many tasks:","category":"page"},{"location":"collect/","page":"Collecting the PT output","title":"Collecting the PT output","text":"estimating normalization constants (uses a univariate statistic   from each chain);\nestimating expectations (uses potentially high-dimensional   statistics from a single chain, the target one).","category":"page"},{"location":"collect/","page":"Collecting the PT output","title":"Collecting the PT output","text":"Here we focus on the design of the machinery for achieving point 2 above in the distributed parallel tempering context. ","category":"page"},{"location":"collect/","page":"Collecting the PT output","title":"Collecting the PT output","text":"The main challenges are:","category":"page"},{"location":"collect/","page":"Collecting the PT output","title":"Collecting the PT output","text":"(A) each machine holds a subset of the samples; this complicates the    computation of order-sensitive estimators such as batch-mean    asymptotic variance estimators for Monte Carlo standard error    estimation;\n(B) in some applications, it may not be possible to hold all the    samples in the memory of one machine. At the extreme, a   machine may not be able to store more than one sample. ","category":"page"},{"location":"collect/#Possible-approaches","page":"Collecting the PT output","title":"Possible approaches","text":"","category":"section"},{"location":"collect/","page":"Collecting the PT output","title":"Collecting the PT output","text":"First decision:","category":"page"},{"location":"collect/","page":"Collecting the PT output","title":"Collecting the PT output","text":"perform collection during sampling using online-statistics only\nstore samples to RAM and do processing after sampling\nsame as 2 but with hard-drive storage\nsupport several of 1-3, potentially using different strategies for different statistic and/or targets","category":"page"},{"location":"collect/","page":"Collecting the PT output","title":"Collecting the PT output","text":"Constraints:","category":"page"},{"location":"collect/","page":"Collecting the PT output","title":"Collecting the PT output","text":"technical challenges (A) and (B)\ndefault settings should be fast...\n...but also ergonomic","category":"page"},{"location":"collect/#Plan-for-next-step-on-this","page":"Collecting the PT output","title":"Plan for next step on this","text":"","category":"section"},{"location":"collect/","page":"Collecting the PT output","title":"Collecting the PT output","text":"We now have a working version of collection for samples    that are not order-sensitive\nfor order sensitive, do some benchmarking to compare the    different approaches 1-3. ","category":"page"},{"location":"pluto/#Instructions-for-remote-Pluto-execution","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"","category":"section"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"Simplest method: connect to server via VSCode. Then ","category":"page"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"julia\nusing Pluto\nPluto.run()","category":"page"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"And this will open a browser window. ","category":"page"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"Longer route without VSCode:","category":"page"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"On the server:","category":"page"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"julia\nusing Pluto\nPluto.run(port = 1234)","category":"page"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"On the client:","category":"page"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"ssh sockeye -N -L 1234:localhost:1234","category":"page"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"Open a browser in the client and go to http://localhost:1234/.  Look at the server terminal to get the \"secret\" part  of the URL. ","category":"page"},{"location":"pluto/#Various-tricks","page":"Instructions for remote Pluto execution","title":"Various tricks","text":"","category":"section"},{"location":"pluto/#Killing-zombies","page":"Instructions for remote Pluto execution","title":"Killing zombies","text":"","category":"section"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"On the client:","category":"page"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"lsof -i :1234","category":"page"},{"location":"pluto/#Force-reload-a-cell","page":"Instructions for remote Pluto execution","title":"Force reload a cell","text":"","category":"section"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"Ctrl-a followed by Shift-Enter","category":"page"},{"location":"pluto/#Misc","page":"Instructions for remote Pluto execution","title":"Misc","text":"","category":"section"},{"location":"pluto/#TableOfContents()","page":"Instructions for remote Pluto execution","title":"TableOfContents()","text":"","category":"section"},{"location":"pluto/#Wider:","page":"Instructions for remote Pluto execution","title":"Wider:","text":"","category":"section"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"html\"\"\"<style>\nmain {\n    max-width: 1000px;\n}\n\"\"\"","category":"page"},{"location":"pluto/#Sharing-github-hosted-html","page":"Instructions for remote Pluto execution","title":"Sharing github hosted html","text":"","category":"section"},{"location":"pluto/","page":"Instructions for remote Pluto execution","title":"Instructions for remote Pluto execution","text":"https://raw.githack.com/","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"CurrentModule = Pigeons","category":"page"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/#Types-and-functions","page":"Reference","title":"Types and functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [Pigeons]\nFilter = t -> typeof(t) !== Pigeons.InformalInterfaceSpec","category":"page"},{"location":"reference/#Pigeons.BlangTarget","page":"Reference","title":"Pigeons.BlangTarget","text":"A StreamTarget delegating exploration to  Blang worker processes.\n\nusing Pigeons\n\nPigeons.setup_blang(\"blangDemos\", \"UBC-Stat-ML\") # pre-compile the blang models in the github repo UBC-Stat-ML/blangDemos\npigeons(target = Pigeons.blang_ising());\n\nType Pigeons.blang followed by tab to find other examples. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ChildProcess","page":"Reference","title":"Pigeons.ChildProcess","text":"Flag to run to a new julia  process. Useful e.g. to dynamically control  the number of threads to use.   Fields: \n\nn_threads: The number of threads to provide in the child julia process, the same as the current process by default.\n\ndependencies: Julia modules (if of type Module) or paths to include (if of type String) needed by the child process.\n\nn_local_mpi_processes: If greater than one, run the code locally over MPI using that many MPI processes. In most cases, this is useful only for debugging purpose, as multi-threading should typically perform better. This could also potentially be useful if using a third-party target distribution which somehow does not support multi-threading.\n\nwait: If wait is false, the process runs asynchronously. When wait is false, the process' I/O streams are directed to devnull.\n\nmpiexec_args: Extra arguments passed to mpiexec.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.EntangledReplicas","page":"Reference","title":"Pigeons.EntangledReplicas","text":"An implementation of replicas for distributed PT.  Contains:\n\nlocals: The subset of replicas hosted in this process\n\nchain_to_replica_global_indices: A specialized distributed array that maps chain indices to replica indices (global indices). This corresponds to the mapping boldsymbolj in line 2 of Algorithm 5 in Syed et al, 2021.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Entangler","page":"Reference","title":"Pigeons.Entangler","text":"Assume all the MPI processes linked by this communicator  will all call the key operations listed below the same number of times  in their lifetime, at logically related occasions (e.g. a set  number of times per iteration for algorithms running the  same number of iterations). We call these 'occasions' a micro-iteration.\n\nThis datastructure keeps track internally of appropriate unique  tags to coordinate the communication between MPI processes  without having to do any explicit synchronization. \n\nThis struct contains:\n\ncommunicator: An MPI Comm object (or nothing if a single process is involved).\n\nload: How a set of tasks or \"global indices\" are distributed across processes.\n\ncurrent_received_bits: An internal datastructure used during MPI calls.\n\nn_transmits: The current micro-iteration. Do not rely on it to count logical steps as it is reset to zero after transmit_counter_bound micor-iterations to avoid underflows to negative tags which cause MPI to crash.\n\ntransmit_counter_bound: Calculated from MPI.tagub and nglobal_indices to ensure MPI tags stay valid (i.e. do not overflow into negative values).\n\nThe key operations supported:\n\ntransmit() and transmit!(): encapsulates    pairwise communications in which each MPI process is holding     a Vector, the elements of which are to be permuted across the processes.\nall_reduce_deterministically and reduce_deterministically,    to perform MPI collective reduction while maintaining the    Parallelism Invariance property.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.FromCheckpoint","page":"Reference","title":"Pigeons.FromCheckpoint","text":"Flag create_replicas (and related functions) that replicas  should be loaded from a checkpoint. Fields:\n\ncheckpoint_folder\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.GaussianReference","page":"Reference","title":"Pigeons.GaussianReference","text":"A Gaussian mean-field variational reference (i.e., with a diagonal covariance matrix).\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Immutable-Tuple{Any}","page":"Reference","title":"Pigeons.Immutable","text":"Immutable(data)\n\n\nConsider a situation where a distributed system serializes its state,   and part of the state contains large immutable data. When the distributed processes each independently call  Serialization.serialize(), naively the processes would each write identical  copies of the large immutable data, which is space-inefficient. \n\nImmutable resolves this space-inefficiency. For most users,  all they need to know is to enclose large data inside the  struct Immutable. \n\nDetails of how serialization/deserialization is performed:\n\nEnclose large immutable data inside a Immutable.   Assume the type of data has well defined hash and ==.  Internally, we maintain an internal, global Dict indexed   by hash(data) storing the data. This global Dict is   called immutables.\nUse flush_immutable() to clear the global immutable state\nUse Serialization.serialize as usual. Internally, we   dispatch serialization of Immutable is modified to skip   the field containing the data.\nMake one of the processes call serialize_immutables().   This serializes the immutables Dict.\nThen for de-serialization, each process should call   deserialize_immutables(). This restores   immutable.\nFinally, call Serialization.deserialize() as usual.   When an Immutable instances is being deserialize, we   dispatch deserialization so that the data is retreived   from immutable.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.Indexer","page":"Reference","title":"Pigeons.Indexer","text":"A bijection between integers and some type T.  T is assumed to have consistent hash and ==. The two sides of the bijection can be obtained with the fields:\n\ni2t: A Vector mapping integers to objects t of type T.\n\nt2i: A Dict mapping objects t of type T to integers.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Indexer-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T","page":"Reference","title":"Pigeons.Indexer","text":"Indexer(i2t)\n\n\nCreate an Indexer with the given Int to T mapping.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.Inputs","page":"Reference","title":"Pigeons.Inputs","text":"A Base.@kwdef struct  used to create Parallel Tempering algorithms. \n\nFields (see source file for default values):\n\ntarget:  The target distribution.\nseed:  The master random seed.\nn_rounds:  The number of rounds to run.\nn_chains:  The number of chains to use.\nn_chains_var_reference:  The number of chains to use for the variational reference leg.\nvar_reference:  The variational reference family.\ncheckpoint:  Whether a checkpoint should be written to disk at the end of each round.\n\nrecorder_builders: An Vector with elements of type recorder_builder.\n\nchecked_round: The round index where run_checks() will be performed. Set to 0 to skip these checks.\n\nmultithreaded: If multithreaded explorers should be allowed. False by default since it incurs an overhead.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.InterpolatedLogPotential","page":"Reference","title":"Pigeons.InterpolatedLogPotential","text":"A log_potential obtained by evaluation of a path at a  point beta in the closed interval 0 1.  \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.InterpolatingPath-Tuple{Any, Any}","page":"Reference","title":"Pigeons.InterpolatingPath","text":"InterpolatingPath(ref, target)\n\n\nGiven a reference log_potential and a target log_potential,  return a path interpolating between them. \n\nBy default, the interpolator is a LinearInterpolator, i.e.  standard annealing.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.Iterators","page":"Reference","title":"Pigeons.Iterators","text":"Iterators used in Parallel Tempering. Stored in a struct so that  recorder's can access it when outputting  sample statistics.\n\nFields:\n\nround: Index of the Parallel Tempering adaptation round, as defined in Algorithm 4 of Syed et al., 2021. Set to zero when when pigeons() not yet started.\n\nscan: Number of (exploration, communication) pairs performed so far, corresponds to n in Algorithm 1 of Syed et al., 2021. Round i typically performs 2^i scans. Set to zero when runoneround!() is not yet started.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.LoadBalance","page":"Reference","title":"Pigeons.LoadBalance","text":"Split a list of indices across processes.  These indices are denoted 1 2  N. They are usually some kind of task,  for example in the context of parallel tempering,  two kinds of tasks arise:\n\nin replicas.state, task i consists in keeping track of the state of    replica i.\nin replicas.chain_to_replica_global_indices, task i consists in    storing which replica index corresponds to chain i.\n\nOne such task index is called a global_index. \n\nLoadBalance splits the global indices among n_processes. LoadBalance  is constructed so that the difference in the number of global indices  a process is responsible of (its \"load\")  is at most one.\n\nA LoadBalance contains:\n\nmy_process_index: A unique index for this process. We use 1-indexed, i.e. hide MPI's 0-indexed ranks.\n\nn_processes: Total number of processes involved.\n\nn_global_indices: The total number of global indices shared between all the processes.\n\nThe set {1, 2, .., load()} is called a set of local indices.  A local index indexes a slice in {1, 2, ..., n_global_indices}.  Collectively over the n_processes, these slices form a partition of  the global indices.\n\nKey functions to utilize a LoadBalance struct:\n\nmy_global_indices()\nfind_process()\nfind_local_index()\nmy_load()\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.MPI","page":"Reference","title":"Pigeons.MPI","text":"Flag to run on MPI. Before using, you have to call once setup_mpi.\n\nFields: \n\nn_threads: The number of threads per MPI process, 1 by default.\n\nwalltime: The walltime limit, 00:30:00 by default (i.e., 30 minutes).\n\nn_mpi_processes: The number of MPI processes, 2 by default.\n\nmemory: The memory allocated to each MPI process, 8gb by default.\n\ndependencies: Julia modules (if of type Module) or paths to include (if of type String) needed by the child process.\n\nmpiexec_args: Extra arguments passed to mpiexec.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.MPISettings","page":"Reference","title":"Pigeons.MPISettings","text":"Global settings needed for MPI job submission:\n\nallocation_code: E.g., for -A in PBS submission scripts.\n\nenvironment_modules: \"Envirnonment modules\" to load (not to be confused with Julia modules). Run module avail in the HPC login node to see what is available on your HPC. For example: [\"git\", \"gcc\", \"intel-mkl\", \"openmpi\"]\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.NonReversiblePT","page":"Reference","title":"Pigeons.NonReversiblePT","text":"Variables needed for the non-reversible Parallel Tempering described in  Syed et al., 2021:\n\npath:  The path.\nschedule:  The Schedule.\nlog_potentials:  The log_potentials.\nswap_graphs:  The swap_graphs.\ncommunication_barriers:  The communication barriers computed by communication_barriers() at the same time as this tempering was created; or nothing before adaptation, i.e. before the first call to adapt_tempering.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.NonReversiblePT-Tuple{Inputs}","page":"Reference","title":"Pigeons.NonReversiblePT","text":"NonReversiblePT(inputs)\n\n\nThe adaptive non-reversible Parallel Tempering described in  Syed et al., 2021. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.OnlineStateRecorder","page":"Reference","title":"Pigeons.OnlineStateRecorder","text":"See target_online().\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.PT","page":"Reference","title":"Pigeons.PT","text":"Storage involved in PT algorithms:\n\ninputs: The user-provided Inputs that determine the execution of a PT algorithm.\n\nreplicas: The replicas held by this machine.\n\nshared: Information shared across all machines, updated between rounds.\n\nexec_folder: Either a path to a folder shared by all processes, which is used to save information to disk (checkpoints, samples etc); or nothing if a completely in-memory algorithm is used.\n\nreduced_recorders: recorders from the last round, or empty recorders.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.PT-Tuple{AbstractString}","page":"Reference","title":"Pigeons.PT","text":"PT(source_exec_folder; round, fresh_exec_folder)\n\n\nCreate a PT struct from a saved  checkpoint. The path [checkpoint_folder]  should point to a folder with the name  checkpoint found under  results/all/[exec_folder]/round=x.\n\nThe checkpoint carries all the information stored in  a PT struct. It is possible for an MPI-based  execution to load a checkpoint written by a single-process  execution and vice versa.\n\nA new unique folder will be created with symlinks to  the source one, so that e.g. running more rounds of  PT will results in a new space-efficient checkpoint  containing all the information for the new run.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.PT-Tuple{Inputs}","page":"Reference","title":"Pigeons.PT","text":"PT(inputs; exec_folder)\n\n\nCreate a PT struct from provided Inputs.  Optionally, provide a specific exec_folder path (AbstractString),  if not one will be created via next_exec_folder().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.PermutedDistributedArray","page":"Reference","title":"Pigeons.PermutedDistributedArray","text":"A distributed array making special assumptions on how  it will be accessed and written to.  The indices of this distributed array correspond to the  notion of \"global indices\" defined in LoadBalance.  Several MPI processes cooperate, each processing storing  data for a slice of this distributed array. \n\nWe make the following assumptions:\n\nEach MPI process will set/get    entries the same number of times in their lifetime, at    logically related episodes (e.g. a set    number of times per iteration for algorithms running the    same number of iterations).    These episodes are called micro-iterations as in Entangler,    which this datastructure is built on.\nMoreover, at each time all processes perform a get or a set,    we assume that each global index is manipulated by exactly one    process (i.e. an implicit permutation of the global indices).\n\nWe use these assumptions to achieve read/write costs that are  near-constant in the number of machines participating. \n\nThis struct contains:\n\nlocal_data: The slice of the distributed array maintained by this MPI process.\n\nentangler: An Entangler used to coordinate communication.\n\nThe operations supported are:\n\npermuted_get()\npermuted_set!()\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Replica","page":"Reference","title":"Pigeons.Replica","text":"One of the N components that forms the state maintained by a PT algorithm. A Replica contains:\n\nstate:  Configuration in the state space.\nchain:  The index of the distribution currently associated with this replica, modified during swaps.\n\nrng:  Random operations involving this state should use only this random number generator.\n\nrecorders: Records statistics. Each replica carries its own for thread safety/distribution; then they are reduced at end of each round.\n\nreplica_index: A global id associated with this replica.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Result","page":"Reference","title":"Pigeons.Result","text":"A link to an execution folder able to  deserialize type T via a string constructor.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.RoundTripRecorder","page":"Reference","title":"Pigeons.RoundTripRecorder","text":"See round_trip().\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ScaledPrecisionNormalPath","page":"Reference","title":"Pigeons.ScaledPrecisionNormalPath","text":"A path of zero-mean normals for testing; contains:\n\nprecision0: Precision parameter of the reference.\nprecision1: Precision parameter of the target.\ndim: Dimensionality.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ScaledPrecisionNormalPath-Tuple{Int64}","page":"Reference","title":"Pigeons.ScaledPrecisionNormalPath","text":"ScaledPrecisionNormalPath(dim)\n\n\nToy Multivariate Normal (MVN) path of distributions for testing:  see section I.4.1 in Syed et al 2021. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.Schedule","page":"Reference","title":"Pigeons.Schedule","text":"A partition of 0 1 encoded by monotonically increasing grid points  starting at zero and ending at one.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Shared","page":"Reference","title":"Pigeons.Shared","text":"Information shared by all processes involved in  a round of distributed parallel tempering.  This is updated between rounds but only read during  a round. \n\nFields:\n\niterators: See Iterators.\n\ntempering: See tempering.\n\nexplorer: See explorer.\n\nvar_reference: See var_reference\n\nOnly one instance maintained per process. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Shared-Tuple{Any}","page":"Reference","title":"Pigeons.Shared","text":"Shared(inputs)\n\n\nCreate a Shared struct based on an Inputs. \n\nUses create_tempering() and create_explorer().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.SliceSampler","page":"Reference","title":"Pigeons.SliceSampler","text":"Slice sampler based on Neal, 2003.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.StreamState","page":"Reference","title":"Pigeons.StreamState","text":"States used in the replicas when a StreamTarget is used. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.StreamTarget","page":"Reference","title":"Pigeons.StreamTarget","text":"A target based on running worker processes, one for each replica, each communicating with Pigeons  using standard streams.  These worker processes can be implemented in an arbitrary programming language. \n\nStreamTarget implements log_potential and explorer  by invoking worker processes via standard stream communication. The standard stream is less efficient than alternatives such as  protobuff, but it has the advantage of being supported by nearly all  programming languages in existence.  Also in many practical cases, since the worker  process is invoked only three times per chain per iteration, it is unlikely to be the bottleneck (overhead is in the order of 0.1ms).  \n\nThe worker process should be able to reply to commands of the following forms (one command per line):\n\nlog_potential(0.6) in the worker's stdin to which it should return a response of the form    response(-124.23) in its stdout, providing in this example the joint log density at beta = 0.6;\ncall_sampler!(0.4) signaling that one round of local exploration should be performed    at beta = 0.4, after which the worker should signal it is done with response().\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Submission","page":"Reference","title":"Pigeons.Submission","text":"Specifies where to submit a task.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.SwapStat","page":"Reference","title":"Pigeons.SwapStat","text":"Default statistics exchanged by a pair of chains in the process of proposing a swap:\n\nlog_ratio\nuniform\n\nSee swap_stat()\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.TestSwapper","page":"Reference","title":"Pigeons.TestSwapper","text":"For testing/benchmarking purposes, a simple  pair_swapper where all swaps have equal  acceptance probability. \n\nCould also be used to warm-start swap connections  during exploration phase by setting that  constant probability to zero.  \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ThisProcess","page":"Reference","title":"Pigeons.ThisProcess","text":"Flag to ask to run a function within the  current process. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ToyExplorer","page":"Reference","title":"Pigeons.ToyExplorer","text":"Toy explorer for toy paths where each log_potential supports  i.i.d. sampling via rand!(rng, x, log_potential).\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.TuringLogPotential-Tuple{DynamicPPL.Model}","page":"Reference","title":"Pigeons.TuringLogPotential","text":"TuringLogPotential(model)\n\n\nGiven a DynamicPPL.Model from Turing.jl, create a  TuringLogPotential conforming both target and  log_potential.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.VarReference","page":"Reference","title":"Pigeons.VarReference","text":"Abstract type for variational references.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.activate_var_reference-Tuple{Any, Any}","page":"Reference","title":"Pigeons.activate_var_reference","text":"activate_var_reference(var_reference, iterators)\n\n\nChoose on which rounds/scans to activate the variational reference.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.adapt-Tuple{Any, Any}","page":"Reference","title":"Pigeons.adapt","text":"adapt(pt, reduced_recorders)\n\n\nCall adapt_tempering() followed by  adapt_explorer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.adapt_explorer-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.adapt_explorer","text":"adapt_explorer(explorer, reduced_recorders, shared)\n\n\nCalled between successive rounds (run_one_round!). \n\nGiven an explorer, reduced recorders  and Shared return an updated explorer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.adapt_tempering-NTuple{5, Any}","page":"Reference","title":"Pigeons.adapt_tempering","text":"adapt_tempering(\n    tempering,\n    reduced_recorders,\n    iterators,\n    var_reference,\n    state\n)\n\n\nCalled between successive rounds (run_one_round!). \n\nGiven a tempering and reduced recorders  return an updated tempering.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.adapted_schedule-Tuple{Int64, Any}","page":"Reference","title":"Pigeons.adapted_schedule","text":"adapted_schedule(n_chains, cumulativebarrier)\n\n\nCreate a Schedule with n_chains grid points computed using Algorithm 2 in  Syed et al, 2021. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.all_reduce_deterministically-Union{Tuple{T}, Tuple{Any, AbstractVector{T}, Pigeons.Entangler}} where T","page":"Reference","title":"Pigeons.all_reduce_deterministically","text":"all_reduce_deterministically(operation, source_data, e)\n\n\nSame as reduce_deterministically() except that the result at the root of the  tree is then broadcast to all machines so that the output of all_reduce_deterministically()  is the root of the reduction tree for all MPI processes involved. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.allocation_extrema-Tuple{}","page":"Reference","title":"Pigeons.allocation_extrema","text":"Allocations informations. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.analytic_cumulativebarrier-Tuple{Pigeons.ScaledPrecisionNormalPath}","page":"Reference","title":"Pigeons.analytic_cumulativebarrier","text":"analytic_cumulativebarrier(path)\n\n\nKnown cumulative barrier used for testing,  from Predescu et al., 2003.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.blang_ising-Tuple{Any}","page":"Reference","title":"Pigeons.blang_ising","text":"blang_ising(model_options)\n\n\nTwo-dimensional Ising model.\n\nFor more information:\n\nusing Pigeons\n\nPigeons.setup_blang(\"blangDemos\") \nrun(Pigeons.blang_ising(`--help`).command);\n\nE.g., use arguments `model.N` to set the size \nof the grid. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.blang_ising-Tuple{}","page":"Reference","title":"Pigeons.blang_ising","text":"blang_ising()\n\n\n15x15 Ising model. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.blang_sitka-Tuple{Any}","page":"Reference","title":"Pigeons.blang_sitka","text":"blang_sitka(model_options)\n\n\nModel for phylogenetic inference from single-cell copy-number alteration from  Salehi et al., 2020. \n\nFor more information:\n\nusing Pigeons\n\nPigeons.setup_blang(\"nowellpack\") \nrun(Pigeons.blang_sitka(`--help`).command);\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.blang_sitka-Tuple{}","page":"Reference","title":"Pigeons.blang_sitka","text":"blang_sitka()\n\n\nDefault options for infering a posterior distribution on  phylogenetic trees for   the 535 triple negative breast cancer dataset in  Salehi et al., 2020.   \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.check_against_serial-Tuple{Any}","page":"Reference","title":"Pigeons.check_against_serial","text":"check_against_serial(pt)\n\n\nRun a separate, fully serial version of the PT algorithm,  and compare the checkpoint files to ensure the two  produce exactly the same output.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.checksum","page":"Reference","title":"Pigeons.checksum","text":"checksum(filename)\nchecksum(filename, blocksize)\n\n\nGiven a filename path, compute a crc32c() checksum  in constant memory. \n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.communicate!-Tuple{Any}","page":"Reference","title":"Pigeons.communicate!","text":"communicate!(pt)\n\n\nUse create_pair_swapper() and  create_swap_graph to construct the  inputs needed for swap!.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.communication_barriers-Tuple{AbstractVector, AbstractVector}","page":"Reference","title":"Pigeons.communication_barriers","text":"communication_barriers(intensity, schedule)\n\n\nCompute the local communication barrier and cumulative barrier functions from the  intensity rates (i.e. rejection rates in the context of Parallel Tempering) and  the current annealing schedule. The estimation of the barriers  is based on Fritsch-Carlson monotonic interpolation.\n\nReturns a NamedTuple with fields:\n\nlocalbarrier\ncumulativebarrier\nglobalbarrier\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.communicator-Tuple{Any}","page":"Reference","title":"Pigeons.communicator","text":"communicator(replicas)\n\n\nReturn the replicas's MPI.Comm or nothing if no MPI needed\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.continuous_variables-Tuple{Any}","page":"Reference","title":"Pigeons.continuous_variables","text":"continuous_variables(state)\n\n\nThe names (each a Symbol) of the continuous variables in the given state. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.continuous_variables-Tuple{PT}","page":"Reference","title":"Pigeons.continuous_variables","text":"continuous_variables(pt)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_entangled_replicas-Tuple{Inputs, Pigeons.Shared, Any}","page":"Reference","title":"Pigeons.create_entangled_replicas","text":"create_entangled_replicas(inputs, shared, source)\n\n\nCreate distributed replicas. \n\nSee create_replicas.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_explorer-Tuple{Any, Any}","page":"Reference","title":"Pigeons.create_explorer","text":"create_explorer(target, inputs)\n\n\nCurrent explorer for Turing models: a SliceSampler. Slice sampler has the advantage of being not very sensitive to tuning. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_explorer-Tuple{Any, Inputs}","page":"Reference","title":"Pigeons.create_explorer","text":"create_explorer(target, inputs)\n\n\nCreate an explorer for the given target.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_explorer-Tuple{Any}","page":"Reference","title":"Pigeons.create_explorer","text":"create_explorer(inputs)\n\n\nGiven an Inputs object, dispatch on  create_explorer(inputs.target, inputs) to construct the  explorer associated with the input target distribution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_pair_swapper-Tuple{Any, Any}","page":"Reference","title":"Pigeons.create_pair_swapper","text":"create_pair_swapper(tempering, target)\n\n\nGiven a tempering and a Shared struct,  create a pair_swapper. \n\nIf omitted, by default will return the standard Metropolis-Hastings  accept-reject. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_path-Tuple{Any, Inputs}","page":"Reference","title":"Pigeons.create_path","text":"create_path(target, inputs)\n\n\nCreate a path, by default linking the given target to  the refence provided by create_reference_log_potential().\n\nFor this default to work, the target should conform both  target and log_potential.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_path-Tuple{Pigeons.ScaledPrecisionNormalPath, Inputs}","page":"Reference","title":"Pigeons.create_path","text":"create_path(target, inputs)\n\n\nIn this case, the target is already a path, so return it. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_recorders-Tuple{Any}","page":"Reference","title":"Pigeons.create_recorders","text":"create_recorders(recorder_builders)\n\n\nCreate a recorders from an iterable with element  type recorder_builder.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_recorders-Tuple{Inputs, Pigeons.Shared}","page":"Reference","title":"Pigeons.create_recorders","text":"create_recorders(inputs, shared)\n\n\nCreate a recorders from an Inputs and Shared.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_reference_log_potential-Tuple{Any, Inputs}","page":"Reference","title":"Pigeons.create_reference_log_potential","text":"create_reference_log_potential(target, inputs)\n\n\nCreate a default reference distribution, by returning a  log_potential. The returned object will also get  passed to sample_iid!() at the \"hot chains\" of  the Parallel Tempering algorithm. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_replicas-Tuple{Inputs, Pigeons.Shared, Any}","page":"Reference","title":"Pigeons.create_replicas","text":"create_replicas(inputs, shared, source)\n\n\nCreate replicas, detecting automatically if MPI is needed. \n\nArgument source is either a state_initializer to create  fresh replicas, or FromCheckpoint to load from  a saved checkpoint.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_state_initializer-Tuple{Any, Inputs}","page":"Reference","title":"Pigeons.create_state_initializer","text":"create_state_initializer(target, inputs)\n\n\nReturn a state_initializer used to populate  the states at the beginning of the first round of  Parallel Tempering. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_swap_graph-Tuple{Any, Any}","page":"Reference","title":"Pigeons.create_swap_graph","text":"create_swap_graph(swap_graphs, shared)\n\n\nGiven a swap_graphs and Shared, return  the swap_graph for the current iteration. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_tempering-Tuple{Inputs}","page":"Reference","title":"Pigeons.create_tempering","text":"create_tempering(inputs)\n\n\nBuild the tempering needed for communicate!(). \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_var_reference-Tuple{Any}","page":"Reference","title":"Pigeons.create_var_reference","text":"Create a variational reference.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_vector_replicas-Tuple{Inputs, Pigeons.Shared, Any}","page":"Reference","title":"Pigeons.create_vector_replicas","text":"create_vector_replicas(inputs, shared, source)\n\n\nCreate replicas when distributed computing is not needed.  See also state_initializer.\n\nSee create_replicas.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.default_recorder_builders-Tuple{}","page":"Reference","title":"Pigeons.default_recorder_builders","text":"Set of recorders with no measurable impact on performance. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.deo-Tuple{Any}","page":"Reference","title":"Pigeons.deo","text":"deo(n_chains)\n\n\nImplements the Deterministic Even Odd (DEO) scheme proposed in Okabe, 2001 and analyzed in Syed et al., 2021.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.deserialize_immutables-Tuple{AbstractString}","page":"Reference","title":"Pigeons.deserialize_immutables","text":"deserialize_immutables(filename)\n\n\nSee Immutable().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.discrete_variables-Tuple{Any}","page":"Reference","title":"Pigeons.discrete_variables","text":"discrete_variables(state)\n\n\nThe names (each a Symbol) of the discrete (Int) variables in the given state. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.discretize-Tuple{Any, Pigeons.Schedule}","page":"Reference","title":"Pigeons.discretize","text":"discretize(path, betas)\n\n\nCreate log_potentials from a path by interpolating the  path at each grid point specified in the Schedule.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.energy_ac1-Tuple{}","page":"Reference","title":"Pigeons.energy_ac1","text":"Auto-correlation before and after an exploration step, grouped by   chain.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.energy_ac1s","page":"Reference","title":"Pigeons.energy_ac1s","text":"energy_ac1s(reduced_recorders)\nenergy_ac1s(reduced_recorders, skip_reference)\nenergy_ac1s(reduced_recorders, skip_reference, pt)\n\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.energy_ac1s-2","page":"Reference","title":"Pigeons.energy_ac1s","text":"energy_ac1s(pt)\nenergy_ac1s(pt, skip_reference)\n\n\nAuto-correlations between energy before and after an exploration step,  for each chain. Organized as a Vector where component i corresponds  to chain i.\n\nIt is often useful to skip the reference chain, for two reasons, first,  exploration should be iid there, second, if the prior is flat the  auto-correlation of the energy will be NaN for the reference.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.entangler-Tuple{Any}","page":"Reference","title":"Pigeons.entangler","text":"entangler(replicas)\n\n\nReturn the replicas's Entangler (possibly a no-communication Entangler if a single process is involved)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.equally_spaced_schedule-Tuple{Int64}","page":"Reference","title":"Pigeons.equally_spaced_schedule","text":"equally_spaced_schedule(n_chains)\n\n\nCreate a Schedule with n_chains equally spaced grid points.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explore!-Tuple{Any, Any, Val{false}}","page":"Reference","title":"Pigeons.explore!","text":"explore!(pt, explorer, multithreaded)\n\n\nThe @threads macro brings a large overhead even  when Threads.nthreads == 1 (!), so a separate method  is used for the single thread mode.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explore!-Tuple{Any, Any, Val{true}}","page":"Reference","title":"Pigeons.explore!","text":"explore!(pt, explorer, multithreaded_flag)\n\n\nCall sample_iid! or step!() on  each chain (depending if it is a reference or not  respectively). \n\nUses @threads to parallelize across threads.  This is safe by the contract described in  sample_iid!() and step!().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explorer_recorder_builders-Tuple{Any}","page":"Reference","title":"Pigeons.explorer_recorder_builders","text":"explorer_recorder_builders(explorer)\n\n\nWhat information is needed to perform adapt_explorer? Answer this by specifying an iterator containing recorder_builder's.  Return [] if none are needed. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_global_index-Tuple{Pigeons.LoadBalance, Int64}","page":"Reference","title":"Pigeons.find_global_index","text":"find_global_index(lb, local_idx)\n\n\nFind the global index corresponding to the given local_index. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_local_index-Tuple{Pigeons.LoadBalance, Int64}","page":"Reference","title":"Pigeons.find_local_index","text":"find_local_index(lb, global_idx)\n\n\nFind the local index corresponding to the given global_index.  Assumes the given global_index is one of this process'. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_log_potential-Tuple{Any, Any}","page":"Reference","title":"Pigeons.find_log_potential","text":"find_log_potential(replica, shared)\n\n\nFind the log_potential for the chain  the replica is at, based on the Shared object.  \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_process-Tuple{Pigeons.LoadBalance, Int64}","page":"Reference","title":"Pigeons.find_process","text":"find_process(lb, global_idx)\n\n\nFind the process id (1-indexed) responsible for the given global_idx. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.flush_immutables!-Tuple{}","page":"Reference","title":"Pigeons.flush_immutables!","text":"flush_immutables!()\n\n\nSee Immutable().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.index_process-Tuple{}","page":"Reference","title":"Pigeons.index_process","text":"Full index process stored in memory. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.informal_doc-Tuple{Any, Module}","page":"Reference","title":"Pigeons.informal_doc","text":"informal_doc(doc_dir, mod)\n\n\nGenerate informal interface documentation, e.g.: \n\nmakedocs(;\n    ...\n    pages=[\n        \"Home\" => \"index.md\", \n        \"Interfaces\" => informal_doc(@__DIR__, MyModuleName),\n        ...\n    ]\n)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.initialization-Tuple{Any, SplittableRandoms.SplittableRandom, Int64}","page":"Reference","title":"Pigeons.initialization","text":"initialization(state_initializer, rng, replica_index)\n\n\nDetermine state_initializer's initialization for the given replica_index.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.initialization-Tuple{Pigeons.StreamTarget, SplittableRandoms.SplittableRandom, Int64}","page":"Reference","title":"Pigeons.initialization","text":"initialization(target, rng, replica_index)\n\n\nReturn StreamState by following these steps:\n\ncreate a Cmd that uses the provided rng to set the random seed properly, as well   as target-specific configurations provided by target.\nCreate StreamState from the Cmd created in step 1 and return it.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.interpolate-Tuple{Any, Any}","page":"Reference","title":"Pigeons.interpolate","text":"interpolate(path, beta)\n\n\nReturns the log_potential at point beta in the path.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.is_finished-Tuple{AbstractString, Any}","page":"Reference","title":"Pigeons.is_finished","text":"is_finished(checkpoint_folder, inputs)\n\n\nIs the provided path to a checkpoint folder complete?  I.e. check in the .signal subfolder that all MPI processes have  signaled that they are done.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.is_reference-Tuple{Any, Int64}","page":"Reference","title":"Pigeons.is_reference","text":"is_reference(swap_graphs, chain)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.is_target-Tuple{Any, Int64}","page":"Reference","title":"Pigeons.is_target","text":"is_target(swap_graphs, chain)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.kill_job-Tuple{Result}","page":"Reference","title":"Pigeons.kill_job","text":"kill_job(result)\n\n\nInstruct the scheduler to cancel or kill a job. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.last_round_max_allocation-Tuple{Any}","page":"Reference","title":"Pigeons.last_round_max_allocation","text":"Maximum bytes allocated (over the MPI process) to compute the last Parallel Tempering round. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.last_round_max_time-Tuple{Any}","page":"Reference","title":"Pigeons.last_round_max_time","text":"Maximum time (over the MPI process) to compute the last Parallel Tempering round. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.latest_checkpoint_folder-Tuple{Any}","page":"Reference","title":"Pigeons.latest_checkpoint_folder","text":"latest_checkpoint_folder(exec_folder)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.load-Tuple{Any}","page":"Reference","title":"Pigeons.load","text":"load(replicas)\n\n\nReturn the replicas's LoadBalance (possibly single_process_load)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.load-Union{Tuple{Result{T}}, Tuple{T}} where T","page":"Reference","title":"Pigeons.load","text":"load(replicas)\nload(result)\n\n\nLoad the result in memory.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.locals-Tuple{Any}","page":"Reference","title":"Pigeons.locals","text":"locals(replicas)\n\n\nReturn the replica's that are stored in this machine\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.log_sum_ratio-Tuple{}","page":"Reference","title":"Pigeons.log_sum_ratio","text":"Log of the sum of density ratios between neighbour chains, used  to compute stepping stone estimators of lognormalization contants.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.log_unnormalized_ratio-Tuple{AbstractVector, Int64, Int64, Any}","page":"Reference","title":"Pigeons.log_unnormalized_ratio","text":"log_unnormalized_ratio(\n    log_potentials,\n    numerator,\n    denominator,\n    state\n)\n\n\nAssumes the input log_potentials is a vector where each element is a log_potential.\n\nThis default implementation is sufficient in most cases, but in less standard scenarios, e.g. where the state space is infinite dimensional, this can be overridden. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.log_unnormalized_ratio-Tuple{Any, Int64, Int64, Any}","page":"Reference","title":"Pigeons.log_unnormalized_ratio","text":"log_unnormalized_ratio(\n    log_potentials,\n    numerator,\n    denominator,\n    state\n)\n\n\nThe argument numerator selects one distribution pi_i from the collection log_potentials,  and similarly denominator selects pi_j. Let x denote the input state. The ratio:\n\nf(x) = fractextdpi_itextdpi_j(x)\n\nmay only be known up to a normalization constant which can depend on i and j but  not x, g(x) = C_ij f(x).\n\nThis function should return log g evaluated at state.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.mpi_active-Tuple{}","page":"Reference","title":"Pigeons.mpi_active","text":"mpi_active()\n\n\nA flag is set by launch scripts (see ChildProcess.jl) to indicate  if this process is a child MPI process under an mpiexec.  Otherwise, that flag is false by default.\n\nThis function retrieves the value of that flag. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.my_global_indices-Tuple{Pigeons.LoadBalance}","page":"Reference","title":"Pigeons.my_global_indices","text":"my_global_indices(lb)\n\n\nThe slice of lb.global_indices this process is reponsible for.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.my_load-Tuple{Pigeons.LoadBalance}","page":"Reference","title":"Pigeons.my_load","text":"my_load(lb)\n\n\nReturn the number of indices (task) this process is responsible for. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_chains-Tuple{Any}","page":"Reference","title":"Pigeons.n_chains","text":"n_chains(log_potentials)\n\n\nThe number of chains in the log_potentials.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_round_trips-Tuple{Any}","page":"Reference","title":"Pigeons.n_round_trips","text":"n_round_trips(reduced_recorders)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_round_trips-Tuple{PT}","page":"Reference","title":"Pigeons.n_round_trips","text":"n_round_trips(pt)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_tempered_restarts-Tuple{Any}","page":"Reference","title":"Pigeons.n_tempered_restarts","text":"n_tempered_restarts(reduced_recorders)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_tempered_restarts-Tuple{PT}","page":"Reference","title":"Pigeons.n_tempered_restarts","text":"n_tempered_restarts(pt)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.next_exec_folder-Tuple{}","page":"Reference","title":"Pigeons.next_exec_folder","text":"Return a unique subfolder of  results/all/, making sure the  unique folder and its parents are created.  It will also create a soft symlink to it  called results/latest`\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.number_of_chains-Tuple{Any}","page":"Reference","title":"Pigeons.number_of_chains","text":"Extract the number of PT chains from Inputs. TODO: Once you implement PT with two reference distributions, update this function.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.one_per_host-Tuple{Any}","page":"Reference","title":"Pigeons.one_per_host","text":"For benchmarking purpose: subset the communicator so that at most one MPI process runs      in each machine.\n\nDivision is done so that original rank 0 is always included.\n\nReturn the new communicator or nothing if this machine is not in the subset. \n\nSee also '-s' option in mpi-run\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.online_recorder_builders-Tuple{}","page":"Reference","title":"Pigeons.online_recorder_builders","text":"Set of constant memory recorders.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.only_one_process-Tuple{Any, Any}","page":"Reference","title":"Pigeons.only_one_process","text":"only_one_process(task, pt)\n\n\nA task that should be ran on only one of the processes.  Using the do .. end syntax, this can be used as:\n\nonly_one_process(pt) do \n    ...\nend\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.optimal_schedule-Tuple{AbstractVector, Pigeons.Schedule, Int64}","page":"Reference","title":"Pigeons.optimal_schedule","text":"optimal_schedule(\n    intensity,\n    old_schedule,\n    new_schedule_n_chains\n)\n\n\nReturn an optimal Schedule based on statistics from a previous round. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.partner_chain-Tuple{Any, Int64}","page":"Reference","title":"Pigeons.partner_chain","text":"partner_chain(swap_graph, chain)\n\n\nFor a given swap_graph and input chain index, what chain will it interact with at the current iteration? Convention: if a chain is not interacting, return its index.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.permuted_get-Union{Tuple{T}, Tuple{Pigeons.PermutedDistributedArray{T}, AbstractVector{Int64}}} where T","page":"Reference","title":"Pigeons.permuted_get","text":"permuted_get(p, indices)\n\n\nRetreive the values for the given indices, using MPI communication when needed. \n\nWe make the following assumptions:\n\nlength(indices) == my_load(p.entangler.load)\nthe indices across all participating processes form a permutation of the global indices. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.permuted_set!-Union{Tuple{T}, Tuple{Pigeons.PermutedDistributedArray{T}, AbstractVector{T}, AbstractVector{T}}} where T","page":"Reference","title":"Pigeons.permuted_set!","text":"permuted_set!(p, indices, new_values)\n\n\nSet the values for the given indices to the given new_values, using MPI communication when needed. \n\nWe make the same assumptions as in permuted_get().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{Any, ChildProcess}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(pt_arguments, new_process)\n\n\nRun Parallel Tempering in a new process.  See ChildProcess.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{Any, MPI}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(pt_arguments, mpi_submission)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{Any}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(pt_arguments; on)\n\n\npt_arguments can be either an Inputs, to start  a new Parallel Tempering algorithm, or a string pointing to  an execution to resume. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{PT}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(pt)\n\n\nRun (a generalization of) Parallel Tempering. \n\nThis will call several rounds of run_one_round!(),  performing adaptation between each round via adapt().\n\nThis will also call report(), write_checkpoint(),  and run_checks() between rounds. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(; on, args...)\n\n\nPasses the args... to Inputs and start  a new Parallel Tempering algorithm with that inputs. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.providers-Tuple{Module, Symbol}","page":"Reference","title":"Pigeons.providers","text":"providers(mod, name)\n\n\nProvides a Set{Expr} containing all the providers of the  given name in the given module. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.queue_status-Tuple{Result}","page":"Reference","title":"Pigeons.queue_status","text":"queue_status(result)\n\n\nDisplay the queue status for one MPI job. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.queue_status-Tuple{}","page":"Reference","title":"Pigeons.queue_status","text":"queue_status()\n\n\nDisplay the queue status for all the user's jobs. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record!-Tuple{Any, Any}","page":"Reference","title":"Pigeons.record!","text":"record!(recorder, value)\n\n\nAdd value to the statistics accumulated by recorder. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record!-Tuple{OnlineStatsBase.OnlineStat, Any}","page":"Reference","title":"Pigeons.record!","text":"record!(recorder, value)\n\n\nForwards to OnlineStats' fit!.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record!-Union{Tuple{V}, Tuple{K}, Tuple{Dict{K, Vector{V}}, Tuple{K, V}}} where {K, V}","page":"Reference","title":"Pigeons.record!","text":"record!(recorder, value)\n\n\nGiven a value, a pair (a, b), and a Dict{K, Vector{V}} backed  recorder,  append b to the vector corresponding to a, inserting an empty  vector into the dictionary first if needed.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record_if_requested!-Tuple{Any, Symbol, Any}","page":"Reference","title":"Pigeons.record_if_requested!","text":"record_if_requested!(recorders, recorder_key, value)\n\n\nIf the recorders contains the given recorder_key,  send the value to the recorder corresponding to the  recorder_key. Otherwise, do nothing.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record_swap_stats!-Tuple{Any, Any, Int64, Any, Int64, Any}","page":"Reference","title":"Pigeons.record_swap_stats!","text":"record_swap_stats!(\n    pair_swapper,\n    recorders,\n    chain1,\n    stat1,\n    chain2,\n    stat2\n)\n\n\nGiven a pair_swapper, a recorders, the provided chain indices, and  the sufficient statistics computed by swap_stat(), record statistics. \n\nTo avoid accumulating twice the same statistic with (chain1, chain2) and  (chain2, chain2), swap!() only calls this for the pair with chain1 < chain2.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record_swap_stats!-Tuple{Pigeons.TestSwapper, Any, Int64, Any, Int64, Any}","page":"Reference","title":"Pigeons.record_swap_stats!","text":"record_swap_stats!(\n    swapper,\n    recorder,\n    chain1,\n    stat1,\n    chain2,\n    stat2\n)\n\n\nSee TestSwapper.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.reduce_deterministically-Union{Tuple{T}, Tuple{Any, AbstractVector{T}, Pigeons.Entangler}} where T","page":"Reference","title":"Pigeons.reduce_deterministically","text":"reduce_deterministically(operation, source_data, e)\n\n\nPerform a binary reduction of the  source_data, using MPI when needed. \n\nConsider the binary tree with leaves given by the global indices specified in e.load and stored  in the different MPI processes' input source_data vectors.  At each node of the tree, a reduction is performed using operation, i.e.  by calling operation(left_child, right_child). When, and only when a branch of the tree crosses from one MPI process to another one,  MPI communication is used to transmit the intermediate reduction. \n\nAt the end, for process 1, reduce_deterministically() will return the root of the  binary tree, and for the other processes, reduce_deterministically() will return  nothing. \n\nNote that even when the operation is only approximately associative (typical situation  for floating point reductions), the output of this function is invariant to the  number of MPI processes involved (hence the terminology 'deterministically').  This contrasts to direct use of MPI collective communications where the leaves are  MPI processes and hence will give slightly different outputs given different  numbers of MPI processes. In the context of randomized algorithms, these minor  differences are then amplified. \n\nIn contrast to transmit!(), we do not assume isbitstype(T) == true and use  serialization when messages are transmitted over MPI.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.reduce_recorders!-Tuple{Pigeons.EntangledReplicas}","page":"Reference","title":"Pigeons.reduce_recorders!","text":"reduce_recorders!(replicas)\n\n\nPerform a reduction across all the replicas' individual recorders,  using Base.merge() on each individual recorder held. Returns a recorders with all the information merged. \n\nWill reset the replicas' recorders at the same time using Base.empty!().\n\nSince this uses all_reduce_deterministically, the output is  identical, no matter how many MPI processes are used, even when  the reduction involves only approximately associative Base.merge() operations (e.g. most floating point ones).\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.report-Tuple{Any}","page":"Reference","title":"Pigeons.report","text":"report(pt)\n\n\nReport summary information on the progress of pigeons().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.round_trip-Tuple{}","page":"Reference","title":"Pigeons.round_trip","text":"Restart and round-trip counts. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.run_checks-Tuple{Any}","page":"Reference","title":"Pigeons.run_checks","text":"Perform checks to detect software defects.  Unable via field checked_round in Inputs Currently the following checks are implemented:\n\ncheck_against_serial()\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.run_one_round!-Tuple{Any}","page":"Reference","title":"Pigeons.run_one_round!","text":"run_one_round!(pt)\n\n\nFrom a PT object, run one round of  a generalized version of Algorithm 1 in  Syed et al., 2021.\n\nAlternates between communicate!(),  which consists of any pairwise communicating  moves and [explore!()], which consists in  moves independ to each chain. \n\nConcrete specification of how to communicate and  explore are specified by the field of type Shared  contained in the provided PT. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.safelink-Tuple{AbstractString, AbstractString}","page":"Reference","title":"Pigeons.safelink","text":"safelink(target, link)\n\n\nWork around two issues with symlink():\n\nnaively calling symlink() when there are relative paths leads to broken links\non windows, one needs admin permission to do symlinks, so print a helpful error message in that case\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.sample_iid!-Tuple{Any, Any}","page":"Reference","title":"Pigeons.sample_iid!","text":"sample_iid!(reference_log_potential, replica)\n\n\nPerform i.i.d. sampling on the given Replica  during its visit to the referencelogpotential created  by create_reference_log_potential().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.sample_iid!-Tuple{Pigeons.VarReference, Any}","page":"Reference","title":"Pigeons.sample_iid!","text":"sample_iid!(var_reference, replica)\n\n\nObtain one iid sample from the reference distribution specified by the variational family.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.serialize_immutables-Tuple{AbstractString}","page":"Reference","title":"Pigeons.serialize_immutables","text":"serialize_immutables(filename)\n\n\nSee Immutable().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.setup_blang","page":"Reference","title":"Pigeons.setup_blang","text":"setup_blang(repo_name)\nsetup_blang(repo_name, organization)\n\n\nDownload the github repo with the given repo_name and organization in ~.pigeons,  and compile the blang code. \n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.setup_mpi-Tuple{Pigeons.MPISettings}","page":"Reference","title":"Pigeons.setup_mpi","text":"setup_mpi(settings)\n\n\nRun this function once before running MPI jobs.  The setting are permanently saved.  See MPISettings.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.setup_mpi-Tuple{}","page":"Reference","title":"Pigeons.setup_mpi","text":"setup_mpi(; args...)\n\n\nArguments are passed in the constructor of MPISettings.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.single_process_load-Tuple{Any}","page":"Reference","title":"Pigeons.single_process_load","text":"single_process_load(n_global_indices)\n\n\nA load balance with only one process.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.slice_accept-Tuple{Pigeons.SliceSampler, Any, Any, Any, Any, Any, Any, Any}","page":"Reference","title":"Pigeons.slice_accept","text":"slice_accept(\n    h,\n    state,\n    new_position,\n    z,\n    L,\n    R,\n    pointer,\n    log_potential\n)\n\n\nTest whether to accept the current slice.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.slice_double-Tuple{Pigeons.SliceSampler, Any, Any, Any, Any, Any}","page":"Reference","title":"Pigeons.slice_double","text":"slice_double(h, state, z, pointer, log_potential, rng)\n\n\nDouble the current slice.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.slice_sample!-Tuple{Pigeons.SliceSampler, AbstractVector, Any, Any}","page":"Reference","title":"Pigeons.slice_sample!","text":"slice_sample!(h, state, log_potential, rng)\n\n\nSlice sample one point.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.slice_shrink-Tuple{Pigeons.SliceSampler, Any, Any, Any, Any, Any, Any, Any}","page":"Reference","title":"Pigeons.slice_shrink","text":"slice_shrink(h, state, z, L, R, pointer, log_potential, rng)\n\n\nShrink the current slice.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.sort_includes!-Tuple{Any}","page":"Reference","title":"Pigeons.sort_includes!","text":"sort_includes!(main)\n\n\nHeuristic to automate the process  of sorting include()'s.\n\nTopological sorting of the source files under src  (excluding main) is attempted, if successful, print the  include string to copy and paste to the main file, otherwise,  print the detected loops. \n\nInternally, this function will:\n\nConstruct a graph where the vertices are the .jl files   under src, excluding the provided main file (i.e. where the module is   defined and the includes will sit in).\nEach file starting with a capital letter is assumed to   contain a struct with the same name as the file after   removal of the .jl suffix. Similarly, files starting   with @ are assumed to contain a macro with the similarly   obtained name.\nEach source file is inspected to see if the above struct and   macro strings are detected. This defines edges in the graph.  (known limitation: this includes spurious edges when e.g.   the string occurs in a comment).\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.split_slice-Tuple{UnitRange, Any}","page":"Reference","title":"Pigeons.split_slice","text":"split_slice(slice, rng)\n\n\nFrom one splittable random object, one can conceptualize an infinite list of splittable random objects.  Return a slice from this infinite list.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.step!-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.step!","text":"step!(explorer, replica, shared)\n\n\nPerform a transition on the given Replica  invariant with respect to the distribution of the  replica's chain. \n\nThe input explorer and Shared should only  be read, not written to. \n\nSee also find_log_potential. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.stepping_stone_pair-Tuple{PT}","page":"Reference","title":"Pigeons.stepping_stone_pair","text":"stepping_stone_pair(pt)\n\n\nAssuming that the reference distribution has a normalization constant of one,  compute the (log of) the stepping stone estimator.  It returns a pair, one such that its exponential is unbiased under  Assumptions (A1-2) in Syed et al., 2021 for Z and the  other, for 1Z.  Both are consistent in the number of MCMC iterations without these strong assumptions. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap!-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.swap!","text":"swap!(pair_swapper, replicas, swap_graph)\n\n\nFor each pair of chains encoded in swap_graph, use  pair_swapper to decide if the pair will swap or not,  and write the changes in-place into replicas (i.e. exchanging  the Replica's chain fields for those that swapped.)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap!-Tuple{Any, Pigeons.EntangledReplicas, Any}","page":"Reference","title":"Pigeons.swap!","text":"swap!(pair_swapper, replicas, swap_graph)\n\n\nEntangled MPI swap! implementation.\n\nThis implementation is designed to support distributed PT with the following guarantees\n\nThe running time is independent of the size of the state space      ('swapping annealing parameters rather than states')\nThe output is identical no matter how many MPI processes are used. In particular,      this means that we can check correctness by comparing to the serial, single-process version.\nScalability to 1000s of processes communicating over MPI (see details below).\nThe same function can be used when a single process is used and MPI is not available.\nFlexibility to extend PT to e.g. networks of targets and general paths.\n\nRunning time analysis:\n\nLet N denote the number of chains, P, the number of processes, and K = textceil(NP),   the maximum number of chains held by one process.  Assuming the running time is dominated by communication latency and  a constant time for the latency of each   peer-to-peer communication, the theoretical running time is O(K).  In practice, latency will grow as a function of P, but empirically, this growth appears to be slow enough that for say P = N = a few 1000s,  swapping will not be the computational bottleneck.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap!-Union{Tuple{R}, Tuple{Any, Vector{R}, Any}} where R","page":"Reference","title":"Pigeons.swap!","text":"swap!(pair_swapper, replicas, swap_graph)\n\n\nSingle process, non-allocating swap! implementation. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_acceptance_pr-Tuple{}","page":"Reference","title":"Pigeons.swap_acceptance_pr","text":"Average MH swap acceptance probabilities for each pairs  of interacting chains. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_decision-Tuple{Any, Int64, Any, Int64, Any}","page":"Reference","title":"Pigeons.swap_decision","text":"swap_decision(pair_swapper, chain1, stat1, chain2, stat2)\n\n\nGiven a pair_swapper, a recorders, the provided chain indices, and  the sufficient statistics computed by swap_stat(), make a swap decision.\n\nBy default, this is done as follows:\n\ncompute the standard swap acceptance probability min(1, exp(stat1.log_ratio + stat2.log_ratio))\nmake sure the two chains share the same uniform by picking the uniform from the chain with the smallest chain index \nswap if the shared uniform is smaller than the swap acceptance probability.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_decision-Tuple{Pigeons.TestSwapper, Int64, Float64, Int64, Float64}","page":"Reference","title":"Pigeons.swap_decision","text":"swap_decision(swapper, chain1, stat1, chain2, stat2)\n\n\nSee TestSwapper.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_stat-Tuple{Any, Pigeons.Replica, Int64}","page":"Reference","title":"Pigeons.swap_stat","text":"swap_stat(pair_swapper, replica, partner_chain)\n\n\nBy default, two sufficient statistics are computed and stored in the SwapStat struct:\n\nThe result of calling log_unnormalized_ratio() on pair_swapper\nA uniform number to coordinate the swap decision.\n\nThis can be extended by dispatching on other pair_swapper types, with the  constraint that the returned sufficient statistics should satisfy isbitstype().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_stat-Tuple{Pigeons.TestSwapper, Pigeons.Replica, Int64}","page":"Reference","title":"Pigeons.swap_stat","text":"swap_stat(swapper, replica, partner_chain)\n\n\nSee TestSwapper.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.target_online-Tuple{}","page":"Reference","title":"Pigeons.target_online","text":"Online statistics on the target chain. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.tempering_recorder_builders-Tuple{Any}","page":"Reference","title":"Pigeons.tempering_recorder_builders","text":"tempering_recorder_builders(tempering)\n\n\nWhat information is needed to perform adapt_tempering? Answer this by specifying an iterator containing recorder_builder's.  Return [] if none are needed.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.timing_extrema-Tuple{}","page":"Reference","title":"Pigeons.timing_extrema","text":"Timing informations. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.toy_mvn_target-Tuple{Int64}","page":"Reference","title":"Pigeons.toy_mvn_target","text":"toy_mvn_target(dim)\n\n\nA toy multi-variate normal (mvn) target distribution used for testing.  Uses a specialized path, ScaledPrecisionNormalPath,  such that i.i.d. sampling is possible at all chains (via ToyExplorer). \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.transmit!-Union{Tuple{T}, Tuple{Pigeons.Entangler, AbstractVector{T}, AbstractVector{Int64}, Vector{T}}} where T","page":"Reference","title":"Pigeons.transmit!","text":"transmit!(\n    e,\n    source_data,\n    to_global_indices,\n    write_received_data_here\n)\n\n\nUse MPI point-to-point communication to  permute the contents of source_data across MPI processes, writing the permuted data into  write_received_data_here.  The permutation is specified by the load balance in the input argument e as well as the  argument to_global_indices.\n\nMore precisely, assume the Vectors source_data, to_global_indices, and write_received_data_here  are all of the length specified in my_load(e.load). \n\nFor each i, source_data[i] is sent to MPI process p = find_process(e.load, g),  where g = to_global_indices[i] and  written into this p 's write_received_data_here[j], where j = find_local_index(e.load, g)\n\nSee Entangler's comments regarding the requirement that all machines call transmit() the  same number of times and at logically related intervals. \n\nAdditionally, at each micro-iteration, we assume that  {to_global_indices_p : p ranges over the different processes} forms a partition of  {1, ..., e.load.n_global_indices} If ran in single-process mode, this 'partition property' is checked;  if ran in multi-process, opportunistic checks will be made, namely when several entries in to_global_indices  lie in the same process, but systematic checks are not made for performance reasons. \n\nWe also assume isbitstype(T) == true. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.transmit-Union{Tuple{T}, Tuple{Pigeons.Entangler, AbstractVector{T}, AbstractVector{Int64}}} where T","page":"Reference","title":"Pigeons.transmit","text":"transmit(e, source_data, to_global_indices)\n\n\nThe same as transmit!() but instead of writing the result to an input argument, provide the result  as a returned Vector. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.update_reference!-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.update_reference!","text":"update_reference!(reduced_recorders, var_reference, state)\n\n\nUpdate the variational reference and the annealing path. Returns the new annealing path.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.update_state!-Tuple{Any, Symbol, Any, Any}","page":"Reference","title":"Pigeons.update_state!","text":"update_state!(state, name, index, value)\n\n\nUpdate the state's entry at symbol name and index with value.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.var_reference_recorder_builders-Tuple{Any}","page":"Reference","title":"Pigeons.var_reference_recorder_builders","text":"var_reference_recorder_builders(var_reference)\n\n\nSpecify the recorder builders for this variational reference family.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.variable-Tuple{Any, Symbol}","page":"Reference","title":"Pigeons.variable","text":"variable(state, name)\n\n\nThe storage within the state of the variable of the given name, typically an Array.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.watch-Tuple{Result}","page":"Reference","title":"Pigeons.watch","text":"watch(result; machine, last, interactive)\n\n\nPrint the queue status as well as the standard out  and error streams (merged) for the given machine. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.winsorized_mean-Tuple{Any}","page":"Reference","title":"Pigeons.winsorized_mean","text":"winsorized_mean(x; )\n\nCompute the winsorized mean from an input x, which is assumed to be a vector of vectors.   denotes the percentage of observations to winsorize at the bottom and the top  so that we use 1 - 2 observations and winsorize the rest.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.winsorized_std-Tuple{Any}","page":"Reference","title":"Pigeons.winsorized_std","text":"winsorized_std(x; )\n\nCompute the winsorized standard deviation. The parameters are the same  as those for winsorized_mean().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.write_checkpoint-Tuple{Any}","page":"Reference","title":"Pigeons.write_checkpoint","text":"write_checkpoint(pt)\n\n\nIf pt.inputs.checkpoint == true, save a checkpoint under  [pt.exec_folder]/[unique folder]/round=[x]/checkpoint. \n\nBy default, pt.exec_folder is results/all/[unique folder].\n\nIn an MPI context, each MPI process will write its local replicas,  while only one of the MPI processes will write the Shared  and reduced recorders data. Moreover, only one MPI process will  write once at the first round the Inputs data. \n\nIn cases where the sampled model contains large immutable data, consider using  Immutable() to save disk space (Immutables will be written only by  one MPI process at the first round). \n\n\n\n\n\n","category":"method"},{"location":"reference/#RecipesBase.apply_recipe-Tuple{AbstractDict{Symbol, Any}, Dict{Int64, Vector{Int64}}}","page":"Reference","title":"RecipesBase.apply_recipe","text":"apply_recipe(plotattributes, index_process)\n\n\nA plot @recipe for an index process. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Statistics.mean","page":"Reference","title":"Statistics.mean","text":"mean(pt)\nmean(pt, variable_name)\n\n\n\n\n\n\n","category":"function"},{"location":"reference/#Statistics.var","page":"Reference","title":"Statistics.var","text":"var(pt)\nvar(pt, variable_name)\n\n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.@abstract-Tuple{}","page":"Reference","title":"Pigeons.@abstract","text":"my_fct() = @abstract()\n\nDefine an abstract function (i.e. which gives an error message if calling it  is attempted). \n\n\n\n\n\n","category":"macro"},{"location":"reference/#Pigeons.@informal-Tuple{Symbol, Expr}","page":"Reference","title":"Pigeons.@informal","text":"@informal name begin ... end\n\nDocument an informal interface with provided name, and functions  specified in a begin .. end block. \n\n@informal will spit back the contents of the begin .. end block so  this macro can be essentially ignored at first read. \n\nWhen building documentation, this allows us to use the  function informal_doc() to automatically document the  informal interface.\n\n\n\n\n\n","category":"macro"},{"location":"reference/#Pigeons.@weighted-Tuple{Any, Any}","page":"Reference","title":"Pigeons.@weighted","text":"@weighted(w, x)\n\nCompute w*x, but if w==0.0, do not evaluate x and just return w (i.e. zero). Useful when x is computationally costly.\n\n\n\n\n\n","category":"macro"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"CurrentModule = Pigeons","category":"page"},{"location":"distributed/#Distributed-and-parallel-implementation-of-PT","page":"Distributed PT","title":"Distributed and parallel implementation of PT","text":"","category":"section"},{"location":"distributed/#Introduction","page":"Distributed PT","title":"Introduction","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Pigeons provides an implementation of Distributed PT based on Syed et al., 2021,  Algorithm 5. This page describes our strategies for addressing the challenges of implementing this distributed,  parallelized, and randomized algorithm.","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"note: Note\nRead this page if you are interested in extending Pigeons or  understanding how it works under the hood.  Reading this page is not required to use Pigeons. Instead, refer to the  user guide. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"In Distributed PT, one or several computers run MCMC simulations in parallel and  communicate with each other to improve MCMC efficiency.  We use the terminology machine for one of these computers, or, to be more precise,  process. In the typical setting, each machine will run one process, since our implementation also supports  the use of several Julia threads.","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Pigeons is designed so that it is suitable in all these scenarios:","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"one machine running PT on one thread,\none machine running PT on several threads,\nseveral machines running PT, each using one thread, and\nseveral machines running PT, each using several threads.","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Ensuring code correctness at the intersection of randomized, parallel, and distributed algorithms is a challenge.  To address this challenge, we designed Pigeons based on the following principle:","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"note: Parallelism Invariance\nThe output of Pigeons is invariant to the number of machines and/or threads.","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"In other words, if X_m t(s) denotes the output of Pigeons when provided m machines, t threads  per machine, and random seed s, we guarantee that X_m t(s) = X_m t(s) for all m t. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Without explicitly keeping Parallelism Invariance in mind during software construction,  parallel/distributed implementations of randomized algorithms will  typically only guarantee EX_m t = EX_m t for all m m t t. While equality in distribution is technically  sufficient, the stronger pointwise equality required by Parallelism Invariance makes  debugging and software validation considerably easier.  This is because the developer can first focus on the fully serial randomized algorithm,  and then use it as an easy-to-compare gold-standard reference for parallel/distributed  implementations.  This strategy is used extensively in Pigeons to ensure correctness.  In contrast, testing equality in distribution, while possible (e.g., see  Geweke, 2004), incurs additional  false negatives due to statistical error. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Two factors tend to cause violations of Parallelism Invariance: ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Global, thread-local and task-local random number generators (the dominant approaches to parallel   random number generators in current languages).\nNon-associativity of floating point operations. As a result, when several workers    perform Distributed reduction of    floating point values, the output of this reduction will be slightly different.    When these reductions are then fed into further random operations, this implies    two randomized algorithms with the same seed but using a different number of workers    will eventually arbitrarily diverge pointwise. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"One focus in the remainder of this page is to describe how our implementation sidesteps  the two above issues while maintaining the same asymptotic runtime complexity.","category":"page"},{"location":"distributed/#Overview-of-the-algorithm","page":"Distributed PT","title":"Overview of the algorithm","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Let us start with a high-level picture of the distributed PT algorithm. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"The high-level code is the function pigeons() which is identical to the single-machine algorithm.  A first difference lay in the replicas datastructure taking on a different type. Also, as promised the  output is identical despite a vastly different swap logic: this can be checked using the checked_round  argument described in the user guide.  A second difference between the execution of pigeons() in single vs many machine context is the behaviour  of swap! which is dispatched  based on the type of  replicas. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"In the following, we go over the main building block of  our distributed PT algorithm. ","category":"page"},{"location":"distributed/#Splittable-random-streams","page":"Distributed PT","title":"Splittable random streams","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"The first building block is a splittable random stream.  To motivate splittable random streams, consider the following example violating Parallelism Invariance.","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Julia uses task-local random number generators, a notion which  is related but distinct from parallelism invariance.  We will now explain the difference between task-local random number  generators and parallelism invariance, and why the latter is more  advantageous for checking correctness of distributed randomized algorithms. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Consider the following toy example:","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"using Random\nimport Base.Threads.@threads\n\nprintln(\"Number of threads: $(Threads.nthreads())\")\n\nconst n_iters = 10000;\nresult = zeros(n_iters);\nRandom.seed!(1);\n@threads for i in 1:n_iters\n    # in a real problem, do some expensive calculation here...\n    result[i] = rand();\nend\nprintln(\"Result: $(last(result))\")","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"When using 8 threads, this outputs:","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Number of threads: 8\nResult: 0.25679999169092793","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Julia guarantees that if we rerun this code, as long as we  are using 8 threads, we will always get the same result,  irrespective of the multi-threading scheduling decisions  implied by the @threads-loop (hence, a step ahead another  concept known as thread-local random number generation, which does not guarantee replicability even for a fixed number of  threads). ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"However, when we use a different number of threads (e.g.,  the key example is one thread), the result is different:","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Number of threads: 1\nResult: 0.8785201210435906","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"In this simple example above, it is not a big deal, but for our parallel tempering use case, the  distributed version of the algorithm is significantly more complex and  harder to debug compared to the single-threaded one. Hence we take  task-local random number generation one step further, into parallelism  invariance, which will guarantee that the output is not only  reproducible with respect to repetitions for a fixed number of threads,  but also for different numbers of threads. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"In our context, a first step to achieve this is to associate one random number generator to each PT chain. To do so, we use the  SplittableRandoms.jl library which allows  us to turn one seed into an arbitrary collection pseudo-independent random number generators.  Since each MPI process holds a subset of the chains, we internally use the  function split_slice() to  get the random number generators for the slice of replicas held in a given MPI process.","category":"page"},{"location":"distributed/#Distributed-replicas","page":"Distributed PT","title":"Distributed replicas","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Calling create_entangled_replicas() will produce a fresh EntangledReplicas,  taking care of distributed random seed splitting internally.  An EntangledReplicas contains the list of replicas that are local to the machine, in addition to three data structures allowing distributed communication:  a LoadBalance which keeps track of  how to split work across machines; an Entangler, which encapsulates MPI calls;  and a PermutedDistributedArray, which   maps chain indices to replica indices. These datastructures can be obtained using load(), entangler(), and  replicas.chain_to_replica_global_indices respectively.","category":"page"},{"location":"distributed/#Distributed-swaps","page":"Distributed PT","title":"Distributed swaps","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"To perform distributed swaps, swap!() proceeds as follows:","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Use the swap_graph to determine swapping partner chains,\ntranslate partner chains into partner replicas (global indices) using  replicas.chain_to_replica_global_indices,\ncompute swap_stat() for local chains, and use   transmit() to obtain partner swap stats,\nuse swap_decision() to decide if each pair should swap, and \nupdate the replicas.chain_to_replica_global_indices datastructure. ","category":"page"},{"location":"distributed/#Distributed-reduction","page":"Distributed PT","title":"Distributed reduction","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"After each round of PT, the workers need to exchange richer messages compared to the information exchanged in the swaps.  These richer messages include swap acceptance probabilities,  statistics to adapt a variational reference, etc. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"This part of the communication is performed using reduce_recorders!() which  in turn calls all_reduce_deterministically() with the appropriate   merging operations. See reduce_recorders!() and  all_reduce_deterministically() for more information on how  our implementation preserves Parallelism Invariance, while maintaining the logarithmic runtime of binary-tree based  collective operations. (More precisely, all_reduce_deterministically() runs in time log(N)  when each machine holds a single chain.)","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"CurrentModule = Pigeons","category":"page"},{"location":"#Pigeons","page":"Guide","title":"Pigeons","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"Facing a challenging integration problem? Tired of waiting for hours or days for your high-dimensional, multimodal Bayesian posterior approximation? Summing over your combinatorial space is taking months? ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Try Pigeons: a Julia package to efficiently approximate posterior distributions, and more broadly, Lebesgue integration problems. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Pigeons' core algorithm is a distributed and parallel implementation  of the following algorithms: ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Non-Reversible Parallel Tempering (NRPT),    Syed et al., 2021.\nVariational PT, Surjanovic et al., 2022. [under construction]","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"These algorithms achieve state-of-the-art performance for approximation  of challenging probability distributions.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Pigeons can be used in a multi-threaded context, and/or  distributed over hundreds or thousands of MPI-communicating machines.","category":"page"},{"location":"#Scope","page":"Guide","title":"Scope","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"We describe here the class of problems that can be approached using Pigeons.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Let pi(x) denote a probability density called the target.  In many problems, e.g. in Bayesian statistics, the density pi is typically  known only up to a normalization constant, ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pi(x) = fracgamma(x)Z","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"where gamma can be evaluated pointwise, but Z is unknown. Pigeons takes as input the function gamma.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"terminology: log_potential\nSince we work in log-scale, we use the terminology  log_potential as a shorthand for the  unnormalized log density log gamma(x).  See informal interface log_potential.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Pigeons' outputs can be used for two tasks:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Approximating expecations of the form Ef(X), where X sim pi.    For example, the choice f(x) = x computes the mean, and    f(x) = Ix in A computes the probability of A under pi.\nApproximating the value of the normalization constant Z. For    example, in Bayesian statistics, this corresponds to the    marginal likelihood.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Pigeons shines in the following scenarios:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"When the posterior density pi is challenging due to    non-convexity and/or concentration on a    sub-manifolds due to unidentifiability.\nWhen the user needs not only Ef(X) but also Z. Many existing MCMC tools   focus on the former and struggle to do the latter in high dimensional    problems. \nWhen the posterior density pi is defined over a non-standard state-space,    e.g. a combinatorial object such as a phylogenetic tree. ","category":"page"},{"location":"#Installing-Pigeons","page":"Guide","title":"Installing Pigeons","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"If you have not done so, install Julia. So far, we have tested the code on Julia 1.8.x.\nInstall Pigeons using","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"using Pkg; Pkg.add(\"Pigeons\")","category":"page"},{"location":"#Running-PT","page":"Guide","title":"Running PT","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"Specify the target distribution and, optionally,  parameters like random seed, etc by creating an  Inputs:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"using Pigeons\n\ninputs = Inputs(target = toy_mvn_target(100))","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"See Inputs for more options. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Then, run PT (locally on one process) using the function pigeons():","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt = pigeons(inputs);\nnothing # hide","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"This runs PT on a 100-dimensional MVN toy example with 10 chains  for 2047 = 2^11 - 1 iterations, and  returns a PT struct containing the results of  this run (more later on how to access information inside  a PT struct). Each line in the output provides information on a round, where the number of iteration  per round doubles at each round and adaptation is performed  between rounds. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Since the above two julia lines are the most common operations in this package, creating inputs and running PT can be done in one line  as follows:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt = pigeons(target = toy_mvn_target(100));\nnothing # hide","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"where the args... passed to pigeons are forwarded  to Inputs.","category":"page"},{"location":"#Estimating-the-log-normalization-constant","page":"Guide","title":"Estimating the log normalization constant","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"To estimate the log normalization constant, use stepping_stone_pair(),  for example: ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"stepping_stone_pair(pt)","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"we can see that this is close to the close-form expression available for this  toy example:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Pigeons.analytic_lognormalization(toy_mvn_target(100))","category":"page"},{"location":"#Accessing-the-output-of-PT","page":"Guide","title":"Accessing the output of PT","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"The PT struct returned by pigeons  contains a field called reduced_recorders, which is just  a NamedTuple containing recorder's which can be used to collect  arbitary statistics computed along the execution of PT. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"By default, the statistics collected use constant-memory summaries  (i.e. constant in the number of iteration, leveraging the package OnlineStats.jl), however it is possible to customize which statistics to collect. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"For example, we show here how to plot the index process, a  useful diagnostic to assess the efficiency of PT algorithms  (Syed et al., 2021). We use the argument recorder_builders to  specify that we wish to collect the full index process:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"p = pigeons(\n        target = toy_mvn_target(1), \n        recorder_builders = [index_process], \n        n_rounds = 5);\nnothing # hide","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Then we can access the information via:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"p.reduced_recorders.index_process\n\nusing Plots\nplot(p.reduced_recorders.index_process);\nsavefig(\"index_process_plot.svg\"); \nnothing # hide","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"(Image: )","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Other statistics follow the same general usage,  see Parallel Tempering (PT) for  more details. ","category":"page"},{"location":"#Loading-and-resuming-a-checkpoint","page":"Guide","title":"Loading and resuming a checkpoint","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"Pigeons can write a \"checkpoint\" periodically  to ensure that not more than half of the work is lost in  the event of e.g. a server failure. This is enabled as follows:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt = pigeons(target = toy_mvn_target(100), checkpoint = true)","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"See write_checkpoint() for details of how this  is accomplished in a way compatible to both the single-machine  and MPI contexts.  Each checkpoint is located in  results/all/[unique folder]/round=[x]/checkpoint,  with the latest run in results/latest/[unique folder]/round=[x]/checkpoint. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Checkpoints are also useful when an MPI-distributed PT has been  ran, and the user wants to load the full set of  results in one interactive session. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"To load a checkpoint, create a PT struct by passing in the path  string to the checkpoint folder, for example to re-load the latest checkpoint  from the latest run:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt_from_checkpoint = PT(\"results/latest\")","category":"page"},{"location":"#Automatic-correctness-checks","page":"Guide","title":"Automatic correctness checks","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"It is notoriously difficult to implement correct parallel/distributed algorithms.  One strategy we use to address this is to guarantee that the code will output  precisely the same output no matter how many threads/machines are used.  We describe how this is done under the hood in the page Distributed PT. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"In practice, how is this useful? Let us say you developed a new target and you would like to make sure that it works correctly in a multi-threaded environment. To do so, add a flag to indicate to \"check\" one of the PT rounds as follows, and  enable checkpointing","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pigeons(target = toy_mvn_target(100), checked_round = 3, checkpoint = true)","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"The above line does the following: the PT algorithm will pause at the end of round 3, spawn  a separate process with only one thread in it, run 3 rounds of PT with the same  Inputs object in it, and verify that the checkpoints of the single-threaded run  is identical to   the one that ran in the main process. If not, an error will be raised with some  information on where the discrepancy comes from.  Try to pick the checked round to be small enough that it does not dominate the running time  (since it runs in single-threaded, single-process mode), but big enough to achieve  the same code coverage as the full algorithm. Setting it to zero (or omitting the argument),  disable this functionality.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Did the code above actually used many threads? This depends on the value of Threads.nthreads(). Julia currently does not allow you to change this value at  runtime, so for convenience we provide the following way to run the job in a  child process with a set number of Julia threads:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt_result = pigeons(target = toy_mvn_target(100), multithreaded = true, checked_round = 3, checkpoint = true, on = ChildProcess(n_threads = 4))","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Notice that we also add the flag multithreaded = true. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Notice that this time, instead of returning a PT struct, this time we obtain  a Result, which only holds the path where the checkpoints can be found.  If you would like to load a result in memory, use:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt = load(pt_result)","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"In this case, since the model is built-in, the check passed successfully as expected. But what  if you had a third-party target distribution that is not multi-threaded friendly?  I.e. it may write in global variables or  other non-thread safe construct. Then you can probably still  use your thread-naive  target over MPI processes.  For example, if the thread-unsafety comes from the use of global variables, then each  process will have its own copy of the global variables. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"We described how MPI can be used in the next two sections.","category":"page"},{"location":"#Running-MPI-locally","page":"Guide","title":"Running MPI locally","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"To run MPI locally on one machine, using 4 MPI processes and 1 thread per process use:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pigeons(\n    target = toy_mvn_target(100), \n    checked_round = 3, \n    checkpoint = true, \n    on = ChildProcess(\n            n_local_mpi_processes = 4,\n            n_threads = 1))","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Note that if n_local_mpi_processes exceeds the number of cores, performance  will steeply degrade (in contrast to threads, for which performance degrades  much more gracefully when the number of threads exceeds the number of cores). ","category":"page"},{"location":"#Running-MPI-on-a-cluster","page":"Guide","title":"Running MPI on a cluster","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"note: The magic of distributed Parallel Tempering\nIf the dimensionality of the state space is large, you may worry that  the time to transmit states over the network would dominate the running time.  Remarkably, the size of the messages transmitted in the inner loop of our  algorithm does not depend on the state space. In a nutshell, the  machines only need to transmit the value of log density ratios (a single float).  See Algorithm 5 in Syed et al., 2021 for details.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"MPI is typically available via a cluster scheduling system. At the time of  writing, only PBS PRO is supported, but more will be added. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Follow these instructions to run MPI over several machines:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"In the cluster login node, follow the installation instruction as above. \nStart Julia in the login node, and perform a one-time setup by calling setup_mpi().\nStill in the Julia REPL running in the login node, use:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"mpi_run = pigeons(\n    target = toy_mvn_target(1000000), \n    n_chains = 1000,\n    on = MPI(\n        n_mpi_processes = 1000,\n        n_threads = 1))","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"This will start a distributed PT algorithm with 1000 chains on 1000 MPI processes, each using one thread, targeting a one million  dimensional target distribution. On the UBC Sockeye cluster, the last  round of this run (i.e. the last 1024 iterations) takes 10 seconds to complete, versus more than  2 hours if ran serially, i.e. a >700x speed-up.  This is reasonably close to the theoretical 1000x speedup, i.e. we see that the communication costs are negligible. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"You can \"watch\" the progress of your job (queue status and  standard output once it is available), using:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"watch(mpi_run)","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"and cancel/kill a job using ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"kill_job(mpi_run)","category":"page"},{"location":"#Specification-of-general-models","page":"Guide","title":"Specification of general models","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"The most general way to invoke Pigeons is by specifying two ingredients: a sequence of distributions,  pi_1 pi_2 dots pi_N, and for each pi_i, a pi_i-invariant Markov transition kernel.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"See examples/general-target.jl  for an example of how to input an arbitrary Julia function as the  target distribution.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Typically, pi_1 is a distribution from which we can sample i.i.d. (e.g. the prior, or a variational  approximation), while the last distribution coincides with the distribution of interest,  pi_N = pi, the target.  We use an informal interface called target to orchestrate the creation of the ingredients  needed by parallel tempering algorithms.  The main pieces to specify are create_state_initializer(), to provide initial states,  create_explorer, to construct explorer's  which are pi_i-invariant Markov transition kernel,  and finally, create_reference_log_potential(),  to construct pi_1. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"A range of other extension points are defined, to control  the tempering, interpolating path's,  adaptation, but those all have reasonable default implementations built-in. See the Parallel Tempering (PT) page for more information.","category":"page"},{"location":"#Targeting-a-Turing.jl-model","page":"Guide","title":"Targeting a Turing.jl model","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"To demonstrate how to integrate a third-party target distribution into  Pigeons, we show in this section how to sample from target distributions defined using a Turing.jl model. This integration is currently experimental. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"We consider an unidentifiable Beta-Binomial model for instructional purposes. Typically, MCMC samplers would have difficulty sampling from  posterior distributions of unidentifiable models. However, Pigeons excels in this scenario compared to traditional samplers.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"First, we define the Turing model.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"using Turing\n\n# *Unidentifiable* unconditioned coinflip model with `N` observations.\n@model function coinflip_unidentifiable(; N::Int)\n    p1 ~ Uniform(0, 1) # prior on p1\n    p2 ~ Uniform(0, 1) # prior on p2\n    y ~ filldist(Bernoulli(p1*p2), N) # data-generating model\n    return y\nend;\ncoinflip_unidentifiable(y::AbstractVector{<:Real}) = coinflip_unidentifiable(; N=length(y)) | (; y)\n\nfunction flip_model_unidentifiable()\n    p_true = 0.5; # true probability of heads is 0.5\n    N = 100;\n    data = rand(Bernoulli(p_true), N); # generate N data points\n    return coinflip_unidentifiable(data)\nend","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Once we have defined our Turing model, it is straightforward to sample from the posterior distribution of p1 and p2 as follows:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"using Pigeons\nmodel = flip_model_unidentifiable()\npt = pigeons(target = TuringLogPotential(model));\nnothing # hide","category":"page"},{"location":"#Targeting-a-non-Julian-model","page":"Guide","title":"Targeting a non-Julian model","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"Suppose you have some code implementing vanilla MCMC, written  in an arbitrary \"foreign\" language such as C++, Python, R, Java, etc.  You would like to turn this vanilla MCMC code into a Parallel Tempering  algorithm able to harness large numbers of cores, including  distributing this algorithm over MPI.  However, you do not wish to learn anything about  MPI/multi-threading/Parallel Tempering. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Surprisingly, it is very simple to bridge such code with Pigeons.  The only requirement on the \"foreign\" language is that it supports  reading the standard in and writing to the standard out, hence  virtually any languages can be interfaced in this fashion.  Based on this minimalist \"standard stream bridge\" with worker  processes running foreign code (one such process per replica; not  necessarily running on the same machine), Pigeons will  coordinate the execution of an adaptive non-reversible parallel  tempering algorithm. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"To see how to accomplish this, see StreamTarget. A concrete example is also shown in BlangTarget, which  uses this infrastructure to run arbitrary  code in the Blang modelling language over MPI.","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"CurrentModule = Pigeons","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"We provide in this page an overview of Non-Reversible Parallel Tempering (PT),  Syed et al., 2021,  linking it with some key parts of the code base. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"note: Note\nRead this page if you are interested in extending Pigeons or  understanding how it works under the hood.  Reading this page is not required to use Pigeons, for that instead refer to the  user guide. ","category":"page"},{"location":"pt/#PT-augmented-state-space,-replicas","page":"Parallel Tempering (PT)","title":"PT augmented state space, replicas","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Let X_n denote a Markov chain on state space mathscrX with stationary distribution pi.  PT is a Markov chain defined on the augmented state space mathscrX^N, hence  a state has the form boldsymbolX = (X^(1) X^(2) dots X^(N)).  Each component of boldsymbolX is stored in a struct called a Replica. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"The storage of the vector of replicas boldsymbolX, is done via the informal  interface replicas. In the context of PT running on one computer,  replicas is implemented with a Vector{Replica}. In the context  of running PT distributed across several communicating machines, replicas  is implemented via EntangledReplicas, which stores the parts of  boldsymbolX that are local to that machine as well as data structures  required to communicate with the other machines. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Internally, PT operates on a discrete set of distributions,  pi_1 pi_2 dots pi_N, where N can be obtained using n_chains().  We use the terminology chain to refer to an index i of pi_i. Typically, pi_N coincides with the distribution of interest pi (called the \"target\"), while  pi_1 is a tractable approximation that will help PT efficiently explore the  state space (called the \"reference\").  More broadly, we assume a subset of the chains (determined by is_target()) coincide with the target, and that a subset of the chains (determined by  is_reference()) support  efficient exploration such as i.i.d. sampling or a rapid mixing kernel. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"PT is designed so that its stationary distribution is boldsymbolpi = pi_1 times pi_2 times dots pi_N.  As a result, subsetting each sample to its component corresponding to pi_N = pi,  and applying an integrable function f to each, will lead under weak assumptions  to Monte Carlo averages that converge to the expectation of interest Ef(X) for  X sim pi.","category":"page"},{"location":"pt/#Outline-of-local-exploration-and-communication","page":"Parallel Tempering (PT)","title":"Outline of local exploration and communication","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"PT alternates between two phases, each boldsymbolpi-invariant: the local  exploration phase and the communication phase. Informally, the first phase attempts to achieve  mixing for the univariate statistics pi_i(X^(i)), while the second phase attempts to  translate well-mixing of these univariate statistics into global mixing of X^(i) by  leveraging the reference distribution(s).","category":"page"},{"location":"pt/#Local-exploration","page":"Parallel Tempering (PT)","title":"Local exploration","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"In the local exploration phase, each Replica's state is modified using a pi_i-invariant kernel,  where i is given by Replica.chain. Often, Replica.chain corresponds to  an annealing parameter beta_i but this need not be the case (see  e.g. Baragatti et al., 2011). The kernel can either modify Replica.state in-place, or modify the  Replica's state field. The key interface controlling local exploration, explorer, is  described in more detail below. ","category":"page"},{"location":"pt/#Communication","page":"Parallel Tempering (PT)","title":"Communication","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"In the communication phase, PT proposes swaps between pairs of replicas.  These swaps allow each replica's state to periodically visit reference chains. During these reference visits, the state can move around the space quickly.  In principle, there are two equivalent ways to do a swap: the Replicas could exchange  their state fields; or alternatively, they could exchange their chain fields. Since we provide distributed implementations, we use the latter as it ensures that  the amount of data that needs to be exchanged between two machines during a swap  can be made very small (two floats).  It is remarkable that this cost does not vary with the dimensionality of the state space,  in constrast to the naive implementation which would transmit states over the network. See Distributed PT for more information on our distributed implementation.","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Both in distributed and single process mode,  swaps are performed using the function swap!(). ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"The key interface controlling communication, tempering, is  described in more detail below. ","category":"page"},{"location":"pt/#A-tour-of-the-PT-meta-algorithm","page":"Parallel Tempering (PT)","title":"A tour of the PT meta-algorithm","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"A generalized version of Algorithm 1 (\"one round of PT\") in Syed et al., 2021  is implemented in Pigeons in run_one_round!(),  while the complete algorithm (\"several adaptive rounds\"),  Algorithm 4 of Syed et al., 2021,  has a generalized implementation in pigeons(). ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"In the following we discuss different facets of these (meta-)algorithms.","category":"page"},{"location":"pt/#Storage-in-PT-algorithms","page":"Parallel Tempering (PT)","title":"Storage in PT algorithms","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"The information stored in the execution of pigeons()  is grouped in the struct PT.  The key fields are one pointing to a replicas and  one to a Shared.  Briefly, replicas will store information distinct in each  MPI process, and read-write during each  round, while Shared is identical in all MPI processes, read only during a round, and updated only between  rounds. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"To orchestrate the creation of PT structs, Inputs is used. Inputs fully determines the execution of a  PT algorithm (target distribution, random seed, etc). ","category":"page"},{"location":"pt/#Collecting-statistics:-[recorder](@ref)-and-[recorders](@ref)","page":"Parallel Tempering (PT)","title":"Collecting statistics: recorder and recorders","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Two steps are needed to collect statistics from the execution of a PT algorithm: ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Specifying which statistics to collect using one or several recorder_builder    (e.g. by    default, only some statistics that can be computed in constant memory  are included,    those that have growing memory consumption, e.g. tracking the full    index process as done here, need to be explicitly specified in advance).\nThen at the end of run_one_round!(), reduce_recorders!()   is called to compile the statistics collected  by the different replicas.","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"An object responsible for accumulating all different types of statistics for  one replica is called a  recorders. An object accumulating one  type of statistic for one replica is a recorder.  Each replica has a single recorders to ensure thread safety (e.g., see  the use of a parallel local exploration phase using @thread in explore!()) and to enable distributed  computing. ","category":"page"},{"location":"pt/#Using-a-built-in-[recorder](@ref)","page":"Parallel Tempering (PT)","title":"Using a built-in recorder","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"To see the list of built-in implementations of recorder, see the section \"Examples of functions..\" at recorder. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"To specify you want to use one recorder, specify it in the Vector  argument recorder_builders in Inputs. For example, to signal you want  to save the full index process, use:","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"using Pigeons\n\npt = pigeons(target = toy_mvn_target(1), recorder_builders = [index_process]);\nnothing # hide","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"You can then access the index process via ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"pt.reduced_recorders.index_process","category":"page"},{"location":"pt/#Creating-your-own-[recorder](@ref)","page":"Parallel Tempering (PT)","title":"Creating your own recorder","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"The following pieces are needed","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Pick or create a struct MyStruct that will hold the information. \nImplement all the methods in the section \"Contract\" of recorder making sure to type the recorder argument as recorder::MyStruct. Some examples are in the same source file as recorder and/or in the same folder as recorder.jl.   \nCreate a recorder_builder which is simply a function such ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"that when called with zero argument, creates your desired type, i.e.  MyStruct. The name of this function will define the name of your recorder.","category":"page"},{"location":"pt/#Local-[explorer](@ref)","page":"Parallel Tempering (PT)","title":"Local explorer","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Typical target distributions are expected to take care of building  their own explorers, so most users are not expected to have to  write their own. But for non-standard target it is useful to be  able to do so. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Building a new explorer is done as follows: first, suppose you are planning to use a non-standard target of type MyTargetType","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Pick or create a struct MyExplorerStruct that may contain adaptation   information such as step sizes for HMC or proposal bandwidth.   Note that explorers will need to explore not only the target   distribution pi but also the intermediate ones pi_i.\nImplement all the methods in the section \"Contract\" of explorer making sure to type the explorer argument as explorer::MyExplorerStruct. Some examples are in the same folder as the source file of explorer.  \nDefine a method create_explorer(target::MyTargetType, inputs) which   should return a fresh MyExplorerStruct instance. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"One explorer struct will be shared by all threads, so it should be  read-only during execution of run_one_round!().  It can be adapted between rounds. ","category":"page"},{"location":"pt/#Tempering","page":"Parallel Tempering (PT)","title":"Tempering","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Customizing communicate!() follows the same general steps as custom explorers, i.e.:","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Pick or create a struct MyTemperingStruct that may contain adaptation   information such as schedule optimization. \nImplement all the methods in the section \"Contract\" of tempering making sure to type the tempering argument as tempering::MyTemperingStruct. For example, see NonReversiblePT. \nInitial construction of the tempering is done via  create_tempering().","category":"page"}]
}
