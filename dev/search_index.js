var documenterSearchIndex = {"docs":
[{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Descriptions of informal interfaces (see Pigeons.@informal to see how this page  was generated).","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#explorer","page":"Interfaces","title":"explorer","text":"","category":"section"},{"location":"interfaces/#Description","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.explorer","category":"page"},{"location":"interfaces/#Pigeons.explorer","page":"Interfaces","title":"Pigeons.explorer","text":"Orchestrate the explore!() phase  of Parallel Tempering. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.step!()\nPigeons.adapt_explorer()\nPigeons.explorer_recorder_builders()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_explorer()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#log_potential","page":"Interfaces","title":"log_potential","text":"","category":"section"},{"location":"interfaces/#Description-2","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.log_potential","category":"page"},{"location":"interfaces/#Pigeons.log_potential","page":"Interfaces","title":"Pigeons.log_potential","text":"A log_potential encodes a probability distribution, where only the  un-normalized probability density function is known. \n\nTo make MyType conform to this informal interface, implement \n\n(log_potential::MyType)(x)\n\nwhich should return the log of the un-normalized density.\n\nFor example, we provide this behaviour for any distribution  in Distributions.jl. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#log_potentials","page":"Interfaces","title":"log_potentials","text":"","category":"section"},{"location":"interfaces/#Description-3","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.log_potentials","category":"page"},{"location":"interfaces/#Pigeons.log_potentials","page":"Interfaces","title":"Pigeons.log_potentials","text":"An encoding of a discrete set of probability distributions, where only the un-normalized  probability density functions are known.  Each distribution is allowed to have a different normalization constant. \n\nFor example, we provide this behaviour for any Vector containing log_potential's. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-2","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.log_unnormalized_ratio()\nPigeons.n_chains()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#pair_swapper","page":"Interfaces","title":"pair_swapper","text":"","category":"section"},{"location":"interfaces/#Description-4","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.pair_swapper","category":"page"},{"location":"interfaces/#Pigeons.pair_swapper","page":"Interfaces","title":"Pigeons.pair_swapper","text":"Informs swap!() of how to perform a swap between a given pair of chains.\n\nThis is done in two steps:\n\nUse swap_stat() to extract sufficient statistics needed to make a swap decision. \nGiven these statistics for the two chains, swap_decision() then perform the swap.\n\nThe rationale for breaking this down into two steps is that in a distributed swap context, swap!() will take care of transmitting the sufficient statistics over the network if necessary.\n\nThe function record_swap_stats!() is used to record information about swapping,  in particular mean swap acceptance probabilities.\n\nA default implementation of all of pair_swapper's methods is provided,  where the pair_swapper is assumed to follow the log_potentials interface.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-3","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.swap_stat()\nPigeons.record_swap_stats!()\nPigeons.swap_decision()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-2","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.TestSwapper()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#path","page":"Interfaces","title":"path","text":"","category":"section"},{"location":"interfaces/#Description-5","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.path","category":"page"},{"location":"interfaces/#Pigeons.path","page":"Interfaces","title":"Pigeons.path","text":"A continuum of log_potential's interpolating between two end-points. More precisely, a mapping from [0, 1] to the space of probability distributions.\n\nThe main use of this interface is to pass it to discretize().\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-4","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.interpolate()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-3","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.InterpolatingPath()\nPigeons.ScaledPrecisionNormalPath()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#recorder","page":"Interfaces","title":"recorder","text":"","category":"section"},{"location":"interfaces/#Description-6","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.recorder","category":"page"},{"location":"interfaces/#Pigeons.recorder","page":"Interfaces","title":"Pigeons.recorder","text":"Accumulate a specific type of statistic, for example  by keeping constant size sufficient statistics  (via OnlineStat, which conforms this interface),  storing samples to a file, etc. \n\nIn addition to the contract below, a recorder should support \n\nBase.merge()\nBase.empty!()\n\nSee also recorders.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-5","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.record!()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-4","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.swap_acceptance_pr()\nPigeons.index_process()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#recorder_builder","page":"Interfaces","title":"recorder_builder","text":"","category":"section"},{"location":"interfaces/#Description-7","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.recorder_builder","category":"page"},{"location":"interfaces/#Pigeons.recorder_builder","page":"Interfaces","title":"Pigeons.recorder_builder","text":"A function such that calling it returns a fresh  recorder.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#recorders","page":"Interfaces","title":"recorders","text":"","category":"section"},{"location":"interfaces/#Description-8","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.recorders","category":"page"},{"location":"interfaces/#Pigeons.recorders","page":"Interfaces","title":"Pigeons.recorders","text":"A NamedTuple containing several recorder's.  Each recorder is responsible for a type of statistic to be  accumulated (e.g. one for swap accept prs, one for round trip  info; some are in-memory, some are on file). \n\nDuring PT execution, each recorders object keep track of only the  statistics for one replica (for thread safety and/or  distribution purpose). After a PT round, reduce_recorders!() is used to do  a reduction before  accessing statistic values. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-6","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.record_if_requested!()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-5","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_recorders()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#replicas","page":"Interfaces","title":"replicas","text":"","category":"section"},{"location":"interfaces/#Description-9","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.replicas","category":"page"},{"location":"interfaces/#Pigeons.replicas","page":"Interfaces","title":"Pigeons.replicas","text":"Stores the process' replicas.  Since we provide MPI implementations, do not assume that this will contain all the replicas, as  others can be located in other processes/machines\n\nImplementations provided\n\nEntangledReplicas: an MPI-based implementation\nVector{Replica}: single-process case (above can handle that case, but the array based implementation is non-allocating)\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-7","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.swap!()\nPigeons.locals()\nPigeons.load()\nPigeons.communicator()\nPigeons.entangler()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-6","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_entangled_replicas()\nPigeons.create_replicas()\nPigeons.create_vector_replicas()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#state_initializer","page":"Interfaces","title":"state_initializer","text":"","category":"section"},{"location":"interfaces/#Description-10","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.state_initializer","category":"page"},{"location":"interfaces/#Pigeons.state_initializer","page":"Interfaces","title":"Pigeons.state_initializer","text":"Determine how to initialize the states in the replicas.  Implementations include Ref(my_state), to signal all replicas will  be initalized to my_state, or a Vector(...) for chain-specific  initializations. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-8","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.initialization()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#swap_graph","page":"Interfaces","title":"swap_graph","text":"","category":"section"},{"location":"interfaces/#Description-11","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.swap_graph","category":"page"},{"location":"interfaces/#Pigeons.swap_graph","page":"Interfaces","title":"Pigeons.swap_graph","text":"Informs swap!() about which chain will interact with which.\n\nThese are instantiated by swap_graphs. \n\nCanonical example is the standard Odd and Even swap. Extension point for e.g. \n\nparallel parallel tempering,\nvariational methods with more than 2 legs,\nPT algorithms dealing with more than one target simultaneously for the purpose of model selection. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-9","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.partner_chain()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#swap_graphs","page":"Interfaces","title":"swap_graphs","text":"","category":"section"},{"location":"interfaces/#Description-12","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.swap_graphs","category":"page"},{"location":"interfaces/#Pigeons.swap_graphs","page":"Interfaces","title":"Pigeons.swap_graphs","text":"Creates one swap_graph for each communication  iteration.\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-10","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_swap_graph()\nPigeons.reference_chains()\nPigeons.target_chains()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-7","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.deo()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#target","page":"Interfaces","title":"target","text":"","category":"section"},{"location":"interfaces/#Description-13","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.target","category":"page"},{"location":"interfaces/#Pigeons.target","page":"Interfaces","title":"Pigeons.target","text":"The probability distribution of interest. \n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-11","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_state_initializer()\nPigeons.create_explorer()\nPigeons.create_reference_log_potential()\nPigeons.sample_iid!()\nPigeons.create_path()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-8","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.toy_mvn_target()\nPigeons.TuringLogPotential()","category":"page"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"","category":"page"},{"location":"interfaces/#tempering","page":"Interfaces","title":"tempering","text":"","category":"section"},{"location":"interfaces/#Description-14","page":"Interfaces","title":"Description","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.tempering","category":"page"},{"location":"interfaces/#Pigeons.tempering","page":"Interfaces","title":"Pigeons.tempering","text":"Orchestrate the communicate!() phase  of Parallel Tempering. \n\nIn addition to the methods in the contract below,  we also assume the presence of the following fields:\n\nlog_potentials\nswap_graphs\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/#Contract-12","page":"Interfaces","title":"Contract","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.adapt_tempering()\nPigeons.tempering_recorder_builders()\nPigeons.create_pair_swapper()","category":"page"},{"location":"interfaces/#Examples-of-functions-providing-instances-of-this-interface-9","page":"Interfaces","title":"Examples of functions providing instances of this interface","text":"","category":"section"},{"location":"interfaces/","page":"Interfaces","title":"Interfaces","text":"Pigeons.create_tempering()","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"CurrentModule = Pigeons","category":"page"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/#Types-and-functions","page":"Reference","title":"Types and functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [Pigeons]\nFilter = t -> typeof(t) !== Pigeons.InformalInterfaceSpec","category":"page"},{"location":"reference/#Pigeons.ChildProcess","page":"Reference","title":"Pigeons.ChildProcess","text":"Flag to run to a new julia  process. Useful e.g. to dynamically control  the number of threads to use.   Fields: \n\nn_threads: The number of threads to provide in the child julia process, the same as the current process by default.\n\nextra_julia_modules: Extra Julia Modules needed by the child process.\n\nn_local_mpi_processes: If greater than one, run the code locally over MPI using that many MPI processes. In most cases, this is useful only for debugging purpose, as multi-threading should typically perform better. This could also potentially be useful if using a third-party target distribution which somehow does not support multi-threading.\n\nwait: If wait is false, the process runs asynchronously. When wait is false, the process' I/O streams are directed to devnull.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.EntangledReplicas","page":"Reference","title":"Pigeons.EntangledReplicas","text":"An implementation of replicas for distributed PT.  Contains:\n\nlocals: The subset of replicas hosted in this process\n\nchain_to_replica_global_indices: A specialized distributed array that maps chain indices to replica indices (global indices). This corresponds to the mapping boldsymbolj in line 2 of Algorithm 5 in Syed et al, 2021.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Entangler","page":"Reference","title":"Pigeons.Entangler","text":"Assume all the MPI processes linked by this communicator  will all call the key operations listed below the same number of times  in their lifetime, at logically related occasions (e.g. a set  number of times per iteration for algorithms running the  same number of iterations). We call these 'occasions' a micro-iteration.\n\nThis datastructure keeps track internally of appropriate unique  tags to coordinate the communication between MPI processes  without having to do any explicit synchronization. \n\nThis struct contains:\n\ncommunicator: An MPI Comm object (or nothing if a single process is involved).\n\nload: How a set of tasks or \"global indices\" are distributed across processes.\n\ncurrent_received_bits: An internal datastructure used during MPI calls.\n\nn_transmits: The current micro-iteration.\n\nThe key operations supported:\n\ntransmit() and transmit!(): encapsulates    pairwise communications in which each MPI process is holding     a Vector, the elements of which are to be permuted across the processes.\nall_reduce_deterministically and reduce_deterministically,    to perform MPI collective reduction while maintaining the    Parallelism Invariance property.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.FromCheckpoint","page":"Reference","title":"Pigeons.FromCheckpoint","text":"Flag create_replicas (and related functions) that replicas  should be loaded from a checkpoint. Fields:\n\ncheckpoint_folder\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Immutable-Tuple{Any}","page":"Reference","title":"Pigeons.Immutable","text":"Immutable(data)\n\n\nConsider a situation where a distributed system serializes its state,   and part of the state contains large immutable data. When the distributed processes each independently call  Serialization.serialize(), naively the processes would each write identical  copies of the large immutable data, which is space-inefficient. \n\nImmutable resolves this space-inefficiency. For most users,  all they need to know is to enclose large data inside the  struct Immutable. \n\nDetails of how serialization/deserialization is performed:\n\nEnclose large immutable data inside a Immutable.   Assume the type of data has well defined hash and ==.  Internally, we maintain an internal, global Dict indexed   by hash(data) storing the data. This global Dict is   called immutables.\nUse flush_immutable() to clear the global immutable state\nUse Serialization.serialize as usual. Internally, we   dispatch serialization of Immutable is modified to skip   the field containing the data.\nMake one of the processes call serialize_immutables().   This serializes the immutables Dict.\nThen for de-serialization, each process should call   deserialize_immutables(). This restores   immutable.\nFinally, call Serialization.deserialize() as usual.   When an Immutable instances is being deserialize, we   dispatch deserialization so that the data is retreived   from immutable.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.Indexer","page":"Reference","title":"Pigeons.Indexer","text":"A bijection between integers and some type T.  T is assumed to have consistent hash and ==. The two sides of the bijection can be obtained with the fields:\n\ni2t: A Vector mapping integers to objects t of type T.\n\nt2i: A Dict mapping objects t of type T to integers.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Indexer-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T","page":"Reference","title":"Pigeons.Indexer","text":"Indexer(i2t)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.Inputs","page":"Reference","title":"Pigeons.Inputs","text":"A Base.@kwdef struct  used to create Parallel Tempering algorithms. \n\nFields (see source file for default values):\n\ntarget:  The target distribution.\nseed:  The master random seed.\nn_rounds:  The number of rounds to run.\nn_chains:  The number of chains to use.\ncheckpoint:  Whether a checkpoint should be written to disk at the end of each round.\n\nrecorder_builders: An Vector with elements of type recorder_builder.\n\nchecked_round: The round index where run_checks() will be performed. Set to 0 to skip these checks.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.InterpolatedLogPotential","page":"Reference","title":"Pigeons.InterpolatedLogPotential","text":"A log_potential obtained by evaluation of a path at a point beta. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.InterpolatingPath-Tuple{Any, Any}","page":"Reference","title":"Pigeons.InterpolatingPath","text":"InterpolatingPath(ref, target)\n\n\nGiven a reference log_potential and a target log_potential,  return a path interpolating between them. \n\nBy default, the interpolator is a LinearInterpolator, i.e.  standard annealing.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.Iterators","page":"Reference","title":"Pigeons.Iterators","text":"Iterators used in Parallel Tempering. Stored in a struct so that  recorder's can access it when outputting  sample statistics.\n\nFields:\n\nround: Index of the Parallel Tempering adaptation round, as defined in Algorithm 4 of Syed et al., 2021. Set to zero when when pigeons() not yet started.\n\nscan: Number of (exploration, communication) pairs performed so far, corresponds to n in Algorithm 1 of Syed et al., 2021. Round i typically performs 2^i scans. Set to zero when runoneround!() is not yet started.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.LoadBalance","page":"Reference","title":"Pigeons.LoadBalance","text":"Split a list of indices across processes.  These indices are denoted 1 2  N. They are usually some kind of task,  for example in the context of parallel tempering,  two kinds of tasks arise:\n\nin replicas.state, task i consists in keeping track of the state of    replica i.\nin replicas.chain_to_replica_global_indices, task i consists in    storing which replica index corresponds to chain i.\n\nOne such task index is called a global_index. \n\nLoadBalance splits the global indices among n_processes. LoadBalance  is constructed so that the difference in the number of global indices  a process is responsible of (its \"load\")  is at most one.\n\nA LoadBalance contains:\n\nmy_process_index: A unique index for this process. We use 1-indexed, i.e. hide MPI's 0-indexed ranks.\n\nn_processes: Total number of processes involved.\n\nn_global_indices: The total number of global indices shared between all the processes.\n\nThe set {1, 2, .., load()} is called a set of local indices.  A local index indexes a slice in {1, 2, ..., n_global_indices}.  Collectively over the n_processes, these slices form a partition of  the global indices.\n\nKey functions to utilize a LoadBalance struct:\n\nmy_global_indices()\nfind_process()\nfind_local_index()\nmy_load()\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.MPI","page":"Reference","title":"Pigeons.MPI","text":"Flag to run on MPI. Before using, you have to call once setup_mpi.\n\nFields: \n\nn_threads: The number of threads per MPI process, 1 by default.\n\nwalltime: The walltime limit, 00:30:00 by default (i.e., 30 minutes).\n\nn_mpi_processes: The number of MPI processes, 2 by default.\n\nmemory: The memory allocated to each MPI process, 8gb by default.\n\nextra_julia_modules: Extra Julia Modules needed by the child process.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.MPISettings","page":"Reference","title":"Pigeons.MPISettings","text":"Global settings needed for MPI job submission:\n\nallocation_code: E.g., for -A in PBS submission scripts.\n\nenvironment_modules: Run module avail in the terminal to see what is available on your HPC.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.NonReversiblePT","page":"Reference","title":"Pigeons.NonReversiblePT","text":"Variables needed for the non-reversible Parallel Tempering described in  Syed et al., 2021:\n\npath:  The path.\nschedule:  The Schedule.\nlog_potentials:  The log_potentials.\nswap_graphs:  The swap_graphs.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.NonReversiblePT-Tuple{Inputs}","page":"Reference","title":"Pigeons.NonReversiblePT","text":"NonReversiblePT(inputs)\n\n\nThe adaptive non-reversible Parallel Tempering described in  Syed et al., 2021. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.PT","page":"Reference","title":"Pigeons.PT","text":"Storage involved in PT algorithms:\n\ninputs: The user-provided Inputs that determine the execution of a PT algorithm.\n\nreplicas: The replicas held by this machine.\n\nshared: Information shared across all machines, updated between rounds.\n\nexec_folder: Either a path to a folder shared by all processes, which is used to save information to disk (checkpoints, samples etc); or nothing if a completely in-memory algorithm is used.\n\nreduced_recorders: recorders from the last round, or empty recorders.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.PT-Tuple{AbstractString}","page":"Reference","title":"Pigeons.PT","text":"PT(source_exec_folder; round, fresh_exec_folder)\n\n\nCreate a PT struct from a saved  checkpoint. The path [checkpoint_folder]  should point to a folder with the name  checkpoint found under  results/all/[exec_folder]/round=x.\n\nThe checkpoint carries all the information stored in  a PT struct. It is possible for an MPI-based  execution to load a checkpoint written by a single-process  execution and vice versa.\n\nA new unique folder will be created with symlinks to  the source one, so that e.g. running more rounds of  PT will results in a new space-efficient checkpoint  containing all the information for the new run.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.PT-Tuple{Inputs}","page":"Reference","title":"Pigeons.PT","text":"PT(inputs; exec_folder)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.PermutedDistributedArray","page":"Reference","title":"Pigeons.PermutedDistributedArray","text":"A distributed array making special assumptions on how  it will be accessed and written to.  The indices of this distributed array correspond to the  notion of \"global indices\" defined in LoadBalance.  Several MPI processes cooperate, each processing storing  data for a slice of this distributed array. \n\nWe make the following assumptions:\n\nEach MPI process will set/get    entries the same number of times in their lifetime, at    logically related episodes (e.g. a set    number of times per iteration for algorithms running the    same number of iterations).    These episodes are called micro-iterations as in Entangler,    which this datastructure is built on.\nMoreover, at each time all processes perform a get or a set,    we assume that each global index is manipulated by exactly one    process (i.e. an implicit permutation of the global indices).\n\nWe use these assumptions to achieve read/write costs that are  near-constant in the number of machines participating. \n\nThis struct contains:\n\nlocal_data: The slice of the distributed array maintained by this MPI process.\n\nentangler: An Entangler used to coordinate communication.\n\nThe operations supported are:\n\npermuted_get()\npermuted_set!()\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Replica","page":"Reference","title":"Pigeons.Replica","text":"One of the N components that forms the state maintained by a PT algorithm. A Replica contains:\n\nstate:  Configuration in the state space.\nchain:  The index of the distribution currently associated with this replica, modified during swaps.\n\nrng:  Random operations involving this state should use only this random number generator.\n\nrecorders: Records statistics. Each replica carries its own for thread safety/distribution; then they are reduced at end of each round.\n\nreplica_index: A global id associated with this replica.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Reproducibility","page":"Reference","title":"Pigeons.Reproducibility","text":"Used to check reproducibility of jobs.   Less emphasis on speed, more on getting diagnostic when  reproducibility is violated.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Result","page":"Reference","title":"Pigeons.Result","text":"A link to an execution folder able to  deserialize type T via a string constructor.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ScaledPrecisionNormalPath","page":"Reference","title":"Pigeons.ScaledPrecisionNormalPath","text":"A path of zero-mean normals for testing; contains:\n\nprecision0: Precision parameter of the reference.\nprecision1: Precision parameter of the target.\ndim: Dimensionality.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ScaledPrecisionNormalPath-Tuple{Int64}","page":"Reference","title":"Pigeons.ScaledPrecisionNormalPath","text":"ScaledPrecisionNormalPath(dim)\n\n\nToy Multivariate Normal (MVN) path of distributions for testing:  see section I.4.1 in Syed et al 2021. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.Schedule","page":"Reference","title":"Pigeons.Schedule","text":"A partition of [0, 1] encoded by monotonically increasing grid points  starting at zero and ending at one.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Shared","page":"Reference","title":"Pigeons.Shared","text":"Information shared by all processes involved in  a round of distributed parallel tempering.  This is updated between rounds but only read during  a round. \n\nFields:\n\niterators: See Iterators.\n\ntempering: See tempering.\n\nexplorer: See explorer.\n\nOnly one instance maintained per process. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Shared-Tuple{Any}","page":"Reference","title":"Pigeons.Shared","text":"Shared(inputs)\n\n\nCreate a Shared struct based on an Inputs. \n\nUses create_tempering() and create_explorer().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.SliceSampler","page":"Reference","title":"Pigeons.SliceSampler","text":"Slice sampler based on Neal, 2003.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.Submission","page":"Reference","title":"Pigeons.Submission","text":"Specifies where to submit a task.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.SwapStat","page":"Reference","title":"Pigeons.SwapStat","text":"Default statistics exchanged by a pair of chains in the process of proposing a swap:\n\nlog_ratio\nuniform\n\nSee swap_stat()\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.TestSwapper","page":"Reference","title":"Pigeons.TestSwapper","text":"For testing/benchmarking purposes, a simple  pair_swapper where all swaps have equal  acceptance probability. \n\nCould also be used to warm-start swap connections  during exploration phase by setting that  constant probability to zero.  \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ThisProcess","page":"Reference","title":"Pigeons.ThisProcess","text":"Flag to ask to run a function within the  current process. \n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.ToyExplorer","page":"Reference","title":"Pigeons.ToyExplorer","text":"Toy explorer for toy paths where each log_potential supports  i.i.d. sampling via rand(rng, log_potential).\n\n\n\n\n\n","category":"type"},{"location":"reference/#Pigeons.TuringLogPotential-Tuple{DynamicPPL.Model}","page":"Reference","title":"Pigeons.TuringLogPotential","text":"TuringLogPotential(model)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.NRPT-Tuple{Any, Any, Array{Vector{T}, 1} where T<:Real, Int64, Int64}","page":"Reference","title":"Pigeons.NRPT","text":"NRPT(V_0, V_1, initial_state, ntotal, N)\n\nNon-reversible parallel tempering (NRPT).\n\nArguments\n\npotential: Function with three arguments (x, η, params) that returns a 'double'.  'x' is the point at which the log-density V0(x; params=params) * η[1] + V1(x) * η[2] is evaluated,  where V0 is the negative log density of the reference and V1 is the negative  log density of the target.\ninitial_state: Matrix of initial states for all N+1 chains. Dimensions: (N+1) x (dim_x).\nntotal: Total number of scans/iterations.\nN: The total number of chains is N+1.\noptimreference: Whether the reference distribution is to be optimized.\nmaxround: Maximum number of rounds for tuning.\nfulltrajectory: Controls whether to keep track of all 'states', 'indices', 'energies', and 'lifts'.\nϕ: (Partially removed. Useful for constructing non-linear paths.)\nresolution: Resolution of the output for the estimates of the local communication barrier. \nprior_sampler: User may supply an efficient sampler that can obtain   samples from the prior / original reference distribution.\noptimreference_start: On which tuning round to start optimizing the reference distribution.\nfull_covariance: Controls whether to use a mean-field approximation for the modified   reference (false) or a full covariance matrix (true)\nwinsorize: Whether or not to use a winsorized/trimmed mean when estimating \n\nthe parameters of the variational reference\n\ntwo_references: Whether to run two PT chains in parallel with two different references:   prior and variational reference. Note that with this setting there are 2*(N+1) chains in total.\nmodref_means_start: Starting values for modref_means\nmodref_stds_start: Starting values for modref_stds\nn_explore: Number of exploration steps to take before considering a communication swap\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.acceptanceprobability-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.acceptanceprobability","text":"acceptanceprobability(newenergy, newenergy1, newenergy2)\n\nCompute acceptance probabilities for communication moves.  newenergy inputs are lists of numbers. \n\nArguments\n\nnewenergy: -log([πβ0(x^0), πβ1(x^1), ..., πβN(x^N)]) : length N+1\nnewenergy1: -log([πβ0(x^1), πβ1(x^2), ..., πβ{N-1}(x^N)]) : length N\nnewenergy2: -log([πβ1(x^0), πβ2(x^1), ..., πβN(x^{N-1})]) : length N\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.adapt-Tuple{Any, Any}","page":"Reference","title":"Pigeons.adapt","text":"adapt(pt, reduced_recorders)\n\n\nCall adapt_tempering() followed by  adapt_explorer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.adapt_explorer-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.adapt_explorer","text":"adapt_explorer(explorer, reduced_recorders, shared)\n\n\nCalled between successive rounds (run_one_round!). \n\nGiven an explorer, reduced recorders  and Shared return an updated explorer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.adapt_tempering-Tuple{Any, Any}","page":"Reference","title":"Pigeons.adapt_tempering","text":"adapt_tempering(tempering, reduced_recorders)\n\n\nCalled between successive rounds (run_one_round!). \n\nGiven a tempering and reduced recorders  return an updated tempering.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.adapted_schedule-Tuple{Int64, Any}","page":"Reference","title":"Pigeons.adapted_schedule","text":"adapted_schedule(n_chains, cumulativebarrier)\n\n\nCreate a Schedule with n_chains grid points computed using Algorithm 2 in  Syed et al, 2021. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.all_reduce_deterministically-Union{Tuple{T}, Tuple{Any, AbstractVector{T}, Pigeons.Entangler}} where T","page":"Reference","title":"Pigeons.all_reduce_deterministically","text":"all_reduce_deterministically(operation, source_data, e)\n\n\nSame as reduce_deterministically() except that the result at the root of the  tree is then broadcast to all machines so that the output of all_reduce_deterministically()  is the root of the reduction tree for all MPI processes involved. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.analytic_cumulativebarrier-Tuple{Pigeons.ScaledPrecisionNormalPath}","page":"Reference","title":"Pigeons.analytic_cumulativebarrier","text":"analytic_cumulativebarrier(path)\n\n\nKnown cumulative barrier used for testing,  from Predescu et al., 2003.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.check_against_serial-Tuple{Any}","page":"Reference","title":"Pigeons.check_against_serial","text":"Run a separate, fully serial version of the PT algorithm,  and compare the checkpoint files to ensure the two  produce exactly the same output.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.checksum","page":"Reference","title":"Pigeons.checksum","text":"checksum(filename)\nchecksum(filename, blocksize)\n\n\nGiven a filename path, compute a crc32c() checksum  in constant memory. \n\n\n\n\n\n","category":"function"},{"location":"reference/#Pigeons.communicate!-Tuple{Any}","page":"Reference","title":"Pigeons.communicate!","text":"communicate!(pt)\n\n\nUse create_pair_swapper() and  create_swap_graph to construct the  inputs needed for swap!.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.communicationbarrier-Tuple{AbstractVector, AbstractVector}","page":"Reference","title":"Pigeons.communicationbarrier","text":"communicationbarrier(rejection, schedule)\n\n\nCompute the local communication barrier and cumulative barrier functions from the  rejection rates and the current annealing schedule. The estimation of the barriers  is based on Fritsch-Carlson monotonic interpolation.\n\nReturns a NamedTuple with fields:\n\nlocalbarrier\ncumulativebarrier\nglobalbarrier\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.communicator-Tuple{Any}","page":"Reference","title":"Pigeons.communicator","text":"communicator(replicas)\n\n\nReturn the replicas's MPI.Comm or nothing if no MPI needed\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.computeetas-Tuple{Any, Any}","page":"Reference","title":"Pigeons.computeetas","text":"computeetas(ϕ, β)\n\nCompute the etas matrix given ϕ, which is an Array(K - 1, 2) containing  knot parameters, and β, a vector of N+1 schedules. For linear paths,  the function returns an (N+1)x2 matrix with entries 1-β in the first column  and β in the second column. (This function is useful for those wishing to consider non-linear paths. However, full support is provided only for linear paths at  the moment.) \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_entangled_replicas-Tuple{Inputs, Pigeons.Shared, Any}","page":"Reference","title":"Pigeons.create_entangled_replicas","text":"create_entangled_replicas(inputs, shared, source)\n\n\nCreate distributed replicas. \n\nSee create_replicas.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_explorer-Tuple{Any, Any}","page":"Reference","title":"Pigeons.create_explorer","text":"create_explorer(target, inputs)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_explorer-Tuple{Any, Inputs}","page":"Reference","title":"Pigeons.create_explorer","text":"create_explorer(target, inputs)\n\n\nCreate an explorer for the given target.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_explorer-Tuple{Any}","page":"Reference","title":"Pigeons.create_explorer","text":"create_explorer(inputs)\n\n\nGiven an Inputs object, dispatch on  create_explorer(inputs.target, inputs) to construct the  explorer associated with the input target distribution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_pair_swapper-Tuple{Any, Any}","page":"Reference","title":"Pigeons.create_pair_swapper","text":"create_pair_swapper(tempering, target)\n\n\nGiven a tempering and a Shared struct,  create a pair_swapper. \n\nIf ommitted, by default will return the standard Metropolis-Hastings  accept-reject. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_path-Tuple{Any, Inputs}","page":"Reference","title":"Pigeons.create_path","text":"create_path(target, inputs)\n\n\nCreate a path, by default linking the given target to  the refence provided by create_reference_log_potential().\n\nFor this default to work, the target should conform both  target and log_potential.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_path-Tuple{Pigeons.ScaledPrecisionNormalPath, Inputs}","page":"Reference","title":"Pigeons.create_path","text":"create_path(target, inputs)\n\n\nIn this case, the target is already a path, so return it. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_recorders-Tuple{Any}","page":"Reference","title":"Pigeons.create_recorders","text":"create_recorders(recorder_builders)\n\n\nCreate a recorders from an iterable with element  type recorder_builder.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_recorders-Tuple{Inputs, Pigeons.Shared}","page":"Reference","title":"Pigeons.create_recorders","text":"create_recorders(inputs, shared)\n\n\nCreate a recorders from an Inputs and Shared.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_reference_log_potential-Tuple{Any, Inputs}","page":"Reference","title":"Pigeons.create_reference_log_potential","text":"create_reference_log_potential(target, inputs)\n\n\nCreate a default reference distribution, by returning a  log_potential. The returned object will also get  passed to sample_iid!() at the \"hot chains\" of  the Parallel Tempering algorithm. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_replicas-Tuple{Inputs, Pigeons.Shared, Any}","page":"Reference","title":"Pigeons.create_replicas","text":"create_replicas(inputs, shared, source)\n\n\nCreate replicas, detecting automatically if MPI is needed. \n\nArgument source is either a state_initializer to create  fresh replicas, or FromCheckpoint to load from  a saved checkpoint.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_state_initializer-Tuple{Any, Inputs}","page":"Reference","title":"Pigeons.create_state_initializer","text":"create_state_initializer(target, inputs)\n\n\nReturn a state_initializer used to populate  the states at the beginning of the first round of  Parallel Tempering. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_swap_graph-Tuple{Any, Any}","page":"Reference","title":"Pigeons.create_swap_graph","text":"create_swap_graph(swap_graphs, shared)\n\n\nGiven a swap_graphs and Shared, return  the swap_graph for the current iteration. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_tempering-Tuple{Inputs}","page":"Reference","title":"Pigeons.create_tempering","text":"create_tempering(inputs)\n\n\nBuild the tempering need for communicate!(). \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.create_vector_replicas-Tuple{Inputs, Pigeons.Shared, Any}","page":"Reference","title":"Pigeons.create_vector_replicas","text":"create_vector_replicas(inputs, shared, source)\n\n\nCreate replicas when distributed computing is not needed.  See also state_initializer.\n\nSee create_replicas.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.deo-Tuple{Any, Any, Any, Any, Any, Any, Int64, Int64, Int64, Any, Any, Any, Any, Bool, Any, Int64}","page":"Reference","title":"Pigeons.deo","text":"deo(potential, initial_state, initial_index, initial_lift, schedule, ϕ, \n    nscan, N, resolution, optimreference_round, modref_means, modref_stds, modref_covs, \n    full_covariance, prior_sampler, n_explore)\n\nDeterministic even-odd parallel tempering (DEO/NRPT).\n\nArguments\n\npotential: Function as in NRPT, but with only two arguments: x and η\ninitial_state: Starting state, as in NRPT. Input is of size: N+1 [ dim_x ]\ninitial_index: Starting indices\ninitial_lift: Starting lift\nschedule: Annealing schedule\nϕ: As in NRPT\nnscan: Number of scans to use\nN: As in NRPT\nresolution: As in NRPT\noptimreference_round: As in NRPT\nmodref_means\nmodref_stds\nprior_sample\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.deo-Tuple{Any}","page":"Reference","title":"Pigeons.deo","text":"deo(n_chains)\n\n\nImplements the Deterministic Even Odd (DEO) scheme proposed in Okabe, 2001 and analyzed in Syed et al., 2021.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.deoscan-NTuple{15, Any}","page":"Reference","title":"Pigeons.deoscan","text":"deoscan(potential, state, index, lift, etas, n, N, kernels, \n    optimreference_round, modref_means, modref_stds, modref_covs, full_covariance, \n    prior_sampler, n_explore)\n\nPerform one DEO scan (local exploration + communication). Arguments are  similar to those for deo(). Note that state is the state from the one previous  scan, which is of size N+1[dim_x].\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.deserialize_immutables-Tuple{AbstractString}","page":"Reference","title":"Pigeons.deserialize_immutables","text":"deserialize_immutables(filename)\n\n\nSee Immutable().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.discretize-Tuple{Any, Pigeons.Schedule}","page":"Reference","title":"Pigeons.discretize","text":"discretize(path, betas)\n\n\nCreate log_potentials from a path by interpolating the  path at each grid point specified in the Schedule.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.entangler-Tuple{Any}","page":"Reference","title":"Pigeons.entangler","text":"entangler(replicas)\n\n\nReturn the replicas's Entangler (possibly a no-communication Entangler if a single process is involved)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.equally_spaced_schedule-Tuple{Int64}","page":"Reference","title":"Pigeons.equally_spaced_schedule","text":"equally_spaced_schedule(n_chains)\n\n\nCreate a Schedule with n_chains equally spaced grid points.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explore!-Tuple{Any, Any, Val{false}}","page":"Reference","title":"Pigeons.explore!","text":"explore!(pt, explorer, multithreaded)\n\n\nThe @thread macro brings a large overhead even  when Threads.nthreads == 1, so treating each case  separately\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explore!-Tuple{Any, Any, Val{true}}","page":"Reference","title":"Pigeons.explore!","text":"explore!(pt, explorer, multithreaded_flag)\n\n\nCall sample_iid! or step!() on  each chain (depending if it is a reference or not  respectively). \n\nUses @threads to parallelize across threads.  This is safe by the contract described in  sample_iid! and step!().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.explorer_recorder_builders-Tuple{Any}","page":"Reference","title":"Pigeons.explorer_recorder_builders","text":"explorer_recorder_builders(explorer)\n\n\nWhat information is needed to perform adapt_explorer? Answer this by specifying an iterator containing recorder_builder's.  Return [] if none are needed. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_global_index-Tuple{Pigeons.LoadBalance, Int64}","page":"Reference","title":"Pigeons.find_global_index","text":"find_global_index(lb, local_idx)\n\n\nFind the global index corresponding to the given local_index. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_local_index-Tuple{Pigeons.LoadBalance, Int64}","page":"Reference","title":"Pigeons.find_local_index","text":"find_local_index(lb, global_idx)\n\n\nFind the local index corresponding to the given global_index.  Assumes the given global_index is one of this process'. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_log_potential-Tuple{Any, Any}","page":"Reference","title":"Pigeons.find_log_potential","text":"find_log_potential(replica, shared)\n\n\nFind the log_potential for the chain  the replica is at, based on the Shared object.  \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.find_process-Tuple{Pigeons.LoadBalance, Int64}","page":"Reference","title":"Pigeons.find_process","text":"find_process(lb, global_idx)\n\n\nFind the process id (1-indexed) responsible for the given global_idx. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.flush_immutables!-Tuple{}","page":"Reference","title":"Pigeons.flush_immutables!","text":"flush_immutables!()\n\n\nSee Immutable().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.index_process-Tuple{}","page":"Reference","title":"Pigeons.index_process","text":"Full index process stored in memory. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.index_process_plot-Tuple{Any}","page":"Reference","title":"Pigeons.index_process_plot","text":"index_process_plot(recorders)\n\n\nGiven a recorders, create an index process plot.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.informal_doc-Tuple{Any, Module}","page":"Reference","title":"Pigeons.informal_doc","text":"informal_doc(doc_dir, mod)\n\n\nGenerate informal interface documentation, e.g.: \n\nmakedocs(;\n    ...\n    pages=[\n        \"Home\" => \"index.md\", \n        \"Interfaces\" => informal_doc(@__DIR__, MyModuleName),\n        ...\n    ]\n)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.initialization-Tuple{Any, SplittableRandoms.SplittableRandom, Int64}","page":"Reference","title":"Pigeons.initialization","text":"initialization(state_initializer, rng, replica_index)\n\n\nDetermine state_initializer's initialization for the given replica_index.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.interpolate-Tuple{Any, Any}","page":"Reference","title":"Pigeons.interpolate","text":"interpolate(path, beta)\n\n\nReturns the log_potential at point beta in the path.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.is_finished-Tuple{AbstractString, Any}","page":"Reference","title":"Pigeons.is_finished","text":"is_finished(checkpoint_folder, inputs)\n\n\nIs the provided path to a checkpoint folder complete?  I.e. check in the .signal subfolder that all MPI processes have  signaled that they are done.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.latest_checkpoint_folder-Tuple{Any}","page":"Reference","title":"Pigeons.latest_checkpoint_folder","text":"latest_checkpoint_folder(exec_folder)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.load-Tuple{Any}","page":"Reference","title":"Pigeons.load","text":"load(replicas)\n\n\nReturn the replicas's LoadBalance (possibly single_process_load)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.load-Union{Tuple{Result{T}}, Tuple{T}} where T","page":"Reference","title":"Pigeons.load","text":"load(replicas)\nload(result)\n\n\nLoad the result in memory.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.local_exploration-NTuple{9, Any}","page":"Reference","title":"Pigeons.local_exploration","text":"local_exploration(states, kernels, optimreference_round, modref_means, modref_stds, \n    modref_covs, full_covariance, prior_sampler, n_explore)\n    chainacceptance = Vector{Int64}(undef, length(states))\n\nPerform one local exploration move. state is the state from the one  previous scan, which is of size N+1[dim_x].\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.locals-Tuple{Any}","page":"Reference","title":"Pigeons.locals","text":"locals(replicas)\n\n\nReturn the replica's that are stored in this machine\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.log_unnormalized_ratio-Tuple{AbstractVector, Int64, Int64, Any}","page":"Reference","title":"Pigeons.log_unnormalized_ratio","text":"log_unnormalized_ratio(\n    log_potentials::AbstractVector,\n    numerator::Int64,\n    denominator::Int64,\n    state\n) -> Any\n\n\nAssumes the input log_potentials is a vector where each element is a log_potential.\n\nThis default implementation is sufficient in most cases, but in less standard scenarios, e.g. where the state space is infinite dimensional, this can be overridden. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.log_unnormalized_ratio-Tuple{Any, Int64, Int64, Any}","page":"Reference","title":"Pigeons.log_unnormalized_ratio","text":"log_unnormalized_ratio(\n    log_potentials,\n    numerator,\n    denominator,\n    state\n)\n\n\nThe argument numerator selects one distribution pi_i from the collection log_potentials,  and similarly denominator selects pi_j. Let x denote the input state. The ratio:\n\nf(x) = fractextdpi_itextdpi_j(x)\n\nmay only be known up to a normalization constant which can depend on i and j but  not x, g(x) = C_ij f(x).\n\nThis function should return log g evaluated at state.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.lognormalizingconstant-Tuple{Any, Any}","page":"Reference","title":"Pigeons.lognormalizingconstant","text":"lognormalizingconstant(energies, schedule)\n\nCompute an estimate of the log normalizing constant given a vector of  energies and the corresponding annealing schedule.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.mpi_active-Tuple{}","page":"Reference","title":"Pigeons.mpi_active","text":"mpi_active()\n\n\nDetect if more than one MPI processes can be found. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.my_global_indices-Tuple{Pigeons.LoadBalance}","page":"Reference","title":"Pigeons.my_global_indices","text":"my_global_indices(lb)\n\n\nThe slice of lb.global_indices this process is reponsible for.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.my_load-Tuple{Pigeons.LoadBalance}","page":"Reference","title":"Pigeons.my_load","text":"my_load(lb::Pigeons.LoadBalance) -> Int64\n\n\nReturn the number of indices (task) this process is responsible for. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.n_chains-Tuple{Any}","page":"Reference","title":"Pigeons.n_chains","text":"n_chains(log_potentials)\n\n\nThe number of chains in the log_potentials.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.next_exec_folder-Tuple{}","page":"Reference","title":"Pigeons.next_exec_folder","text":"Return a unique subfolder of  results/all/, making sure the  unique folder and its parents are created.  It will also create a soft symlink to it  called results/latest`\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.one_per_host-Tuple{Any}","page":"Reference","title":"Pigeons.one_per_host","text":"For benchmarking purpose: subset the communicator so that at most one MPI process runs      in each machine.\n\nDivision is done so that original rank 0 is always included.\n\nReturn the new communicator or nothing if this machine is not in the subset. \n\nSee also '-s' option in mpi-run\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.only_one_process-Tuple{Any, Any}","page":"Reference","title":"Pigeons.only_one_process","text":"only_one_process(task, pt)\n\n\nA task that should be ran on only one of the processes.  Using the do .. end syntax, this can be used as:\n\nonly_one_process(pt) do \n    ...\nend\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.partner_chain-Tuple{Any, Int64}","page":"Reference","title":"Pigeons.partner_chain","text":"partner_chain(swap_graph, chain)\n\n\nFor a given swap_graph and input chain index, what chain will it interact with at the current iteration? Convention: if a chain is not interacting, return its index.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.permuted_get-Union{Tuple{T}, Tuple{Pigeons.PermutedDistributedArray{T}, AbstractVector{Int64}}} where T","page":"Reference","title":"Pigeons.permuted_get","text":"permuted_get(p, indices)\n\n\nRetreive the values for the given indices, using MPI communication when needed. \n\nWe make the following assumptions:\n\nlength(indices) == my_load(p.entangler.load)\nthe indices across all participating processes form a permutation of the global indices. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.permuted_set!-Union{Tuple{T}, Tuple{Pigeons.PermutedDistributedArray{T}, AbstractVector{T}, AbstractVector{T}}} where T","page":"Reference","title":"Pigeons.permuted_set!","text":"permuted_set!(p, indices, new_values)\n\n\nSet the values for the given indices to the given new_values, using MPI communication when needed. \n\nWe make the same assumptions as in permuted_get().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{Any, ChildProcess}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(pt_arguments, new_process)\n\n\nRun Parallel Tempering in a new process.  See ChildProcess.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{Any, MPI}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(pt_arguments, mpi_submission)\n\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{Any}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(pt_arguments; on)\n\n\npt_arguments can be either an Inputs, to start  a new Parallel Tempering algorithm, or a string pointing to  an execution to resume. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{PT}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(pt)\n\n\nRun (a generalization of) Parallel Tempering. \n\nThis will call several rounds of run_one_round!(),  performing adaptation between each round via adapt().\n\nThis will also call report(), write_checkpoint(),  and run_checks() between rounds. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.pigeons-Tuple{}","page":"Reference","title":"Pigeons.pigeons","text":"pigeons(; on, args...)\n\n\nPasses the args... to Inputs and start  a new Parallel Tempering algorithm with that inputs. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.providers-Tuple{Module, Symbol}","page":"Reference","title":"Pigeons.providers","text":"providers(mod, name)\n\n\nProvides a Set{Expr} containing all the providers of the  given name in the given module. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record!-Tuple{Any, Any}","page":"Reference","title":"Pigeons.record!","text":"record!(recorder, value)\n\n\nAdd value to the statistics accumulated by recorder. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record!-Tuple{OnlineStatsBase.OnlineStat, Any}","page":"Reference","title":"Pigeons.record!","text":"record!(recorder, value)\n\n\nForwards to OnlineStats' fit!.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record!-Union{Tuple{V}, Tuple{K}, Tuple{Dict{K, Vector{V}}, Tuple{K, V}}} where {K, V}","page":"Reference","title":"Pigeons.record!","text":"record!(recorder, value)\n\n\nGiven a value, a pair (a, b), and a Dict{K, Vector{V}} backed  recorder,  append b to the vector corresponding to a, inserting an empty  vector into the dictionary first if needed.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record_if_requested!-Tuple{Any, Symbol, Any}","page":"Reference","title":"Pigeons.record_if_requested!","text":"record_if_requested!(recorders, recorder_key, value)\n\n\nIf the recorders contains the given recorder_key,  send the value to the recorder corresponding to the  recorder_key. Otherwise, do nothing.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record_swap_stats!-Tuple{Any, Any, Int64, Any, Int64, Any}","page":"Reference","title":"Pigeons.record_swap_stats!","text":"record_swap_stats!(\n    pair_swapper,\n    recorders,\n    chain1,\n    stat1,\n    chain2,\n    stat2\n)\n\n\nGiven a pair_swapper, a recorders, the provided chain indices, and  the sufficient statistics computed by swap_stat(), record statistics. \n\nTo avoid accumulating twice the same statistic with (chain1, chain2) and  (chain2, chain2), swap!() only calls this for the pair with chain1 < chain2.\n\nBy default, the following are accumulated:\n\nthe swap acceptance probability.\nTODO: stepping stone statistics.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.record_swap_stats!-Tuple{Pigeons.TestSwapper, Any, Int64, Any, Int64, Any}","page":"Reference","title":"Pigeons.record_swap_stats!","text":"record_swap_stats!(\n    swapper,\n    recorder,\n    chain1,\n    stat1,\n    chain2,\n    stat2\n)\n\n\nSee TestSwapper.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.reduce_deterministically-Union{Tuple{T}, Tuple{Any, AbstractVector{T}, Pigeons.Entangler}} where T","page":"Reference","title":"Pigeons.reduce_deterministically","text":"reduce_deterministically(operation, source_data, e)\n\n\nPerform a binary reduction of the  source_data, using MPI when needed. \n\nConsider the binary tree with leaves given by the global indices specified in e.load and stored  in the different MPI processes' input source_data vectors.  At each node of the tree, a reduction is performed using operation, i.e.  by calling operation(left_child, right_child). When, and only when a branch of the tree crosses from one MPI process to another one,  MPI communication is used to transmit the intermediate reduction. \n\nAt the end, for process 1, reduce_deterministically() will return the root of the  binary tree, and for the other processes, reduce_deterministically() will return  nothing. \n\nNote that even when the operation is only approximately associative (typical situation  for floating point reductions), the output of this function is invariant to the  number of MPI processes involved (hence the terminology 'deterministically').  This contrasts to direct use of MPI collective communications where the leaves are  MPI processes and hence will give slightly different outputs given different  numbers of MPI processes. In the context of randomized algorithms, these minor  differences are then amplified. \n\nIn contrast to transmit!(), we do not assume isbitstype(T) == true and use  serialization when messages are transmitted over MPI.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.reduce_recorders!-Tuple{Pigeons.EntangledReplicas}","page":"Reference","title":"Pigeons.reduce_recorders!","text":"reduce_recorders!(replicas)\n\n\nPerform a reduction across all the replicas' individual recorders,  using merge() on each individual recorder held. Returns a recorders with all the information merged. \n\nWill reset the replicas' recorders at the same time using empty!().\n\nSince this uses all_reduce_deterministically, the output is  identical, no matter how many MPI processes are used, even when  the reduction involves only approximately associative merge() operations (e.g. most floating point ones).\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.reference_chains-Tuple{Any, Any}","page":"Reference","title":"Pigeons.reference_chains","text":"reference_chains(swap_graphs, shared)\n\n\nGiven a swap_graphs and Shared, return  a Set{Int} of chain(s) indices targetting the distribution of interest. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.report-Tuple{Any, Any}","page":"Reference","title":"Pigeons.report","text":"report(pt, reduced_recorders)\n\n\nReport summary information on the progress of pigeons().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.restarts-Tuple{Any}","page":"Reference","title":"Pigeons.restarts","text":"restarts(indices_matrix; cumulative) -> Any\n\n\nCompute the number of restarts for a given index process trajectory.  Otherwise, it is the same as roundtrip().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.roundtrip-Tuple{Any}","page":"Reference","title":"Pigeons.roundtrip","text":"roundtrip(indices_matrix; cumulative) -> Any\n\n\nCompute the number of round trips for a given index process trajectory.  indices_matrix is a matrix containing information about the index process. cumulative indicates whether we should store the output as a vector containing  information about the number of total round trips up to sample n. If false, the output is a scalar.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.run_checks-Tuple{Any}","page":"Reference","title":"Pigeons.run_checks","text":"Perform checks to detect software defects.  Unable via field checked_round in Inputs Currently the following checks are implemented:\n\ncheck_against_serial()\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.run_one_round!-Tuple{Any}","page":"Reference","title":"Pigeons.run_one_round!","text":"run_one_round!(pt)\n\n\nFrom a PT object, run one round of  a generalized version of Algorithm 1 in  Syed et al., 2021.\n\nAlternates between communicate!(),  which consists of any pairwise communicating  moves and [explore!()], which consists in  moves independ to each chain. \n\nConcrete specification of how to communicate and  explore are specified by the field of type Shared  contained in the provided PT. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.sample_iid!-Tuple{Any, Any}","page":"Reference","title":"Pigeons.sample_iid!","text":"sample_iid!(reference_log_potential, replica)\n\n\nPerform i.i.d. sampling on the given Replica  during its visit to the referencelogpotential created  by create_reference_log_potential().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.serialize_immutables-Tuple{AbstractString}","page":"Reference","title":"Pigeons.serialize_immutables","text":"serialize_immutables(filename)\n\n\nSee Immutable().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.setkernels-Tuple{Any, Any}","page":"Reference","title":"Pigeons.setkernels","text":"setkernels(potential, etas)\n\nSet the local exploration kernels given the potential and the annealing  parameters, etas.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.setup_mpi-Tuple{Pigeons.MPISettings}","page":"Reference","title":"Pigeons.setup_mpi","text":"setup_mpi(settings)\n\n\nRun this function once before running MPI jobs.  The setting are permanently saved\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.setup_mpi-Tuple{}","page":"Reference","title":"Pigeons.setup_mpi","text":"setup_mpi(; args...)\n\n\nArguments are passed in the constructor of MPISettings.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.single_process_load-Tuple{Any}","page":"Reference","title":"Pigeons.single_process_load","text":"single_process_load(n_global_indices)\n\n\nA load balance with only one process.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.slice_accept-Tuple{Pigeons.SliceSampler, Any, Any, Any, Any, Any, Any, Any}","page":"Reference","title":"Pigeons.slice_accept","text":"slice_accept(\n    h,\n    state,\n    new_position,\n    z,\n    L,\n    R,\n    pointer,\n    log_potential\n)\n\n\nTest whether to accept the current slice.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.slice_double-Tuple{Pigeons.SliceSampler, Any, Any, Any, Any, Any}","page":"Reference","title":"Pigeons.slice_double","text":"slice_double(h, state, z, pointer, log_potential, rng)\n\n\nDouble the current slice.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.slice_sample!-Tuple{Pigeons.SliceSampler, AbstractVector, Any, Any}","page":"Reference","title":"Pigeons.slice_sample!","text":"slice_sample!(h, state, log_potential, rng)\n\n\nSlice sample one point.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.slice_shrink-Tuple{Pigeons.SliceSampler, Any, Any, Any, Any, Any, Any, Any}","page":"Reference","title":"Pigeons.slice_shrink","text":"slice_shrink(h, state, z, L, R, pointer, log_potential, rng)\n\n\nShrink the current slice.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.sort_includes!-Tuple{Any}","page":"Reference","title":"Pigeons.sort_includes!","text":"sort_includes!(main)\n\n\nHeuristic to automate the process  of sorting include()'s.\n\nTopological sorting of the source files under src  (excluding main) is attempted, if successful, print the  include string to copy and paste to the main file, otherwise,  print the detected loops. \n\nInternally, this function will:\n\nConstruct a graph where the vertices are the .jl files   under src, excluding the provided main file (i.e. where the module is   defined and the includes will sit in).\nEach file starting with a capital letter is assumed to   contain a struct with the same name as the file after   removal of the .jl suffix. Similarly, files starting   with @ are assumed to contain a macro with the similarly   obtained name.\nEach source file is inspected to see if the above struct and   macro strings are detected. This defines edges in the graph.  (known limitation: this includes spurious edges when e.g.   the string occurs in a comment).\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.split_slice-Tuple{UnitRange, Any}","page":"Reference","title":"Pigeons.split_slice","text":"split_slice(slice, rng)\n\n\nFrom one splittable random object, one can conceptualize an infinite list of splittable random objects.  Return a slice from this infinite list.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.step!-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.step!","text":"step!(explorer, replica, shared)\n\n\nPerform a transition on the given Replica  invariant with respect to the distribution of the  replica's chain. \n\nThe input explorer and Shared should only  be read, not written to. \n\nSee also find_log_potential. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap!-Tuple{Any, Any, Any}","page":"Reference","title":"Pigeons.swap!","text":"swap!(pair_swapper, replicas, swap_graph)\n\n\nFor each pair of chains encoded in swap_graph, use  pair_swapper to decide if the pair will swap or not,  and write the changes in-place into replicas (i.e. exchanging  the Replica's chain fields for those that swapped.)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap!-Tuple{Any, Pigeons.EntangledReplicas, Any}","page":"Reference","title":"Pigeons.swap!","text":"swap!(pair_swapper, replicas, swap_graph)\n\n\nEntangled MPI swap! implementation.\n\nThis implementation is designed to support distributed PT with the following guarantees\n\nThe running time is independent of the size of the state space      ('swapping annealing parameters rather than states')\nThe output is identical no matter how many MPI processes are used. In particular,      this means that we can check correctness by comparing to the serial, single-process version.\nScalability to 1000s of processes communicating over MPI (see details below).\nThe same function can be used when a single process is used and MPI is not available.\nFlexibility to extend PT to e.g. networks of targets and general paths.\n\nRunning time analysis:\n\nLet N denote the number of chains, P, the number of processes, and K = textceil(NP),   the maximum number of chains held by one process.  Assuming the running time is dominated by communication latency and  a constant time for the latency of each   peer-to-peer communication, the theoretical running time is O(K).  In practice, latency will grow as a function of P, but empirically, this growth appears to be slow enough that for say P = N = a few 1000s,  swapping will not be the computational bottleneck.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap!-Union{Tuple{R}, Tuple{Any, Vector{R}, Any}} where R","page":"Reference","title":"Pigeons.swap!","text":"swap!(pair_swapper, replicas, swap_graph)\n\n\nSingle process, non-allocating swap! implementation. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_acceptance_pr-Tuple{}","page":"Reference","title":"Pigeons.swap_acceptance_pr","text":"Average MH swap acceptance probabilities for each pairs  of interacting chains. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_decision-Tuple{Any, Int64, Any, Int64, Any}","page":"Reference","title":"Pigeons.swap_decision","text":"swap_decision(pair_swapper, chain1, stat1, chain2, stat2)\n\n\nGiven a pair_swapper, a recorders, the provided chain indices, and  the sufficient statistics computed by swap_stat(), make a swap decision.\n\nBy default, this is done as follows:\n\ncompute the standard swap acceptance probability min(1, exp(stat1.log_ratio + stat2.log_ratio))\nmake sure the two chains share the same uniform by picking the uniform from the chain with the smallest chain index \nswap if the shared uniform is smaller than the swap acceptance probability.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_decision-Tuple{Pigeons.TestSwapper, Int64, Float64, Int64, Float64}","page":"Reference","title":"Pigeons.swap_decision","text":"swap_decision(swapper, chain1, stat1, chain2, stat2)\n\n\nSee TestSwapper.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_stat-Tuple{Any, Pigeons.Replica, Int64}","page":"Reference","title":"Pigeons.swap_stat","text":"swap_stat(pair_swapper, replica, partner_chain)\n\n\nBy default, two sufficient statistics are computed and stored in the SwapStat struct:\n\nThe result of calling log_unnormalized_ratio() on pair_swapper\nA uniform number to coordinate the swap decision.\n\nThis can be extended by dispatching on other pair_swapper types, with the  constraint that the returned sufficient statistics should satisfy isbitstype().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.swap_stat-Tuple{Pigeons.TestSwapper, Pigeons.Replica, Int64}","page":"Reference","title":"Pigeons.swap_stat","text":"swap_stat(swapper, replica, partner_chain)\n\n\nSee TestSwapper.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.target_chains-Tuple{Any, Any}","page":"Reference","title":"Pigeons.target_chains","text":"target_chains(swap_graphs, shared)\n\n\nGiven a swap_graphs and Shared, return the set of chain(s) targetting the reference distribution. These are typically tractable in the sense that we can sample  i.i.d. from them. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.tempering_recorder_builders-Tuple{Any}","page":"Reference","title":"Pigeons.tempering_recorder_builders","text":"tempering_recorder_builders(tempering)\n\n\nWhat information is needed to perform adapt_tempering? Answer this by specifying an iterator containing recorder_builder's.  Return [] if none are needed.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.toy_mvn_target-Tuple{Int64}","page":"Reference","title":"Pigeons.toy_mvn_target","text":"toy_mvn_target(\n    dim::Int64\n) -> Pigeons.ScaledPrecisionNormalPath\n\n\nA toy multi-variate normal (mvn) target distribution used for testing.  Uses a specialized path, ScaledPrecisionNormalPath,  such that i.i.d. sampling is possible at all chains (via ToyExplorer). \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.transmit!-Union{Tuple{T}, Tuple{Pigeons.Entangler, AbstractVector{T}, AbstractVector{Int64}, Vector{T}}} where T","page":"Reference","title":"Pigeons.transmit!","text":"transmit!(\n    e,\n    source_data,\n    to_global_indices,\n    write_received_data_here\n)\n\n\nUse MPI point-to-point communication to  permute the contents of source_data across MPI processes, writing the permuted data into  write_received_data_here.  The permutation is specified by the load balance in the input argument e as well as the  argument to_global_indices.\n\nMore precisely, assume the Vectors source_data, to_global_indices, and write_received_data_here  are all of the length specified in my_load(e.load). \n\nFor each i, source_data[i] is sent to MPI process p = find_process(e.load, g),  where g = to_global_indices[i] and  written into this p 's write_received_data_here[j], where j = find_local_index(e.load, g)\n\nSee Entangler's comments regarding the requirement that all machines call transmit() the  same number of times and at logically related intervals. \n\nAdditionally, at each micro-iteration, we assume that  {to_global_indices_p : p ranges over the different processes} forms a partition of  {1, ..., e.load.n_global_indices} If ran in single-process mode, this 'partition property' is checked;  if ran in multi-process, opportunistic checks will be made, namely when several entries in to_global_indices  lie in the same process, but systematic checks are not made for performance reasons. \n\nWe also assume isbitstype(T) == true. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.transmit-Union{Tuple{T}, Tuple{Pigeons.Entangler, AbstractVector{T}, AbstractVector{Int64}}} where T","page":"Reference","title":"Pigeons.transmit","text":"transmit(e, source_data, to_global_indices)\n\n\nThe same as transmit!() but instead of writing the result to an input argument, provide the result  as a returned Vector. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.updateschedule-Tuple{Any, Int64}","page":"Reference","title":"Pigeons.updateschedule","text":"updateschedule(cumulativebarrier, N)\n\n\nUpdate the annealing schedule. Given the cumulative communication barrier function in cumulativebarrier, find the optimal schedule of size N+1.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.winsorized_mean-Tuple{Any}","page":"Reference","title":"Pigeons.winsorized_mean","text":"winsorized_mean(x; α)\n\nCompute the winsorized mean from an input x, which is assumed to be a vector of vectors.  α denotes the percentage of observations to winsorize at the bottom and the top  so that we use 1 - 2α observations and winsorize the rest.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.winsorized_std-Tuple{Any}","page":"Reference","title":"Pigeons.winsorized_std","text":"winsorized_std(x; α)\n\nCompute the winsorized standard deviation. The parameters are the same  as those for winsorized_mean().\n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.write_checkpoint-Tuple{Any, Any}","page":"Reference","title":"Pigeons.write_checkpoint","text":"write_checkpoint(pt, reduced_recorders)\n\n\nIf pt.inputs.checkpoint == true, save a checkpoint under  [pt.exec_folder]/[unique folder]/round=[x]/checkpoint. \n\nBy default, pt.exec_folder is results/all/[unique folder].\n\nIn an MPI context, each MPI process will write its local replicas,  while only one of the MPI processes will write the Shared  and reduced recorders data. Moreover, only one MPI process will  write once at the first round the Inputs data. \n\nIn cases where the sampled model contains large immutable data, consider using  Immutable() to save disk space (Immutables will be written only by  one MPI process at the first round). \n\n\n\n\n\n","category":"method"},{"location":"reference/#Pigeons.@abstract-Tuple{}","page":"Reference","title":"Pigeons.@abstract","text":"my_fct() = @abstract()\n\nDefine an abstract function (i.e. which gives an error message if calling it  is attempted). \n\n\n\n\n\n","category":"macro"},{"location":"reference/#Pigeons.@informal-Tuple{Symbol, Expr}","page":"Reference","title":"Pigeons.@informal","text":"@informal name begin ... end\n\nDocument an informal interface with provided name, and functions  specified in a begin .. end block. \n\n@informal will spit back the contents of the begin .. end block so  this macro can be essentially ignored at first read. \n\nWhen building documentation, this allows us to use the  function informal_doc() to automatically document the  informal interface.\n\n\n\n\n\n","category":"macro"},{"location":"reference/#Pigeons.@weighted-Tuple{Any, Any}","page":"Reference","title":"Pigeons.@weighted","text":"@weighted(w, x)\n\nCompute w*x, but if w==0.0, do not evaluate x and just return w (i.e. zero). Useful when x is computationally costly.\n\n\n\n\n\n","category":"macro"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"CurrentModule = Pigeons","category":"page"},{"location":"distributed/#Distributed-and-parallel-implementation-of-PT","page":"Distributed PT","title":"Distributed and parallel implementation of PT","text":"","category":"section"},{"location":"distributed/#Introduction","page":"Distributed PT","title":"Introduction","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Pigeons provides an implementation of Distributed PT based on Syed et al., 2021,  Algorithm 5. This page describes our strategies for addressing the challenges of implementing this distributed,  parallelized, and randomized algorithm.","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"note: Note\nRead this page if you are interested in extending Pigeons or  understanding how it works under the hood.  Reading this page is not required to use Pigeons. Instead, refer to the  user guide. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"In Distributed PT, one or several computers run MCMC simulations in parallel and  communicate with each other to improve MCMC efficiency.  We use the terminology machine for one of these computers, or, to be more precise,  process. In the typical setting, each machine will run one process, since our implementation also supports  the use of several Julia threads.","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Pigeons is designed so that it is suitable in all these scenarios:","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"one machine running PT on one thread,\none machine running PT on several threads,\nseveral machines running PT, each using one thread, and\nseveral machines running PT, each using several threads.","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Ensuring code correctness at the intersection of randomized, parallel, and distributed algorithms is a challenge.  To address this challenge, we designed Pigeons based on the following principle:","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"note: Parallelism Invariance\nThe output of Pigeons is invariant to the number of machines and/or threads.","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"In other words, if X_m t(s) denotes the output of Pigeons when provided m machines, t threads  per machine, and random seed s, we guarantee that X_m t(s) = X_m t(s) for all m t. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Without explicitly keeping Parallelism Invariance in mind during software construction,  parallel/distributed implementations of randomized algorithms will  typically only guarantee EX_m t = EX_m t for all m m t t. While equality in distribution is technically  sufficient, the stronger pointwise equality required by Parallelism Invariance makes  debugging and software validation considerably easier.  This is because the developer can first focus on the fully serial randomized algorithm,  and then use it as an easy-to-compare gold-standard reference for parallel/distributed  implementations.  This strategy is used extensively in Pigeons to ensure correctness.  In contrast, testing equality in distribution, while possible (e.g., see  Geweke, 2004), incurs additional  false negatives due to statistical error. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Two factors tend to cause violations of Parallelism Invariance: ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Global or thread-local random number generators (which are unfortunately widespread approaches to parallel   random number generators in many languages).\nNon-associativity of floating point operations. As a result, when several workers    perform Distributed reduction of    floating point values, the output of this reduction will be slightly different.    When these reductions are then fed into further random operations, this implies    two randomized algorithms with the same seed but using a different number of workers    will eventually arbitrarily diverge pointwise. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"One focus in the remainder of this page is to describe how our implementation sidesteps  the two above issues while maintaining the same asymptotic runtime complexity.","category":"page"},{"location":"distributed/#Overview-of-the-algorithm","page":"Distributed PT","title":"Overview of the algorithm","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Let us start with a high-level picture of the distributed PT algorithm. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"The high-level code is the function pigeons() which is identical to the single-machine algorithm. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Notice the code is almost identical to the single-machine algorithm presented earlier with the only difference being create_vector_replicas is  replaced by create_entangled_replicas. Also, as promised the  output is identical despite a vastly different swap logic.  Indeed, beyond the superficial syntactic similarities between the single process and  distributed code, the behaviour of swap! is quite different (this is triggered by multiple dispatch  detecting the different types for  replica in fully serial versus distributed). ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"In the following, we go over the main building block of  our distributed PT algorithm. ","category":"page"},{"location":"distributed/#Splittable-random-streams","page":"Distributed PT","title":"Splittable random streams","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"The first building block is a splittable random stream.  To motivate splittable random streams, consider the following example violating Parallelism Invariance:","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"using Pigeons\nusing SplittableRandoms\nusing Random\nimport Base.Threads.@threads\n\nprintln(\"Number of threads: $(Threads.nthreads())\")\n\nconst n_iters = 10000\nresult = zeros(n_iters)\nRandom.seed!(1)\n@threads for i in 1:n_iters\n    # in a real problem, do some expensive calculation here...\n    result[i] = rand()\nend\nprintln(\"Multi-threaded: $(last(result))\")\n\nRandom.seed!(1)\nfor i in 1:n_iters\n    # in a real problem, do some expensive calculation here...\n    result[i] = rand()\nend\nprintln(\"Single-threaded: $(last(result))\")","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Unless only one thread is used, the result of the above parallel loop versus serial loop will be different with  high probability. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"To work around this, we associate one random number generator to each PT chain instead  of one generator per thread. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"To do so, we use the  SplittableRandoms.jl library which allows  us to turn one seed into several pseudo-independent random number generators.  Since each MPI process holds a subset of the chains, we internally use the  function split_slice() to  get the random number generators for the slice of replicas held in a given MPI process.","category":"page"},{"location":"distributed/#Distributed-replicas","page":"Distributed PT","title":"Distributed replicas","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Calling create_entangled_replicas() will produce a fresh EntangledReplicas,  taking care of distributed random seed splitting internally.  An EntangledReplicas contains the list of replicas that are local to the machine, in addition to three data structures allowing distributed communication:  a LoadBalance which keeps track of  how to split work across machines; an Entangler, which encapsulates MPI calls;  and a PermutedDistributedArray, which   maps chain indices to replica indices. These datastructures can be obtained using load(), entangler(), and  replicas.chain_to_replica_global_indices respectively.","category":"page"},{"location":"distributed/#Distributed-swaps","page":"Distributed PT","title":"Distributed swaps","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"To perform distributed swaps, swap!() proceeds as follows:","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"Use the swap_graph to determine swapping partner chains,\ntranslate partner chains into partner replicas (global indices) using  replicas.chain_to_replica_global_indices,\ncompute swap_stat() for local chains, and use   transmit() to obtain partner swap stats,\nuse swap_decision() to decide if each pair should swap, and \nupdate the replicas.chain_to_replica_global_indices datastructure. ","category":"page"},{"location":"distributed/#Distributed-reduction","page":"Distributed PT","title":"Distributed reduction","text":"","category":"section"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"After each round of PT, the workers need to exchange richer messages compared to the information exchanged in the swaps.  These richer messages include swap acceptance probabilities,  statistics to adapt a variational reference, etc. ","category":"page"},{"location":"distributed/","page":"Distributed PT","title":"Distributed PT","text":"This part of the communication is performed using reduce_recorders!() which  in turn calls all_reduce_deterministically() with the appropriate   merging operations. See reduce_recorders!() and  all_reduce_deterministically() for more information on how  our implementation preserves Parallelism Invariance, while maintaining the logarithmic runtime of binary-tree based  collective operations. (More precisely, all_reduce_deterministically() runs in time log(N)  when each machine holds a single chain.)","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"CurrentModule = Pigeons","category":"page"},{"location":"#Pigeons","page":"Guide","title":"Pigeons","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"Facing a challenging integration problem? Tired of waiting for hours or days for your high-dimensional, multimodal Bayesian posterior approximation? Summing over your combinatorial space is taking months? ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Try Pigeons: a Julia package to efficiently approximate posterior distributions, and more broadly, Lebesgue integration problems. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Pigeons' core algorithm is a distributed and parallel implementation  of the following algorithms: ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Non-Reversible Parallel Tempering (NRPT),    Syed et al., 2021.\nVariational PT, Surjanovic et al., 2022. [under construction]","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"These algorithms achieve state-of-the-art performance for approximation  of challenging probability distributions.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Pigeons can be used in a multi-threaded context, and/or  distributed over hundreds or thousands of MPI-communicating machines.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Distributed Parallel Tempering has some remarkable properties.  First, even if your model is very large, the network communication between  processes in the inner loop of the algorithm ","category":"page"},{"location":"#Scope","page":"Guide","title":"Scope","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"We describe here the class of problems that can be approached using Pigeons.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Let pi(x) denote a probability density called the target.  In many problems, e.g. in Bayesian statistics, the density pi is typically  known only up to a normalization constant, ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pi(x) = fracgamma(x)Z","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"where gamma can be evaluated pointwise, but Z is unknown. Pigeons takes as input the function gamma.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"terminology: log_potential\nSince we work in log-scale, we use the terminology  log_potential as a shorthand for the  unnormalized log density log gamma(x).  See informal interface log_potential.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Pigeons' outputs can be used for two tasks:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Approximating expecations of the form Ef(X), where X sim pi.    For example, the choice f(x) = x computes the mean, and    f(x) = Ix in A computes the probability of A under pi.\nApproximating the value of the normalization constant Z. For    example, in Bayesian statistics, this corresponds to the    marginal likelihood.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Pigeons shines in the following scenarios:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"When the posterior density pi is challenging due to    non-convexity and/or concentration on a    sub-manifolds due to unidentifiability.\nWhen the user needs not only Ef(X) but also Z. Many existing MCMC tools   focus on the former and struggle to do the latter in high dimensional    problems. \nWhen the posterior density pi is defined over a non-standard state-space,    e.g. a combinatorial object such as a phylogenetic tree. ","category":"page"},{"location":"#Installing-Pigeons","page":"Guide","title":"Installing Pigeons","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"If you have not done so, install Julia. So far, we have tested the code on Julia 1.8.x.\nInstall Pigeons using","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"using Pkg; Pkg.add(url = \"https://github.com/Julia-Tempering/Pigeons.jl\")","category":"page"},{"location":"#Running-PT","page":"Guide","title":"Running PT","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"Specify the target distribution and, optionally,  parameters like random seed, etc by creating an  Inputs:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"using Pigeons\n\ninputs = Inputs(target = toy_mvn_target(100))","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"See Inputs for more options. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Then, run PT (locally on one process, but using multi-threading) using the function pigeons():","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt = pigeons(inputs)","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"This runs PT on a 100-dimensional MVN toy example, and  returns a PT struct containing the results of  this run (more later on how to access information inside  a PT struct).","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Since the above two julia lines are the most common operation in this package, creating inputs and running PT can be done in one line as:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt = pigeons(target = toy_mvn_target(100))","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"where the args... passed to pigeons are forwarded  to Inputs.","category":"page"},{"location":"#Loading-and-resuming-a-checkpoint","page":"Guide","title":"Loading and resuming a checkpoint","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"By default, PT will automatically write a \"checkpoint\" periodically  to ensure that not more than half of the work is lost in  the event of e.g. a server failure.  See write_checkpoint() for details of how this  is accomplished in a way compatible to both the single-machine  and MPI contexts.  Each checkpoint is located in  results/all/[unique folder]/round=[x]/checkpoint,  with the latest run in results/latest/[unique folder]/round=[x]/checkpoint. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Checkpoints are also useful when an MPI-distributed PT has been  ran, and the user wants to load the full set of  results in one interactive session. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"To load a checkpoint, create a PT struct by passing in the path  string to the checkpoint folder, for example to re-load the latest checkpoint  from the latest run:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt = pigeons(target = toy_mvn_target(100))\npt_from_checkpoint = PT(\"results/latest\")","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Another use case is you may want to run more iterations  of an analysis done in the past. For example, to do two  extra rounds on the above PT algorithm run  (a round is an iteration in the  outer loop of our adaptive PT algorithm, see Parallel Tempering (PT) for  more details):","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt_from_checkpoint.inputs.n_rounds += 2\npigeons(pt_from_checkpoint)","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"You can also disable checkpoints when you create the  Inputs struct or when passing the input  options directly into pigeons()","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pigeons(target = toy_mvn_target(100), checkpoint = false);","category":"page"},{"location":"#Automatic-correctness-checks","page":"Guide","title":"Automatic correctness checks","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"It is notoriously difficult to implement correct parallel/distributed algorithms.  One strategy we use to address this is to guarantee that the code will output  precisely the same output no matter how many threads/machines are used.  We describe how this is done under the hood in the page Distributed PT. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"In practice, how is this useful? Let us say you developed a new target and you would like to make sure that it works correctly in a multi-threaded environment. To do so, you can  just add a flag to indicate to \"check\" one of the PT rounds as follows:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pigeons(target = toy_mvn_target(100), checked_round = 3)","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"The above line does the following: the PT algorithm will pause at the end of round 3, spawn  a separate process with only one thread in it, run 3 rounds of PT with the same  Inputs object in it, and verify that the checkpoints of the single-threaded run  is identical to   the one that ran in the main process. If not, an error will be raised with some  information on where the discrepancy comes from.  Try to pick the checked round to be small enough that it does not dominate the running time  (since it runs in single-threaded, single-process mode), but big enough to achieve  the same code coverage as the full algorithm. Setting it to zero (or omitting the argument),  disable this functionality.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Did the code above actually used many threads? This depends on the value of Threads.nthreads(). Julia currently does not allow you to change this value at  runtime, so for convenience we provide the following way to run the job in a  child process with a set number of Julia threads:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt_result = pigeons(target = toy_mvn_target(100), checked_round = 3, on = ChildProcess(n_threads = 4))","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Notice that this time, instead of returning a PT struct, this time we obtain  a Result, which only holds the path where the checkpoints can be found.  If you would like to load a result in memory, use:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pt = load(pt_result)","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"In this case, since the model is built-in, the check passed successfully as expected. But what  if you had a third-party target distribution that is not multi-threaded friendly?  I.e. it may write in global variables or  other non-thread safe construct. Then you can probably still  use your thread-naive  target over MPI processes.  For example, if the thread-unsafety comes from the use of global variables, then each  process will have its own copy of the global variables. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"We described how MPI can be used in the next two sections.","category":"page"},{"location":"#Running-MPI-locally","page":"Guide","title":"Running MPI locally","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"To run MPI locally on one machine, using 4 MPI processes and 1 thread per process use:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pigeons(\n    target = toy_mvn_target(100), \n    checked_round = 3, \n    on = ChildProcess(\n            n_local_mpi_processes = 4,\n            n_threads = 1))","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Note that if n_local_mpi_processes exceeds the number of cores, performance  will steeply degrade (in contrast to threads, for which performance degrades  much more gracefully when the number of threads exceeds the number of cores). ","category":"page"},{"location":"#Running-MPI-on-a-cluster","page":"Guide","title":"Running MPI on a cluster","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"note: The magic of distributed Parallel Tempering\nIf the dimensionality of the state space is large, you may worry that  the time to transmit states over the network would dominate the running time.  Remarkably, the size of the messages transmitted in the inner loop of our  algorithm does not depend on the state space. In a nutshell, the  machines only need to transmit the value of log density ratios (a single float).  See Algorithm 5 in Syed et al., 2021 for details.","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"MPI is typically available via a cluster scheduling system. At the time of  writing, only PBS PRO is supported, but more will be added. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"Follow these instructions to run MPI over several machines:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"In the cluster login node, follow the installation instruction as above. \nStart Julia in the login node, and perform a one-time setup by calling setup_mpi().\nStill in the Julia REPL running in the login node, use:","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"pigeons(\n    target = toy_mvn_target(100), \n    checked_round = 3, \n    n_chains = 1000,\n    on = MPI(\n        n_mpi_processes = 1000,\n        n_threads = 1))","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"This will start a distributed PT algorithm with 1000 chains on 1000 MPI processes, each using one thread.","category":"page"},{"location":"#Specification-of-general-models","page":"Guide","title":"Specification of general models","text":"","category":"section"},{"location":"","page":"Guide","title":"Guide","text":"The most general way to invoke Pigeons is by specifying two ingredients: a sequence of distributions,  pi_1 pi_2 dots pi_N, and for each pi_i, a pi_i-invariant Markov transition kernel. Typically, pi_1 is a distribution from which we can sample i.i.d. (e.g. the prior, or a variational  approximation), while the last distribution coincides with the distribution of interest,  pi_N = pi.  This sequence of distributions is specified using the informal interface log_potentials. ","category":"page"},{"location":"","page":"Guide","title":"Guide","text":"warning: TODO\nAdd instructions for Markov transition kernels, and example code.","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"CurrentModule = Pigeons","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"We provide in this page an overview of Non-Reversible Parallel Tempering (PT),  Syed et al., 2021,  linking it with some key parts of the code base. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"note: Note\nRead this page if you are interested in extending Pigeons or  understanding how it works under the hood.  Reading this page is not required to use Pigeons, for that instead refer to the  user guide. ","category":"page"},{"location":"pt/#PT-augmented-state-space,-replicas","page":"Parallel Tempering (PT)","title":"PT augmented state space, replicas","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Let X_n denote a Markov chain on state space mathscrX with stationary distribution pi.  PT is a Markov chain defined on the augmented state space mathscrX^N, hence  a state has the form boldsymbolX = (X^(1) X^(2) dots X^(N)).  Each component of boldsymbolX is stored in a struct called a Replica. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"The storage of the vector of replicas boldsymbolX, is done via the informal  interface replicas. In the context of PT running on one computer,  replicas is implemented with a Vector{Replica}. In the context  of running PT distributed across several communicating machines, replicas  is implemented via EntangledReplicas, which stores the parts of  boldsymbolX that are local to that machine as well as data structures  required to communicate with the other machines. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Internally, PT operates on a discrete set of distributions,  pi_1 pi_2 dots pi_N, where N can be obtained using n_chains().  We use the terminology chain to refer to an index i of pi_i. Typically, pi_N coincides with the distribution of interest pi (called the \"target\"), while  pi_1 is a tractable approximation that will help PT efficiently explore the  state space (called the \"reference\").  More broadly, we assume a subset of the chains (given by target_chains()) coincide with the target, and that a subset of the chains (given by reference_chains()) support  efficient exploration such as i.i.d. sampling or a rapid mixing kernel. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"PT is designed so that its stationary distribution is boldsymbolpi = pi_1 times pi_2 times dots pi_N.  As a result, subsetting each sample to its component corresponding to pi_N = pi,  and applying an integrable function f to each, will lead under weak assumptions  to Monte Carlo averages that converge to the expectation of interest Ef(X) for  X sim pi.","category":"page"},{"location":"pt/#Outline-of-local-exploration-and-communication","page":"Parallel Tempering (PT)","title":"Outline of local exploration and communication","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"PT alternates between two phases, each boldsymbolpi-invariant: the local  exploration phase and the communication phase. Informally, the first phase attempts to achieve  mixing for the univariate statistics pi_i(X^(i)), while the second phase attempts to  translate well-mixing of these univariate statistics into global mixing of X^(i) by  leveraging the reference distribution(s).","category":"page"},{"location":"pt/#Local-exploration","page":"Parallel Tempering (PT)","title":"Local exploration","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"In the local exploration phase, each Replica's state is modified using a pi_i-invariant kernel,  where i is given by Replica.chain. Often, Replica.chain corresponds to  an annealing parameter beta_i but this need not be the case (see  e.g. Baragatti et al., 2011). The kernel can either modify Replica.state in-place, or modify the  Replica's state field. The key interface controlling local exploration, explorer, is  described in more detail below. ","category":"page"},{"location":"pt/#Communication","page":"Parallel Tempering (PT)","title":"Communication","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"In the communication phase, PT proposes swaps between pairs of replicas.  These swaps allow each replica's state to periodically visit reference chains. During these reference visits, the state can move around the space quickly.  In principle, there are two equivalent ways to do a swap: the Replicas could exchange  their state fields; or alternatively, they could exchange their chain fields. Since we provide distributed implementations, we use the latter as it ensures that  the amount of data that needs to be exchanged between two machines during a swap  can be made very small (two floats).  It is remarkable that this cost does not vary with the dimensionality of the state space,  in constrast to the naive implementation which would transmit states over the network. See Distributed PT for more information on our distributed implementation.","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Both in distributed and single process mode,  swaps are performed using the function swap!(). ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"The key interface controlling communication, tempering, is  described in more detail below. ","category":"page"},{"location":"pt/#A-tour-of-the-PT-meta-algorithm","page":"Parallel Tempering (PT)","title":"A tour of the PT meta-algorithm","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"A generalized version of Algorithm 1 (\"one round of PT\") in Syed et al., 2021  is implemented in Pigeons in run_one_round!(),  while the complete algorithm (\"several adaptive rounds\"),  Algorithm 4 of Syed et al., 2021,  has a generalized implementation in pigeons(). ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"In the following we discuss different facets of these (meta-)algorithms.","category":"page"},{"location":"pt/#Storage-in-PT-algorithms","page":"Parallel Tempering (PT)","title":"Storage in PT algorithms","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"The information stored in the execution of pigeons()  is grouped in the struct PT.  The key fields are one pointing to a replicas and  one to a Shared.  Briefly, replicas will store information distinct in each  MPI process, and read-write during each  round, while Shared is identical in all MPI processes, read only during a round, and updated only between  rounds. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"To orchestrate the creation of PT structs, Inputs is used. Inputs fully determines the execution of a  PT algorithm (target distribution, random seed, etc). ","category":"page"},{"location":"pt/#Collecting-statistics:-[recorder](@ref)-and-[recorders](@ref)","page":"Parallel Tempering (PT)","title":"Collecting statistics: recorder and recorders","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Two steps are needed to collect statistics from the execution of a PT algorithm: ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Specifying which statistics to collect using one or several recorder_builder    (e.g. by    default, only some statistics that can be computed in constant memory  are included,    those that have growing memory consumption, e.g. tracking the full    index process as done here, need to be explicitly specified in advance).\nThen at the end of run_one_round!(), reduce_recorders!()   is called to compile the statistics collected  by the different replicas.","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"An object responsible for accumulating all different types of statistics for  one replica is called a  recorders. An object accumulating one  type of statistic for one replica is a recorder.  Each replica has a single recorders to ensure thread safety (e.g., see  the use of a parallel local exploration phase using @thread in explore!()) and to enable distributed  computing. ","category":"page"},{"location":"pt/#Using-a-built-in-[recorder](@ref)","page":"Parallel Tempering (PT)","title":"Using a built-in recorder","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"To see the list of built-in implementations of recorder, see the section \"Examples of functions..\" at recorder. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"To specify you want to use one recorder, specify it in the Vector  argument recorder_builders in Inputs. For example, to signal you want  to save the full index process, use:","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"using Pigeons\n\npt = pigeons(target = toy_mvn_target(1), recorder_builders = [index_process])","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"You can then access the index process via ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"pt.reduced_recorders.index_process","category":"page"},{"location":"pt/#Creating-your-own-[recorder](@ref)","page":"Parallel Tempering (PT)","title":"Creating your own recorder","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"The following pieces are needed","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Pick or create a struct MyStruct that will hold the information. \nImplement all the methods in the section \"Contract\" of recorder making sure to type the recorder argument as recorder::MyStruct. Some examples are in the same source file as recorder and/or in the same folder as recorder.jl.   \nCreate a recorder_builder which is simply a function such ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"that when called with zero argument, creates your desired type, i.e.  MyStruct. The name of this function will define the name of your recorder.","category":"page"},{"location":"pt/#Local-[explorer](@ref)","page":"Parallel Tempering (PT)","title":"Local explorer","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Typical target distributions are expected to take care of building  their own explorers, so most users are not expected to have to  write their own. But for non-standard target it is useful to be  able to do so. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Building a new explorer is done as follows: first, suppose you are planning to use a non-standard target of type MyTargetType","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Pick or create a struct MyExplorerStruct that may contain adaptation   information such as step sizes for HMC or proposal bandwidth.   Note that explorers will need to explore not only the target   distribution pi but also the intermediate ones pi_i.\nImplement all the methods in the section \"Contract\" of explorer making sure to type the explorer argument as explorer::MyExplorerStruct. Some examples are in the same folder as the source file of explorer.  \nDefine a method create_explorer(target::MyTargetType, inputs) which   should return a fresh MyExplorerStruct instance. ","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"One explorer struct will be shared by all threads, so it should be  read-only during execution of run_one_round!().  It can be adapted between rounds. ","category":"page"},{"location":"pt/#Tempering","page":"Parallel Tempering (PT)","title":"Tempering","text":"","category":"section"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Customizing communicate!() follows the same general steps as custom explorers, i.e.:","category":"page"},{"location":"pt/","page":"Parallel Tempering (PT)","title":"Parallel Tempering (PT)","text":"Pick or create a struct MyTemperingStruct that may contain adaptation   information such as schedule optimization. \nImplement all the methods in the section \"Contract\" of tempering making sure to type the tempering argument as tempering::MyTemperingStruct. For example, see NonReversiblePT. \nInitial construction of the tempering is done via  create_tempering().","category":"page"}]
}
